{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "47c918b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47c918b0",
        "outputId": "c8711952-371d-4ee3-ba57-a479672dc884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# import module\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive')\n",
        "from preprocessing import FederatedDataBuilder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "69aac5f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "id": "69aac5f0",
        "outputId": "490f60fb-5934-46e9-c9a4-9facdd97d004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating IID partition for 100 clients...\n",
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Round 1/20 (Sparsity: 0.1) ---\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Round 1 Global Test Acc: 1.00%\n",
            "\n",
            "--- Round 2/20 (Sparsity: 0.1) ---\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Calculating sensitivity over 15 batches...\n",
            "Round 2 Global Test Acc: 1.00%\n",
            "\n",
            "--- Round 3/20 (Sparsity: 0.1) ---\n",
            "Calculating sensitivity over 15 batches...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-95028673.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# è¿è¡Œå®éªŒ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mrun_fed_iid_task_arithmetic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparsity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-95028673.py\u001b[0m in \u001b[0;36mrun_fed_iid_task_arithmetic\u001b[0;34m(rounds, num_clients, sampling_rate, sparsity)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# æœ¬åœ°ä»»åŠ¡ç®—æœ¯è®­ç»ƒ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             w, count = local_train_task_arithmetic(\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mlocal_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-95028673.py\u001b[0m in \u001b[0;36mlocal_train_task_arithmetic\u001b[0;34m(model, train_dataset, client_indices, device, sparsity_ratio, local_epochs)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# è¿™é‡Œä¼šè‡ªåŠ¨åº”ç”¨æ©ç \u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m                             )\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/taskarithmetic.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;31m# Update step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from preprocessing import FederatedDataBuilder\n",
        "from taskarithmetic import SparseSGDM, compute_fisher_sensitivity, calibrate_masks\n",
        "from fed_avg_iid import DINOCIFAR100, fed_avg_aggregate # å¤ç”¨ä½ ä¹‹å‰çš„æ¨¡å‹å’Œèšåˆå‡½æ•°\n",
        "\n",
        "# ============================================================\n",
        "# 1. æœ¬åœ°è®­ç»ƒå‡½æ•° (é›†æˆäº† Task Arithmetic)\n",
        "# ============================================================\n",
        "def local_train_task_arithmetic(model, train_dataset, client_indices, device,\n",
        "                                 sparsity_ratio=0.1, local_epochs=4):\n",
        "    \"\"\"\n",
        "    å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒï¼šåŒ…å«æ©ç æ ¡å‡†å’Œç¨€ç–å¾®è°ƒ\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "\n",
        "    # å‡†å¤‡æœ¬åœ°æ•°æ®\n",
        "    local_sub = Subset(train_dataset, list(client_indices))\n",
        "    local_loader = DataLoader(local_sub, batch_size=32, shuffle=True)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # --- é˜¶æ®µ A: æ©ç æ ¡å‡† (Mask Calibration) ---\n",
        "    # æ ¹æ®é¡¹ç›®è¦æ±‚ï¼šè¯†åˆ«æœ€ä¸æ•æ„Ÿ (least-sensitive) çš„å‚æ•°\n",
        "    # ä½¿ç”¨ä¸€è½® (num_batches=len(local_loader)) å³å¯ä»£è¡¨æœ¬åœ°æ•°æ®çš„æ•æ„Ÿåº¦\n",
        "    sensitivity_scores = compute_fisher_sensitivity(\n",
        "        model, local_loader, criterion, device, num_batches=len(local_loader)\n",
        "    )\n",
        "\n",
        "    masks = calibrate_masks(\n",
        "        sensitivity_scores,\n",
        "        sparsity_ratio=sparsity_ratio,\n",
        "        keep_least_sensitive=True # é¡¹ç›® 3.3 è¦æ±‚\n",
        "    )\n",
        "\n",
        "    # --- é˜¶æ®µ B: ç¨€ç–å¾®è°ƒ (Sparse Fine-tuning) ---\n",
        "    # ä½¿ç”¨ä½ å®ç°çš„ SparseSGDM\n",
        "    optimizer = SparseSGDM(\n",
        "        model.parameters(),\n",
        "        lr=0.08,\n",
        "        momentum=0.9,\n",
        "        masks=masks\n",
        "    )\n",
        "\n",
        "    for epoch in range(local_epochs):\n",
        "        for inputs, labels in local_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step() # è¿™é‡Œä¼šè‡ªåŠ¨åº”ç”¨æ©ç \n",
        "\n",
        "    return model.state_dict(), len(local_sub)\n",
        "\n",
        "# ============================================================\n",
        "# 2. ä¸»è”é‚¦è®­ç»ƒå¾ªç¯\n",
        "# ============================================================\n",
        "def run_fed_iid_task_arithmetic(rounds=50, num_clients=100, sampling_rate=0.1, sparsity=0.1):\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # æ•°æ®å‡†å¤‡\n",
        "    builder = FederatedDataBuilder(K=num_clients)\n",
        "    # è·å– IID åˆ’åˆ†\n",
        "    dict_users = builder.get_iid_partition()\n",
        "    test_loader = DataLoader(builder.test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "    # åˆå§‹åŒ–å…¨å±€æ¨¡å‹\n",
        "    global_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    history = {\"accuracy\": [], \"loss\": []}\n",
        "\n",
        "    for r in range(rounds):\n",
        "        print(f\"\\n--- Round {r+1}/{rounds} (Sparsity: {sparsity}) ---\")\n",
        "\n",
        "        local_weights = []\n",
        "        local_counts = []\n",
        "\n",
        "        # éšæœºé€‰æ‹©å®¢æˆ·ç«¯\n",
        "        m = max(int(sampling_rate * num_clients), 1)\n",
        "        selected_clients = np.random.choice(range(num_clients), m, replace=False)\n",
        "\n",
        "        for client_id in selected_clients:\n",
        "            # æ·±æ‹·è´å…¨å±€æ¨¡å‹åˆ°æœ¬åœ°\n",
        "            local_model = copy.deepcopy(global_model)\n",
        "\n",
        "            # æœ¬åœ°ä»»åŠ¡ç®—æœ¯è®­ç»ƒ\n",
        "            w, count = local_train_task_arithmetic(\n",
        "                local_model,\n",
        "                builder.train_dataset,\n",
        "                dict_users[client_id],\n",
        "                DEVICE,\n",
        "                sparsity_ratio=sparsity\n",
        "            )\n",
        "\n",
        "            local_weights.append(w)\n",
        "            local_counts.append(count)\n",
        "\n",
        "        # èšåˆ (FedAvg)\n",
        "        global_weights = fed_avg_aggregate(global_model, local_weights, local_counts)\n",
        "        global_model.load_state_dict(global_weights)\n",
        "\n",
        "        # å…¨å±€è¯„ä¼°\n",
        "        acc, loss = evaluate(global_model, test_loader, DEVICE)\n",
        "        history[\"accuracy\"].append(acc)\n",
        "        history[\"loss\"].append(loss)\n",
        "        print(f\"Round {r+1} Global Test Acc: {acc:.2f}%\")\n",
        "\n",
        "    return history\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total, total_loss / len(loader)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import numpy as np\n",
        "    # è¿è¡Œå®éªŒ\n",
        "    run_fed_iid_task_arithmetic(rounds=20, sparsity=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "è”é‚¦Task Arithmeticè¯Šæ–­è„šæœ¬ (æœ€ç»ˆç‰ˆ)\n",
        "ç”¨äºæ’æŸ¥ä¸ºä»€ä¹ˆæ¨¡å‹ç²¾åº¦æä½(~1%)\n",
        "\n",
        "ä½¿ç”¨ DINOCIFAR100 æ¨¡å‹ç±»\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "\n",
        "from preprocessing import FederatedDataBuilder\n",
        "from taskarithmetic import compute_fisher_sensitivity, calibrate_masks\n",
        "\n",
        "# å¯¼å…¥æ¨¡å‹ - å…¼å®¹ä¸åŒçš„å‘½å\n",
        "try:\n",
        "    from fed_avg_iid import DINOCIFAR100Fixed as DINOCIFAR100\n",
        "except ImportError:\n",
        "    from fed_avg_iid import DINOCIFAR100\n",
        "\n",
        "\n",
        "def diagnose_mask_problem(sparsity_ratio=0.1):\n",
        "    \"\"\"\n",
        "    è¯Šæ–­æ©ç æ˜¯å¦è¿‡äºä¸¥æ ¼\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"è¯Šæ–­ 1: æ£€æŸ¥æ©ç ç”Ÿæˆ\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # å‡†å¤‡æ•°æ®\n",
        "    builder = FederatedDataBuilder(K=10)\n",
        "    dict_users = builder.get_iid_partition()\n",
        "\n",
        "    # åˆ›å»ºæ¨¡å‹\n",
        "    model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    # å‡†å¤‡ä¸€ä¸ªå®¢æˆ·ç«¯çš„æ•°æ®\n",
        "    local_subset = Subset(builder.train_dataset, list(dict_users[0]))\n",
        "    local_loader = DataLoader(local_subset, batch_size=32, shuffle=True)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # è®¡ç®—æ•æ„Ÿåº¦\n",
        "    print(f\"\\nè®¡ç®—Fisheræ•æ„Ÿåº¦ (sparsity={sparsity_ratio})...\")\n",
        "    sensitivity_scores = compute_fisher_sensitivity(\n",
        "        model, local_loader, criterion, DEVICE, num_batches=5\n",
        "    )\n",
        "\n",
        "    # ç”Ÿæˆæ©ç \n",
        "    masks = calibrate_masks(\n",
        "        sensitivity_scores,\n",
        "        sparsity_ratio=sparsity_ratio,\n",
        "        keep_least_sensitive=True\n",
        "    )\n",
        "\n",
        "    # åˆ†ææ©ç \n",
        "    print(\"\\næ©ç ç»Ÿè®¡:\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    total_params = 0\n",
        "    frozen_params = 0\n",
        "    active_params = 0\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            mask = masks.get(param)\n",
        "            if mask is not None:\n",
        "                num_params = int(param.numel())\n",
        "                num_active = int(mask.sum().item())\n",
        "                num_frozen = num_params - num_active\n",
        "\n",
        "                total_params += num_params\n",
        "                frozen_params += num_frozen\n",
        "                active_params += num_active\n",
        "\n",
        "                active_ratio = 100 * num_active / num_params\n",
        "                print(f\"{name:30s} | Total: {num_params:8d} | \"\n",
        "                      f\"Active: {num_active:8d} ({active_ratio:5.1f}%) | \"\n",
        "                      f\"Frozen: {num_frozen:8d}\")\n",
        "\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"{'æ€»è®¡':30s} | Total: {total_params:8d} | \"\n",
        "          f\"Active: {active_params:8d} ({100*active_params/total_params:5.1f}%) | \"\n",
        "          f\"Frozen: {frozen_params:8d}\")\n",
        "\n",
        "    # å…³é”®æ£€æŸ¥\n",
        "    if active_params == 0:\n",
        "        print(\"\\nâŒ ä¸¥é‡é”™è¯¯: æ‰€æœ‰å‚æ•°éƒ½è¢«å†»ç»“!\")\n",
        "        print(\"   - æ¨¡å‹æ— æ³•å­¦ä¹ \")\n",
        "        print(\"   - éœ€è¦æ£€æŸ¥calibrate_maskså®ç°\")\n",
        "        return False\n",
        "\n",
        "    if active_params < total_params * 0.01:  # å°äº1%\n",
        "        print(\"\\nâš ï¸  è­¦å‘Š: å¯æ›´æ–°å‚æ•°è¿‡å°‘!\")\n",
        "        print(f\"   - åªæœ‰{100*active_params/total_params:.2f}%çš„å‚æ•°å¯ä»¥æ›´æ–°\")\n",
        "        print(\"   - å»ºè®®å¢å¤§sparsity_ratio\")\n",
        "        return False\n",
        "\n",
        "    print(\"\\nâœ“ æ©ç ç”Ÿæˆæ­£å¸¸\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def diagnose_training_step():\n",
        "    \"\"\"\n",
        "    è¯Šæ–­å•æ­¥è®­ç»ƒæ˜¯å¦æ­£å¸¸\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"è¯Šæ–­ 2: æ£€æŸ¥è®­ç»ƒæ­¥éª¤\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # å‡†å¤‡æ•°æ®\n",
        "    builder = FederatedDataBuilder(K=10)\n",
        "    dict_users = builder.get_iid_partition()\n",
        "\n",
        "    # åˆ›å»ºæ¨¡å‹\n",
        "    model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    # æ£€æŸ¥backboneæ˜¯å¦å†»ç»“\n",
        "    print(\"\\næ£€æŸ¥backboneå†»ç»“çŠ¶æ€:\")\n",
        "    backbone_params_trainable = sum(p.requires_grad for p in model.backbone.parameters())\n",
        "    print(f\"Backboneå¯è®­ç»ƒå‚æ•°æ•°: {backbone_params_trainable}\")\n",
        "    if backbone_params_trainable > 0:\n",
        "        print(\"âŒ é”™è¯¯: Backboneåº”è¯¥è¢«å®Œå…¨å†»ç»“!\")\n",
        "        return False\n",
        "    print(\"âœ“ Backboneå·²æ­£ç¡®å†»ç»“\")\n",
        "\n",
        "    # æ£€æŸ¥head\n",
        "    print(\"\\nHeadå‚æ•°:\")\n",
        "    for name, param in model.head.named_parameters():\n",
        "        print(f\"  {name}: requires_grad={param.requires_grad}, shape={param.shape}\")\n",
        "\n",
        "    # å‡†å¤‡æœ¬åœ°æ•°æ®\n",
        "    local_subset = Subset(builder.train_dataset, list(dict_users[0]))\n",
        "    local_loader = DataLoader(local_subset, batch_size=32, shuffle=True)\n",
        "\n",
        "    # è·å–ä¸€ä¸ªbatch\n",
        "    inputs, targets = next(iter(local_loader))\n",
        "    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "    # å‰å‘ä¼ æ’­\n",
        "    print(\"\\næµ‹è¯•å‰å‘ä¼ æ’­:\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs)\n",
        "        print(f\"  è¾“å‡ºå½¢çŠ¶: {outputs.shape}\")\n",
        "        print(f\"  è¾“å‡ºèŒƒå›´: [{outputs.min().item():.2f}, {outputs.max().item():.2f}]\")\n",
        "\n",
        "        # æ£€æŸ¥åˆå§‹ç²¾åº¦\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct = predicted.eq(targets).sum().item()\n",
        "        acc = 100. * correct / targets.size(0)\n",
        "        print(f\"  åˆå§‹ç²¾åº¦ (éšæœº): {acc:.2f}%\")\n",
        "\n",
        "        if acc < 0.5 or acc > 5:\n",
        "            print(f\"  âš ï¸  è­¦å‘Š: åˆå§‹ç²¾åº¦å¼‚å¸¸ (æœŸæœ›~1%)\")\n",
        "\n",
        "    # æµ‹è¯•åå‘ä¼ æ’­\n",
        "    print(\"\\næµ‹è¯•åå‘ä¼ æ’­:\")\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # è®°å½•åˆå§‹æƒé‡\n",
        "    initial_weight = model.head.weight.clone()\n",
        "\n",
        "    # è®­ç»ƒä¸€æ­¥\n",
        "    optimizer = torch.optim.SGD(model.head.parameters(), lr=0.1)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "\n",
        "    # æ£€æŸ¥æ¢¯åº¦\n",
        "    if model.head.weight.grad is None:\n",
        "        print(\"  âŒ é”™è¯¯: æ²¡æœ‰è®¡ç®—æ¢¯åº¦!\")\n",
        "        return False\n",
        "\n",
        "    grad_norm = model.head.weight.grad.norm().item()\n",
        "    print(f\"  æ¢¯åº¦èŒƒæ•°: {grad_norm:.4f}\")\n",
        "\n",
        "    if grad_norm < 1e-6:\n",
        "        print(\"  âš ï¸  è­¦å‘Š: æ¢¯åº¦è¿‡å°\")\n",
        "\n",
        "    # æ›´æ–°æƒé‡\n",
        "    optimizer.step()\n",
        "\n",
        "    # æ£€æŸ¥æƒé‡æ˜¯å¦æ”¹å˜\n",
        "    weight_change = (model.head.weight - initial_weight).abs().max().item()\n",
        "    print(f\"  æƒé‡æœ€å¤§å˜åŒ–: {weight_change:.6f}\")\n",
        "\n",
        "    if weight_change < 1e-8:\n",
        "        print(\"  âŒ é”™è¯¯: æƒé‡æ²¡æœ‰æ›´æ–°!\")\n",
        "        return False\n",
        "\n",
        "    print(\"  âœ“ è®­ç»ƒæ­¥éª¤æ­£å¸¸\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def diagnose_aggregation():\n",
        "    \"\"\"\n",
        "    è¯Šæ–­èšåˆæ˜¯å¦æ­£å¸¸\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"è¯Šæ–­ 3: æ£€æŸ¥FedAvgèšåˆ\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    from fed_avg_iid import fed_avg_aggregate\n",
        "\n",
        "    # åˆ›å»ºå…¨å±€æ¨¡å‹\n",
        "    global_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    # åˆ›å»ºä¸¤ä¸ªæ¨¡æ‹Ÿçš„æœ¬åœ°æ¨¡å‹æƒé‡\n",
        "    local_weights = []\n",
        "\n",
        "    for i in range(2):\n",
        "        local_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "        # éšæœºä¿®æ”¹æƒé‡\n",
        "        with torch.no_grad():\n",
        "            local_model.head.weight += torch.randn_like(local_model.head.weight) * 0.1\n",
        "        local_weights.append(local_model.state_dict())\n",
        "\n",
        "    client_counts = [100, 100]\n",
        "\n",
        "    # æ‰§è¡Œèšåˆ\n",
        "    print(\"\\næ‰§è¡Œèšåˆ...\")\n",
        "    global_weight_before = global_model.head.weight.clone()\n",
        "\n",
        "    new_weights = fed_avg_aggregate(global_model, local_weights, client_counts)\n",
        "    global_model.load_state_dict(new_weights, strict=False)\n",
        "\n",
        "    global_weight_after = global_model.head.weight\n",
        "\n",
        "    # æ£€æŸ¥æƒé‡æ˜¯å¦æ”¹å˜\n",
        "    weight_change = (global_weight_after - global_weight_before).abs().max().item()\n",
        "    print(f\"å…¨å±€æ¨¡å‹æƒé‡æœ€å¤§å˜åŒ–: {weight_change:.6f}\")\n",
        "\n",
        "    if weight_change < 1e-8:\n",
        "        print(\"âŒ é”™è¯¯: èšåˆåå…¨å±€æ¨¡å‹æƒé‡æ²¡æœ‰æ”¹å˜!\")\n",
        "        return False\n",
        "\n",
        "    print(\"âœ“ èšåˆæ­£å¸¸\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def test_without_task_arithmetic():\n",
        "    \"\"\"\n",
        "    æµ‹è¯•ä¸ä½¿ç”¨Task Arithmeticçš„æ ‡å‡†FedAvg\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"è¯Šæ–­ 4: æµ‹è¯•æ ‡å‡†FedAvg (æ— Task Arithmetic)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # æ•°æ®å‡†å¤‡\n",
        "    builder = FederatedDataBuilder(K=10)\n",
        "    dict_users = builder.get_iid_partition()\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        builder.test_dataset,\n",
        "        batch_size=256,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # å…¨å±€æ¨¡å‹\n",
        "    global_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    from fed_avg_iid import fed_avg_aggregate, evaluate_global\n",
        "\n",
        "    print(\"\\nè¿è¡Œ3è½®æ ‡å‡†FedAvg...\")\n",
        "\n",
        "    for r in range(3):\n",
        "        # é€‰æ‹©2ä¸ªå®¢æˆ·ç«¯\n",
        "        selected_clients = np.random.choice(range(10), 2, replace=False)\n",
        "\n",
        "        local_weights = []\n",
        "        client_counts = []\n",
        "\n",
        "        for client_idx in selected_clients:\n",
        "            # æœ¬åœ°è®­ç»ƒ\n",
        "            local_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "            local_model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "            local_subset = Subset(builder.train_dataset, list(dict_users[client_idx]))\n",
        "            local_loader = DataLoader(local_subset, batch_size=32, shuffle=True)\n",
        "\n",
        "            optimizer = torch.optim.SGD(local_model.head.parameters(), lr=0.1, momentum=0.9)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            local_model.train()\n",
        "            step_count = 0\n",
        "            iterator = iter(local_loader)\n",
        "\n",
        "            # æ­£ç¡®å®ç°J=4æ­¥\n",
        "            while step_count < 4:\n",
        "                try:\n",
        "                    inputs, targets = next(iterator)\n",
        "                    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = local_model(inputs)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    step_count += 1\n",
        "                except StopIteration:\n",
        "                    break\n",
        "\n",
        "            local_weights.append(local_model.state_dict())\n",
        "            client_counts.append(len(dict_users[client_idx]))\n",
        "\n",
        "        # èšåˆ\n",
        "        new_weights = fed_avg_aggregate(global_model, local_weights, client_counts)\n",
        "        global_model.load_state_dict(new_weights, strict=False)\n",
        "\n",
        "        # è¯„ä¼°\n",
        "        test_loss, test_acc = evaluate_global(global_model, test_loader, DEVICE)\n",
        "        print(f\"Round {r+1}: Test Acc = {test_acc:.2f}%\")\n",
        "\n",
        "        if test_acc < 1.0:\n",
        "            print(\"  âš ï¸  ç²¾åº¦ä»ç„¶è¿‡ä½!\")\n",
        "        elif test_acc > 3.0:\n",
        "            print(\"  âœ“ ç²¾åº¦å¼€å§‹æå‡,åŸºç¡€æµç¨‹æ­£å¸¸\")\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    è¿è¡Œæ‰€æœ‰è¯Šæ–­\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"ğŸ”\"*35)\n",
        "    print(\"      è”é‚¦Task Arithmetic è¯Šæ–­å·¥å…·\")\n",
        "    print(\"ğŸ”\"*35)\n",
        "\n",
        "    # è¯Šæ–­1: æ©ç \n",
        "    mask_ok = diagnose_mask_problem(sparsity_ratio=0.1)\n",
        "\n",
        "    # è¯Šæ–­2: è®­ç»ƒæ­¥éª¤\n",
        "    training_ok = diagnose_training_step()\n",
        "\n",
        "    # è¯Šæ–­3: èšåˆ\n",
        "    aggregation_ok = diagnose_aggregation()\n",
        "\n",
        "    # è¯Šæ–­4: æ— TAçš„FedAvg\n",
        "    fedavg_ok = test_without_task_arithmetic()\n",
        "\n",
        "    # æ€»ç»“\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"è¯Šæ–­æ€»ç»“\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"1. æ©ç ç”Ÿæˆ: {'âœ“ æ­£å¸¸' if mask_ok else 'âŒ å¼‚å¸¸'}\")\n",
        "    print(f\"2. è®­ç»ƒæ­¥éª¤: {'âœ“ æ­£å¸¸' if training_ok else 'âŒ å¼‚å¸¸'}\")\n",
        "    print(f\"3. FedAvgèšåˆ: {'âœ“ æ­£å¸¸' if aggregation_ok else 'âŒ å¼‚å¸¸'}\")\n",
        "    print(f\"4. æ ‡å‡†FedAvg: {'âœ“ æ­£å¸¸' if fedavg_ok else 'âŒ å¼‚å¸¸'}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"å»ºè®®:\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    if not mask_ok:\n",
        "        print(\"1. æ£€æŸ¥calibrate_maskså‡½æ•°å®ç°\")\n",
        "        print(\"2. å°è¯•æ›´å¤§çš„sparsity_ratio (å¦‚0.5)\")\n",
        "        print(\"3. ç¡®è®¤keep_least_sensitiveé€»è¾‘æ­£ç¡®\")\n",
        "\n",
        "    if not training_ok:\n",
        "        print(\"1. æ£€æŸ¥æ¨¡å‹åˆå§‹åŒ–\")\n",
        "        print(\"2. ç¡®è®¤backboneæ­£ç¡®å†»ç»“\")\n",
        "        print(\"3. è°ƒæ•´å­¦ä¹ ç‡\")\n",
        "\n",
        "    if not fedavg_ok:\n",
        "        print(\"1. åŸºç¡€FedAvgå°±æœ‰é—®é¢˜,å…ˆä¿®å¤å®ƒ\")\n",
        "        print(\"2. æ£€æŸ¥æ•°æ®åŠ è½½\")\n",
        "        print(\"3. å¢åŠ æœ¬åœ°è®­ç»ƒæ­¥æ•°\")\n",
        "\n",
        "    if mask_ok and training_ok and aggregation_ok and not fedavg_ok:\n",
        "        print(\"1. é—®é¢˜å¯èƒ½åœ¨æ•°æ®å¤„ç†æˆ–æ¨¡å‹æ¶æ„\")\n",
        "        print(\"2. å°è¯•è¿è¡Œfed_avg_iid.pyçœ‹æ˜¯å¦æ­£å¸¸\")\n",
        "\n",
        "    print(\"\\nğŸ’¡ å¿«é€Ÿä¿®å¤å»ºè®®:\")\n",
        "    print(\"   - å…ˆç¡®ä¿æ ‡å‡†FedAvgèƒ½work (ç²¾åº¦>5%)\")\n",
        "    print(\"   - å†åŠ å…¥Task Arithmetic\")\n",
        "    print(\"   - ä½¿ç”¨è¾ƒå¤§çš„sparsity_ratioå¼€å§‹æµ‹è¯•\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "24MgjhUNTAQh",
        "outputId": "4122d0bd-8a74-45c6-b03a-eb4b4794c576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "id": "24MgjhUNTAQh",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”\n",
            "      è”é‚¦Task Arithmetic è¯Šæ–­å·¥å…·\n",
            "ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”\n",
            "\n",
            "======================================================================\n",
            "è¯Šæ–­ 1: æ£€æŸ¥æ©ç ç”Ÿæˆ\n",
            "======================================================================\n",
            "Creating IID partition for 10 clients...\n",
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "è®¡ç®—Fisheræ•æ„Ÿåº¦ (sparsity=0.1)...\n",
            "Calculating sensitivity over 5 batches...\n",
            "\n",
            "æ©ç ç»Ÿè®¡:\n",
            "----------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unknown format code 'd' for object of type 'float'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2934501298.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2934501298.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;31m# è¯Šæ–­1: æ©ç \u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0mmask_ok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiagnose_mask_problem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparsity_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;31m# è¯Šæ–­2: è®­ç»ƒæ­¥éª¤\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2934501298.py\u001b[0m in \u001b[0;36mdiagnose_mask_problem\u001b[0;34m(sparsity_ratio)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0mactive_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_active\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 print(f\"{name:30s} | Total: {num_params:8d} | \"\n\u001b[0;32m---> 74\u001b[0;31m                       \u001b[0;34mf\"Active: {num_active:8d} ({active_ratio:5.1f}%) | \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                       f\"Frozen: {num_frozen:8d}\")\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown format code 'd' for object of type 'float'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}