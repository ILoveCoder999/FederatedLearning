{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47c918b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47c918b0",
        "outputId": "c6618f61-3130-4c75-d911-3f29f1f4aa96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# import module\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive')\n",
        "from preprocessing import FederatedDataBuilder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "69aac5f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "69aac5f0",
        "outputId": "d0142a31-0288-4b5a-9447-7dac61694011"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "######################################################################\n",
            "# Running Task Arithmetic Experiment\n",
            "######################################################################\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Federated Learning with Task Arithmetic\n",
            "======================================================================\n",
            "Device: cuda\n",
            "Clients: 100, Sampling: 0.1\n",
            "Rounds: 30, Local Epochs: 4\n",
            "Sparsity: 0.5, Learning Rate: 0.1\n",
            "======================================================================\n",
            "\n",
            "Preparing data...\n",
            "Creating IID partition for 100 clients...\n",
            "Initializing global model...\n",
            "Loading DINO backbone...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ DINO loaded\n",
            "Initial accuracy: 0.79% (expected ~1% for random init)\n",
            "\n",
            "Starting training (10 clients per round)...\n",
            "\n",
            "======================================================================\n",
            "Round 1/30\n",
            "======================================================================\n",
            "Selected clients: [78 44 87 70 93]...\n",
            "\n",
            "Client 1/10 (ID: 78):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=14.6403\n",
            "    Epoch 2: loss=14.6141\n",
            "    Epoch 3: loss=14.0571\n",
            "    Epoch 4: loss=13.5539\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 1 Results:\n",
            "  Avg Train Loss: 14.3966\n",
            "  Test Loss: 13.8076\n",
            "  Test Accuracy: 0.91%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 2/30\n",
            "======================================================================\n",
            "Selected clients: [49 83 63 29 12]...\n",
            "\n",
            "Client 1/10 (ID: 49):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=13.8378\n",
            "    Epoch 2: loss=13.6378\n",
            "    Epoch 3: loss=13.0444\n",
            "    Epoch 4: loss=12.6934\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 2 Results:\n",
            "  Avg Train Loss: 13.2292\n",
            "  Test Loss: 12.7540\n",
            "  Test Accuracy: 1.02%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 3/30\n",
            "======================================================================\n",
            "Selected clients: [96 45  4 31 75]...\n",
            "\n",
            "Client 1/10 (ID: 96):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=13.4254\n",
            "    Epoch 2: loss=13.1504\n",
            "    Epoch 3: loss=12.7026\n",
            "    Epoch 4: loss=12.3211\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 3 Results:\n",
            "  Avg Train Loss: 12.3587\n",
            "  Test Loss: 11.8231\n",
            "  Test Accuracy: 1.30%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 4/30\n",
            "======================================================================\n",
            "Selected clients: [35 52 19  2 44]...\n",
            "\n",
            "Client 1/10 (ID: 35):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=11.9913\n",
            "    Epoch 2: loss=11.7600\n",
            "    Epoch 3: loss=11.3451\n",
            "    Epoch 4: loss=10.9665\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 4 Results:\n",
            "  Avg Train Loss: 11.3573\n",
            "  Test Loss: 11.0101\n",
            "  Test Accuracy: 1.79%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 5/30\n",
            "======================================================================\n",
            "Selected clients: [37  9 92  4 73]...\n",
            "\n",
            "Client 1/10 (ID: 37):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=10.9852\n",
            "    Epoch 2: loss=10.6767\n",
            "    Epoch 3: loss=10.4240\n",
            "    Epoch 4: loss=10.0586\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 5 Results:\n",
            "  Avg Train Loss: 10.5718\n",
            "  Test Loss: 10.3031\n",
            "  Test Accuracy: 2.28%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 6/30\n",
            "======================================================================\n",
            "Selected clients: [53 11 41 17 59]...\n",
            "\n",
            "Client 1/10 (ID: 53):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=10.2039\n",
            "    Epoch 2: loss=9.9232\n",
            "    Epoch 3: loss=9.5896\n",
            "    Epoch 4: loss=9.1498\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 6 Results:\n",
            "  Avg Train Loss: 10.0424\n",
            "  Test Loss: 9.6940\n",
            "  Test Accuracy: 3.18%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 7/30\n",
            "======================================================================\n",
            "Selected clients: [44 82 52 84 81]...\n",
            "\n",
            "Client 1/10 (ID: 44):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=9.8585\n",
            "    Epoch 2: loss=9.6176\n",
            "    Epoch 3: loss=9.3188\n",
            "    Epoch 4: loss=9.0010\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 7 Results:\n",
            "  Avg Train Loss: 9.2827\n",
            "  Test Loss: 9.1153\n",
            "  Test Accuracy: 4.15%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 8/30\n",
            "======================================================================\n",
            "Selected clients: [20 68 45 55 93]...\n",
            "\n",
            "Client 1/10 (ID: 20):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=9.1370\n",
            "    Epoch 2: loss=8.8825\n",
            "    Epoch 3: loss=8.5501\n",
            "    Epoch 4: loss=8.1732\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 8 Results:\n",
            "  Avg Train Loss: 8.7817\n",
            "  Test Loss: 8.6043\n",
            "  Test Accuracy: 5.38%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 9/30\n",
            "======================================================================\n",
            "Selected clients: [89 93 95 34 61]...\n",
            "\n",
            "Client 1/10 (ID: 89):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=8.3121\n",
            "    Epoch 2: loss=8.1993\n",
            "    Epoch 3: loss=7.8165\n",
            "    Epoch 4: loss=7.4601\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 9 Results:\n",
            "  Avg Train Loss: 8.1838\n",
            "  Test Loss: 8.1327\n",
            "  Test Accuracy: 6.65%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 10/30\n",
            "======================================================================\n",
            "Selected clients: [ 4 64 79  9 45]...\n",
            "\n",
            "Client 1/10 (ID: 4):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=7.8793\n",
            "    Epoch 2: loss=7.6779\n",
            "    Epoch 3: loss=7.3926\n",
            "    Epoch 4: loss=6.9570\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 10 Results:\n",
            "  Avg Train Loss: 7.6014\n",
            "  Test Loss: 7.7028\n",
            "  Test Accuracy: 8.29%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 11/30\n",
            "======================================================================\n",
            "Selected clients: [49 52 33 70 24]...\n",
            "\n",
            "Client 1/10 (ID: 49):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=7.9272\n",
            "    Epoch 2: loss=7.8362\n",
            "    Epoch 3: loss=7.5994\n",
            "    Epoch 4: loss=7.3116\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 11 Results:\n",
            "  Avg Train Loss: 7.2950\n",
            "  Test Loss: 7.3039\n",
            "  Test Accuracy: 10.12%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 12/30\n",
            "======================================================================\n",
            "Selected clients: [73 57 85 62 41]...\n",
            "\n",
            "Client 1/10 (ID: 73):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=6.8331\n",
            "    Epoch 2: loss=6.6373\n",
            "    Epoch 3: loss=6.4897\n",
            "    Epoch 4: loss=6.0904\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 12 Results:\n",
            "  Avg Train Loss: 6.9002\n",
            "  Test Loss: 6.9537\n",
            "  Test Accuracy: 11.76%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 13/30\n",
            "======================================================================\n",
            "Selected clients: [65 45 56 36 52]...\n",
            "\n",
            "Client 1/10 (ID: 65):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=7.1619\n",
            "    Epoch 2: loss=7.0841\n",
            "    Epoch 3: loss=6.6304\n",
            "    Epoch 4: loss=6.3454\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 13 Results:\n",
            "  Avg Train Loss: 6.6182\n",
            "  Test Loss: 6.6117\n",
            "  Test Accuracy: 13.68%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 14/30\n",
            "======================================================================\n",
            "Selected clients: [11 85 15 76  2]...\n",
            "\n",
            "Client 1/10 (ID: 11):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=6.5512\n",
            "    Epoch 2: loss=6.3064\n",
            "    Epoch 3: loss=6.1530\n",
            "    Epoch 4: loss=5.7270\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 14 Results:\n",
            "  Avg Train Loss: 6.0342\n",
            "  Test Loss: 6.3179\n",
            "  Test Accuracy: 15.42%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 15/30\n",
            "======================================================================\n",
            "Selected clients: [62 44 52 75 84]...\n",
            "\n",
            "Client 1/10 (ID: 62):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=6.1259\n",
            "    Epoch 2: loss=6.0621\n",
            "    Epoch 3: loss=5.8470\n",
            "    Epoch 4: loss=5.4144\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 15 Results:\n",
            "  Avg Train Loss: 6.0004\n",
            "  Test Loss: 6.0497\n",
            "  Test Accuracy: 17.00%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 16/30\n",
            "======================================================================\n",
            "Selected clients: [15  1 34 27 23]...\n",
            "\n",
            "Client 1/10 (ID: 15):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=5.8393\n",
            "    Epoch 2: loss=5.8051\n",
            "    Epoch 3: loss=5.4768\n",
            "    Epoch 4: loss=5.2411\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 16 Results:\n",
            "  Avg Train Loss: 5.6491\n",
            "  Test Loss: 5.8183\n",
            "  Test Accuracy: 18.81%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 17/30\n",
            "======================================================================\n",
            "Selected clients: [13 42 16 23 15]...\n",
            "\n",
            "Client 1/10 (ID: 13):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=5.6845\n",
            "    Epoch 2: loss=5.5939\n",
            "    Epoch 3: loss=5.3562\n",
            "    Epoch 4: loss=5.0170\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 17 Results:\n",
            "  Avg Train Loss: 5.5159\n",
            "  Test Loss: 5.6096\n",
            "  Test Accuracy: 20.67%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 18/30\n",
            "======================================================================\n",
            "Selected clients: [14 76 40 95 10]...\n",
            "\n",
            "Client 1/10 (ID: 14):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=5.8149\n",
            "    Epoch 2: loss=5.7032\n",
            "    Epoch 3: loss=5.4850\n",
            "    Epoch 4: loss=5.3143\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 18 Results:\n",
            "  Avg Train Loss: 5.3354\n",
            "  Test Loss: 5.4239\n",
            "  Test Accuracy: 21.92%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 19/30\n",
            "======================================================================\n",
            "Selected clients: [87 34 82 15 11]...\n",
            "\n",
            "Client 1/10 (ID: 87):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=5.2195\n",
            "    Epoch 2: loss=5.0615\n",
            "    Epoch 3: loss=4.9542\n",
            "    Epoch 4: loss=4.6937\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 19 Results:\n",
            "  Avg Train Loss: 5.0546\n",
            "  Test Loss: 5.2364\n",
            "  Test Accuracy: 23.41%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 20/30\n",
            "======================================================================\n",
            "Selected clients: [10  1 39 66 65]...\n",
            "\n",
            "Client 1/10 (ID: 10):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=5.1149\n",
            "    Epoch 2: loss=5.0578\n",
            "    Epoch 3: loss=4.9344\n",
            "    Epoch 4: loss=4.5552\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 20 Results:\n",
            "  Avg Train Loss: 5.0070\n",
            "  Test Loss: 5.0849\n",
            "  Test Accuracy: 24.51%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 21/30\n",
            "======================================================================\n",
            "Selected clients: [29 34 85 94  1]...\n",
            "\n",
            "Client 1/10 (ID: 29):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=5.0027\n",
            "    Epoch 2: loss=4.9060\n",
            "    Epoch 3: loss=4.7255\n",
            "    Epoch 4: loss=4.4915\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 21 Results:\n",
            "  Avg Train Loss: 4.7930\n",
            "  Test Loss: 4.9390\n",
            "  Test Accuracy: 25.72%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 22/30\n",
            "======================================================================\n",
            "Selected clients: [93 39 34 48 94]...\n",
            "\n",
            "Client 1/10 (ID: 93):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=4.8320\n",
            "    Epoch 2: loss=4.7232\n",
            "    Epoch 3: loss=4.4123\n",
            "    Epoch 4: loss=4.3079\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 22 Results:\n",
            "  Avg Train Loss: 4.5943\n",
            "  Test Loss: 4.8043\n",
            "  Test Accuracy: 26.78%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 23/30\n",
            "======================================================================\n",
            "Selected clients: [52 10 31 68 14]...\n",
            "\n",
            "Client 1/10 (ID: 52):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=4.6292\n",
            "    Epoch 2: loss=4.4756\n",
            "    Epoch 3: loss=4.3415\n",
            "    Epoch 4: loss=4.1534\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 23 Results:\n",
            "  Avg Train Loss: 4.5030\n",
            "  Test Loss: 4.6777\n",
            "  Test Accuracy: 28.04%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 24/30\n",
            "======================================================================\n",
            "Selected clients: [ 2 13 58 25  7]...\n",
            "\n",
            "Client 1/10 (ID: 2):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=4.3632\n",
            "    Epoch 2: loss=4.2317\n",
            "    Epoch 3: loss=4.0753\n",
            "    Epoch 4: loss=3.8228\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 24 Results:\n",
            "  Avg Train Loss: 4.3525\n",
            "  Test Loss: 4.5655\n",
            "  Test Accuracy: 29.14%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 25/30\n",
            "======================================================================\n",
            "Selected clients: [82 22 61 87 40]...\n",
            "\n",
            "Client 1/10 (ID: 82):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=4.5569\n",
            "    Epoch 2: loss=4.3131\n",
            "    Epoch 3: loss=4.2920\n",
            "    Epoch 4: loss=4.1274\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 25 Results:\n",
            "  Avg Train Loss: 4.2709\n",
            "  Test Loss: 4.4529\n",
            "  Test Accuracy: 30.47%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 26/30\n",
            "======================================================================\n",
            "Selected clients: [91 84 11  3 77]...\n",
            "\n",
            "Client 1/10 (ID: 91):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=4.3711\n",
            "    Epoch 2: loss=4.1853\n",
            "    Epoch 3: loss=4.1194\n",
            "    Epoch 4: loss=3.9139\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 26 Results:\n",
            "  Avg Train Loss: 4.1277\n",
            "  Test Loss: 4.3647\n",
            "  Test Accuracy: 30.99%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 27/30\n",
            "======================================================================\n",
            "Selected clients: [32 61 47 74 78]...\n",
            "\n",
            "Client 1/10 (ID: 32):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=4.0109\n",
            "    Epoch 2: loss=3.8778\n",
            "    Epoch 3: loss=3.6306\n",
            "    Epoch 4: loss=3.3739\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 27 Results:\n",
            "  Avg Train Loss: 4.0234\n",
            "  Test Loss: 4.2753\n",
            "  Test Accuracy: 31.84%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 28/30\n",
            "======================================================================\n",
            "Selected clients: [54 93 58 56 14]...\n",
            "\n",
            "Client 1/10 (ID: 54):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=4.3086\n",
            "    Epoch 2: loss=4.2663\n",
            "    Epoch 3: loss=4.0911\n",
            "    Epoch 4: loss=3.8282\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 28 Results:\n",
            "  Avg Train Loss: 4.0707\n",
            "  Test Loss: 4.1941\n",
            "  Test Accuracy: 32.68%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 29/30\n",
            "======================================================================\n",
            "Selected clients: [58 14 34 39 99]...\n",
            "\n",
            "Client 1/10 (ID: 58):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=3.6648\n",
            "    Epoch 2: loss=3.6297\n",
            "    Epoch 3: loss=3.3586\n",
            "    Epoch 4: loss=3.1833\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 29 Results:\n",
            "  Avg Train Loss: 3.8812\n",
            "  Test Loss: 4.1194\n",
            "  Test Accuracy: 33.42%\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Round 30/30\n",
            "======================================================================\n",
            "Selected clients: [62 11 84 92 26]...\n",
            "\n",
            "Client 1/10 (ID: 62):\n",
            "  Local samples: 450\n",
            "  Computing Fisher sensitivity...\n",
            "  Calibrating masks (sparsity=0.5)...\n",
            "  Active params: 19250/38500 (50.00%)\n",
            "  Training for 4 epochs...\n",
            "    Epoch 1: loss=3.8417\n",
            "    Epoch 2: loss=3.7702\n",
            "    Epoch 3: loss=3.5747\n",
            "    Epoch 4: loss=3.4645\n",
            "\n",
            "Aggregating 10 models...\n",
            "\n",
            "======================================================================\n",
            "Round 30 Results:\n",
            "  Avg Train Loss: 3.8385\n",
            "  Test Loss: 4.0481\n",
            "  Test Accuracy: 34.24%\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Training Complete!\n",
            "======================================================================\n",
            "Initial Accuracy: 0.79%\n",
            "Final Accuracy: 34.24%\n",
            "Best Accuracy: 34.24%\n",
            "======================================================================\n",
            "\n",
            "\n",
            "✓ Figure saved: task_arithmetic_results.png\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\"\"\"\n",
        "Task Arithmetic 联邦学习 - 完全修复版本\n",
        "解决了所有已知问题\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from preprocessing import FederatedDataBuilder\n",
        "\n",
        "# ============================================================\n",
        "# 修复后的SparseSGDM\n",
        "# ============================================================\n",
        "class SparseSGDM(optim.SGD):\n",
        "    \"\"\"修复版的稀疏SGD with Momentum\"\"\"\n",
        "    def __init__(self, params, lr=0.001, momentum=0.9, weight_decay=0.0, dampening=0, masks=None):\n",
        "        super().__init__(params, lr=lr, momentum=momentum, weight_decay=weight_decay, dampening=dampening)\n",
        "        self.masks = masks\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            with torch.enable_grad():\n",
        "                loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "\n",
        "                d_p = p.grad\n",
        "\n",
        "                # 应用mask到梯度\n",
        "                if self.masks is not None and p in self.masks:\n",
        "                    d_p = d_p.mul(self.masks[p])\n",
        "\n",
        "                # Weight decay\n",
        "                if group['weight_decay'] != 0:\n",
        "                    d_p = d_p.add(p, alpha=group['weight_decay'])\n",
        "\n",
        "                # Momentum\n",
        "                if group['momentum'] != 0:\n",
        "                    param_state = self.state[p]\n",
        "                    if 'momentum_buffer' not in param_state:\n",
        "                        buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
        "                    else:\n",
        "                        buf = param_state['momentum_buffer']\n",
        "                        buf.mul_(group['momentum']).add_(d_p, alpha=1 - group['dampening'])\n",
        "                    d_p = buf\n",
        "\n",
        "                # 再次应用mask（防止momentum引入被mask的更新）\n",
        "                if self.masks is not None and p in self.masks:\n",
        "                    d_p = d_p.mul(self.masks[p])\n",
        "\n",
        "                # 更新参数\n",
        "                p.add_(d_p, alpha=-group['lr'])\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Fisher敏感度和掩码校准\n",
        "# ============================================================\n",
        "def compute_fisher_sensitivity_head(model, dataloader, criterion, device, num_batches=5):\n",
        "    \"\"\"只对head计算Fisher敏感度\"\"\"\n",
        "    sensitivity = {}\n",
        "    model.eval()\n",
        "\n",
        "    for p in model.head.parameters():\n",
        "        if p.requires_grad:\n",
        "            sensitivity[p] = torch.zeros_like(p.data)\n",
        "\n",
        "    processed = 0\n",
        "    for inputs, labels in dataloader:\n",
        "        if processed >= num_batches:\n",
        "            break\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        model.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        for p in model.head.parameters():\n",
        "            if p.requires_grad and p.grad is not None:\n",
        "                sensitivity[p] += p.grad.data ** 2\n",
        "\n",
        "        processed += 1\n",
        "\n",
        "    for p in sensitivity:\n",
        "        sensitivity[p] /= processed\n",
        "\n",
        "    return sensitivity\n",
        "\n",
        "\n",
        "def calibrate_masks(sensitivity_scores, sparsity_ratio=0.1, keep_least_sensitive=True):\n",
        "    \"\"\"校准掩码\"\"\"\n",
        "    all_scores = torch.cat([s.view(-1) for s in sensitivity_scores.values()])\n",
        "    num_params = all_scores.numel()\n",
        "    k = int(num_params * sparsity_ratio)\n",
        "\n",
        "    if keep_least_sensitive:\n",
        "        threshold = torch.kthvalue(all_scores, k).values.item()\n",
        "        masks = {p: (score <= threshold).float() for p, score in sensitivity_scores.items()}\n",
        "    else:\n",
        "        threshold = torch.kthvalue(all_scores, num_params - k).values.item()\n",
        "        masks = {p: (score >= threshold).float() for p, score in sensitivity_scores.items()}\n",
        "\n",
        "    return masks\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 模型定义\n",
        "# ============================================================\n",
        "GLOBAL_DINO_BACKBONE = None\n",
        "\n",
        "def get_dino_backbone():\n",
        "    global GLOBAL_DINO_BACKBONE\n",
        "    if GLOBAL_DINO_BACKBONE is None:\n",
        "        print(\"Loading DINO backbone...\")\n",
        "        GLOBAL_DINO_BACKBONE = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
        "        print(\"✓ DINO loaded\")\n",
        "    return GLOBAL_DINO_BACKBONE\n",
        "\n",
        "\n",
        "class DINOCIFAR100(nn.Module):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super().__init__()\n",
        "        self.backbone = get_dino_backbone()\n",
        "        for param in self.backbone.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.head = nn.Linear(384, num_classes)\n",
        "        nn.init.xavier_uniform_(self.head.weight)\n",
        "        nn.init.zeros_(self.head.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            features = self.backbone(x)\n",
        "        return self.head(features)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FedAvg聚合\n",
        "# ============================================================\n",
        "def fed_avg_aggregate(global_model, local_weights, client_sample_counts):\n",
        "    global_dict = copy.deepcopy(global_model.state_dict())\n",
        "    total_samples = sum(client_sample_counts)\n",
        "\n",
        "    for k in global_dict.keys():\n",
        "        if 'num_batches_tracked' not in k and 'backbone' not in k:\n",
        "            global_dict[k] = global_dict[k] * 0.0\n",
        "\n",
        "    for i in range(len(local_weights)):\n",
        "        ratio = client_sample_counts[i] / total_samples\n",
        "        weights = local_weights[i]\n",
        "        for k in global_dict.keys():\n",
        "            if 'num_batches_tracked' not in k and 'backbone' not in k:\n",
        "                global_dict[k] += weights[k] * ratio\n",
        "\n",
        "    return global_dict\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 本地训练（Task Arithmetic）\n",
        "# ============================================================\n",
        "def local_train_task_arithmetic(model, train_dataset, client_indices, device,\n",
        "                                 sparsity_ratio=0.1, local_epochs=4, lr=0.1, verbose=False):\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "\n",
        "    local_sub = Subset(train_dataset, list(client_indices))\n",
        "    local_loader = DataLoader(local_sub, batch_size=128, shuffle=True, num_workers=0)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"  Local samples: {len(local_sub)}\")\n",
        "        print(f\"  Computing Fisher sensitivity...\")\n",
        "\n",
        "    # 计算Fisher敏感度（只对head）\n",
        "    sensitivity = compute_fisher_sensitivity_head(model, local_loader, criterion, device, num_batches=5)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"  Calibrating masks (sparsity={sparsity_ratio})...\")\n",
        "\n",
        "    # 校准掩码\n",
        "    masks = calibrate_masks(sensitivity, sparsity_ratio=sparsity_ratio, keep_least_sensitive=True)\n",
        "\n",
        "    # 统计\n",
        "    total_params = sum(p.numel() for p in model.head.parameters())\n",
        "    active_params = sum((masks[p] > 0).sum().item() for p in masks)\n",
        "    actual_sparsity = active_params / total_params\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"  Active params: {active_params}/{total_params} ({actual_sparsity:.2%})\")\n",
        "        print(f\"  Training for {local_epochs} epochs...\")\n",
        "\n",
        "    # 稀疏微调\n",
        "    model.train()\n",
        "    optimizer = SparseSGDM(model.head.parameters(), lr=lr, momentum=0.9, masks=masks)\n",
        "\n",
        "    losses = []\n",
        "    for epoch in range(local_epochs):\n",
        "        epoch_losses = []\n",
        "        for inputs, labels in local_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.head.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            epoch_losses.append(loss.item())\n",
        "\n",
        "        epoch_loss = np.mean(epoch_losses)\n",
        "        losses.append(epoch_loss)\n",
        "        if verbose:\n",
        "            print(f\"    Epoch {epoch+1}: loss={epoch_loss:.4f}\")\n",
        "\n",
        "    return model.state_dict(), len(local_sub), np.mean(losses)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 评估函数\n",
        "# ============================================================\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return total_loss / len(loader), 100 * correct / total\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 主联邦训练循环\n",
        "# ============================================================\n",
        "def run_federated_task_arithmetic(rounds=50, num_clients=100, sampling_rate=0.1,\n",
        "                                   sparsity=0.1, local_epochs=4, lr=0.1, verbose_client=False):\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Federated Learning with Task Arithmetic\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Device: {DEVICE}\")\n",
        "    print(f\"Clients: {num_clients}, Sampling: {sampling_rate}\")\n",
        "    print(f\"Rounds: {rounds}, Local Epochs: {local_epochs}\")\n",
        "    print(f\"Sparsity: {sparsity}, Learning Rate: {lr}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # 数据准备\n",
        "    print(\"Preparing data...\")\n",
        "    builder = FederatedDataBuilder(K=num_clients)\n",
        "    dict_users = builder.get_iid_partition()\n",
        "    test_loader = DataLoader(builder.test_dataset, batch_size=256, shuffle=False, num_workers=0)\n",
        "\n",
        "    # 初始化全局模型\n",
        "    print(\"Initializing global model...\")\n",
        "    global_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    # 检查初始性能\n",
        "    init_loss, init_acc = evaluate(global_model, test_loader, DEVICE)\n",
        "    print(f\"Initial accuracy: {init_acc:.2f}% (expected ~1% for random init)\\n\")\n",
        "\n",
        "    history = {\"accuracy\": [], \"loss\": [], \"train_loss\": [], \"round\": []}\n",
        "\n",
        "    # 联邦训练\n",
        "    m = max(int(sampling_rate * num_clients), 1)\n",
        "    print(f\"Starting training ({m} clients per round)...\\n\")\n",
        "\n",
        "    for r in range(rounds):\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"Round {r+1}/{rounds}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        local_weights = []\n",
        "        local_counts = []\n",
        "        local_losses = []\n",
        "\n",
        "        # 随机选择客户端\n",
        "        selected_clients = np.random.choice(range(num_clients), m, replace=False)\n",
        "        print(f\"Selected clients: {selected_clients[:5]}...\" if m > 5 else f\"Selected: {selected_clients}\")\n",
        "\n",
        "        for idx, client_id in enumerate(selected_clients):\n",
        "            if verbose_client or idx == 0:  # 只详细打印第一个客户端\n",
        "                print(f\"\\nClient {idx+1}/{m} (ID: {client_id}):\")\n",
        "                verbose = True\n",
        "            else:\n",
        "                verbose = False\n",
        "\n",
        "            # 深拷贝全局模型\n",
        "            local_model = copy.deepcopy(global_model)\n",
        "\n",
        "            # 本地训练\n",
        "            w, count, train_loss = local_train_task_arithmetic(\n",
        "                local_model,\n",
        "                builder.train_dataset,\n",
        "                dict_users[client_id],\n",
        "                DEVICE,\n",
        "                sparsity_ratio=sparsity,\n",
        "                local_epochs=local_epochs,\n",
        "                lr=lr,\n",
        "                verbose=verbose\n",
        "            )\n",
        "\n",
        "            local_weights.append(w)\n",
        "            local_counts.append(count)\n",
        "            local_losses.append(train_loss)\n",
        "\n",
        "        # FedAvg聚合\n",
        "        print(f\"\\nAggregating {len(local_weights)} models...\")\n",
        "        global_weights = fed_avg_aggregate(global_model, local_weights, local_counts)\n",
        "        global_model.load_state_dict(global_weights, strict=False)\n",
        "\n",
        "        # 全局评估\n",
        "        test_loss, test_acc = evaluate(global_model, test_loader, DEVICE)\n",
        "        avg_train_loss = np.mean(local_losses)\n",
        "\n",
        "        history[\"accuracy\"].append(test_acc)\n",
        "        history[\"loss\"].append(test_loss)\n",
        "        history[\"train_loss\"].append(avg_train_loss)\n",
        "        history[\"round\"].append(r + 1)\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Round {r+1} Results:\")\n",
        "        print(f\"  Avg Train Loss: {avg_train_loss:.4f}\")\n",
        "        print(f\"  Test Loss: {test_loss:.4f}\")\n",
        "        print(f\"  Test Accuracy: {test_acc:.2f}%\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "        # 早停检查\n",
        "        if r >= 5 and test_acc < 2:\n",
        "            print(\"⚠️  WARNING: Accuracy still < 2% after 5 rounds!\")\n",
        "            print(\"   This suggests a fundamental problem. Consider debugging.\")\n",
        "\n",
        "    # 最终结果\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Training Complete!\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Initial Accuracy: {init_acc:.2f}%\")\n",
        "    print(f\"Final Accuracy: {history['accuracy'][-1]:.2f}%\")\n",
        "    print(f\"Best Accuracy: {max(history['accuracy']):.2f}%\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    return history, global_model\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 主程序\n",
        "# ============================================================\n",
        "if __name__ == \"__main__\":\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # 单个实验\n",
        "    print(\"\\n\" + \"#\"*70)\n",
        "    print(\"# Running Task Arithmetic Experiment\")\n",
        "    print(\"#\"*70 + \"\\n\")\n",
        "\n",
        "    history, model = run_federated_task_arithmetic(\n",
        "        rounds=30,\n",
        "        num_clients=100,\n",
        "        sampling_rate=0.1,\n",
        "        sparsity=0.5,\n",
        "        local_epochs=4,\n",
        "        lr=0.1,\n",
        "        verbose_client=False  # 设为True可以看到所有客户端的详细信息\n",
        "    )\n",
        "\n",
        "    # 绘图\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    ax1.plot(history['round'], history['accuracy'], 'b-o', linewidth=2, markersize=6)\n",
        "    ax1.set_xlabel('Communication Round', fontsize=12)\n",
        "    ax1.set_ylabel('Test Accuracy (%)', fontsize=12)\n",
        "    ax1.set_title('Test Accuracy vs Round', fontsize=14, fontweight='bold')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.set_ylim([0, max(history['accuracy']) * 1.1])\n",
        "\n",
        "    ax2.plot(history['round'], history['train_loss'], 'g-s', label='Train Loss', linewidth=2, markersize=6)\n",
        "    ax2.plot(history['round'], history['loss'], 'r-^', label='Test Loss', linewidth=2, markersize=6)\n",
        "    ax2.set_xlabel('Communication Round', fontsize=12)\n",
        "    ax2.set_ylabel('Loss', fontsize=12)\n",
        "    ax2.set_title('Training Dynamics', fontsize=14, fontweight='bold')\n",
        "    ax2.legend(fontsize=10)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('task_arithmetic_results.png', dpi=150, bbox_inches='tight')\n",
        "    print(\"\\n✓ Figure saved: task_arithmetic_results.png\\n\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "联邦Task Arithmetic诊断脚本 (最终版)\n",
        "用于排查为什么模型精度极低(~1%)\n",
        "\n",
        "使用 DINOCIFAR100 模型类\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "\n",
        "from preprocessing import FederatedDataBuilder\n",
        "from taskarithmetic import compute_fisher_sensitivity, calibrate_masks\n",
        "\n",
        "# 导入模型 - 兼容不同的命名\n",
        "try:\n",
        "    from fed_avg_iid import DINOCIFAR100Fixed as DINOCIFAR100\n",
        "except ImportError:\n",
        "    from fed_avg_iid import DINOCIFAR100\n",
        "\n",
        "\n",
        "def diagnose_mask_problem(sparsity_ratio=0.1):\n",
        "    \"\"\"\n",
        "    诊断掩码是否过于严格\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"诊断 1: 检查掩码生成\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # 准备数据\n",
        "    builder = FederatedDataBuilder(K=10)\n",
        "    dict_users = builder.get_iid_partition()\n",
        "\n",
        "    # 创建模型\n",
        "    model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    # 准备一个客户端的数据\n",
        "    local_subset = Subset(builder.train_dataset, list(dict_users[0]))\n",
        "    local_loader = DataLoader(local_subset, batch_size=32, shuffle=True)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # 计算敏感度\n",
        "    print(f\"\\n计算Fisher敏感度 (sparsity={sparsity_ratio})...\")\n",
        "    sensitivity_scores = compute_fisher_sensitivity(\n",
        "        model, local_loader, criterion, DEVICE, num_batches=5\n",
        "    )\n",
        "\n",
        "    # 生成掩码\n",
        "    masks = calibrate_masks(\n",
        "        sensitivity_scores,\n",
        "        sparsity_ratio=sparsity_ratio,\n",
        "        keep_least_sensitive=True\n",
        "    )\n",
        "\n",
        "    # 分析掩码\n",
        "    print(\"\\n掩码统计:\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    total_params = 0\n",
        "    frozen_params = 0\n",
        "    active_params = 0\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            mask = masks.get(param)\n",
        "            if mask is not None:\n",
        "                num_params = int(param.numel())\n",
        "                num_active = int(mask.sum().item())\n",
        "                num_frozen = num_params - num_active\n",
        "\n",
        "                total_params += num_params\n",
        "                frozen_params += num_frozen\n",
        "                active_params += num_active\n",
        "\n",
        "                active_ratio = 100 * num_active / num_params\n",
        "                print(f\"{name:30s} | Total: {num_params:8d} | \"\n",
        "                      f\"Active: {num_active:8d} ({active_ratio:5.1f}%) | \"\n",
        "                      f\"Frozen: {num_frozen:8d}\")\n",
        "\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"{'总计':30s} | Total: {total_params:8d} | \"\n",
        "          f\"Active: {active_params:8d} ({100*active_params/total_params:5.1f}%) | \"\n",
        "          f\"Frozen: {frozen_params:8d}\")\n",
        "\n",
        "    # 关键检查\n",
        "    if active_params == 0:\n",
        "        print(\"\\n❌ 严重错误: 所有参数都被冻结!\")\n",
        "        print(\"   - 模型无法学习\")\n",
        "        print(\"   - 需要检查calibrate_masks实现\")\n",
        "        return False\n",
        "\n",
        "    if active_params < total_params * 0.01:  # 小于1%\n",
        "        print(\"\\n⚠️  警告: 可更新参数过少!\")\n",
        "        print(f\"   - 只有{100*active_params/total_params:.2f}%的参数可以更新\")\n",
        "        print(\"   - 建议增大sparsity_ratio\")\n",
        "        return False\n",
        "\n",
        "    print(\"\\n✓ 掩码生成正常\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def diagnose_training_step():\n",
        "    \"\"\"\n",
        "    诊断单步训练是否正常\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"诊断 2: 检查训练步骤\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # 准备数据\n",
        "    builder = FederatedDataBuilder(K=10)\n",
        "    dict_users = builder.get_iid_partition()\n",
        "\n",
        "    # 创建模型\n",
        "    model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    # 检查backbone是否冻结\n",
        "    print(\"\\n检查backbone冻结状态:\")\n",
        "    backbone_params_trainable = sum(p.requires_grad for p in model.backbone.parameters())\n",
        "    print(f\"Backbone可训练参数数: {backbone_params_trainable}\")\n",
        "    if backbone_params_trainable > 0:\n",
        "        print(\"❌ 错误: Backbone应该被完全冻结!\")\n",
        "        return False\n",
        "    print(\"✓ Backbone已正确冻结\")\n",
        "\n",
        "    # 检查head\n",
        "    print(\"\\nHead参数:\")\n",
        "    for name, param in model.head.named_parameters():\n",
        "        print(f\"  {name}: requires_grad={param.requires_grad}, shape={param.shape}\")\n",
        "\n",
        "    # 准备本地数据\n",
        "    local_subset = Subset(builder.train_dataset, list(dict_users[0]))\n",
        "    local_loader = DataLoader(local_subset, batch_size=32, shuffle=True)\n",
        "\n",
        "    # 获取一个batch\n",
        "    inputs, targets = next(iter(local_loader))\n",
        "    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "    # 前向传播\n",
        "    print(\"\\n测试前向传播:\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs)\n",
        "        print(f\"  输出形状: {outputs.shape}\")\n",
        "        print(f\"  输出范围: [{outputs.min().item():.2f}, {outputs.max().item():.2f}]\")\n",
        "\n",
        "        # 检查初始精度\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct = predicted.eq(targets).sum().item()\n",
        "        acc = 100. * correct / targets.size(0)\n",
        "        print(f\"  初始精度 (随机): {acc:.2f}%\")\n",
        "\n",
        "        if acc < 0.5 or acc > 5:\n",
        "            print(f\"  ⚠️  警告: 初始精度异常 (期望~1%)\")\n",
        "\n",
        "    # 测试反向传播\n",
        "    print(\"\\n测试反向传播:\")\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # 记录初始权重\n",
        "    initial_weight = model.head.weight.clone()\n",
        "\n",
        "    # 训练一步\n",
        "    optimizer = torch.optim.SGD(model.head.parameters(), lr=0.1)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "\n",
        "    # 检查梯度\n",
        "    if model.head.weight.grad is None:\n",
        "        print(\"  ❌ 错误: 没有计算梯度!\")\n",
        "        return False\n",
        "\n",
        "    grad_norm = model.head.weight.grad.norm().item()\n",
        "    print(f\"  梯度范数: {grad_norm:.4f}\")\n",
        "\n",
        "    if grad_norm < 1e-6:\n",
        "        print(\"  ⚠️  警告: 梯度过小\")\n",
        "\n",
        "    # 更新权重\n",
        "    optimizer.step()\n",
        "\n",
        "    # 检查权重是否改变\n",
        "    weight_change = (model.head.weight - initial_weight).abs().max().item()\n",
        "    print(f\"  权重最大变化: {weight_change:.6f}\")\n",
        "\n",
        "    if weight_change < 1e-8:\n",
        "        print(\"  ❌ 错误: 权重没有更新!\")\n",
        "        return False\n",
        "\n",
        "    print(\"  ✓ 训练步骤正常\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def diagnose_aggregation():\n",
        "    \"\"\"\n",
        "    诊断聚合是否正常\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"诊断 3: 检查FedAvg聚合\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    from fed_avg_iid import fed_avg_aggregate\n",
        "\n",
        "    # 创建全局模型\n",
        "    global_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    # 创建两个模拟的本地模型权重\n",
        "    local_weights = []\n",
        "\n",
        "    for i in range(2):\n",
        "        local_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "        # 随机修改权重\n",
        "        with torch.no_grad():\n",
        "            local_model.head.weight += torch.randn_like(local_model.head.weight) * 0.1\n",
        "        local_weights.append(local_model.state_dict())\n",
        "\n",
        "    client_counts = [100, 100]\n",
        "\n",
        "    # 执行聚合\n",
        "    print(\"\\n执行聚合...\")\n",
        "    global_weight_before = global_model.head.weight.clone()\n",
        "\n",
        "    new_weights = fed_avg_aggregate(global_model, local_weights, client_counts)\n",
        "    global_model.load_state_dict(new_weights, strict=False)\n",
        "\n",
        "    global_weight_after = global_model.head.weight\n",
        "\n",
        "    # 检查权重是否改变\n",
        "    weight_change = (global_weight_after - global_weight_before).abs().max().item()\n",
        "    print(f\"全局模型权重最大变化: {weight_change:.6f}\")\n",
        "\n",
        "    if weight_change < 1e-8:\n",
        "        print(\"❌ 错误: 聚合后全局模型权重没有改变!\")\n",
        "        return False\n",
        "\n",
        "    print(\"✓ 聚合正常\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def test_without_task_arithmetic():\n",
        "    \"\"\"\n",
        "    测试不使用Task Arithmetic的标准FedAvg\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"诊断 4: 测试标准FedAvg (无Task Arithmetic)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # 数据准备\n",
        "    builder = FederatedDataBuilder(K=10)\n",
        "    dict_users = builder.get_iid_partition()\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        builder.test_dataset,\n",
        "        batch_size=256,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # 全局模型\n",
        "    global_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    from fed_avg_iid import fed_avg_aggregate, evaluate_global\n",
        "\n",
        "    print(\"\\n运行3轮标准FedAvg...\")\n",
        "\n",
        "    for r in range(3):\n",
        "        # 选择2个客户端\n",
        "        selected_clients = np.random.choice(range(10), 2, replace=False)\n",
        "\n",
        "        local_weights = []\n",
        "        client_counts = []\n",
        "\n",
        "        for client_idx in selected_clients:\n",
        "            # 本地训练\n",
        "            local_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "            local_model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "            local_subset = Subset(builder.train_dataset, list(dict_users[client_idx]))\n",
        "            local_loader = DataLoader(local_subset, batch_size=32, shuffle=True)\n",
        "\n",
        "            optimizer = torch.optim.SGD(local_model.head.parameters(), lr=0.1, momentum=0.9)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            local_model.train()\n",
        "            step_count = 0\n",
        "            iterator = iter(local_loader)\n",
        "\n",
        "            # 正确实现J=4步\n",
        "            while step_count < 4:\n",
        "                try:\n",
        "                    inputs, targets = next(iterator)\n",
        "                    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = local_model(inputs)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    step_count += 1\n",
        "                except StopIteration:\n",
        "                    break\n",
        "\n",
        "            local_weights.append(local_model.state_dict())\n",
        "            client_counts.append(len(dict_users[client_idx]))\n",
        "\n",
        "        # 聚合\n",
        "        new_weights = fed_avg_aggregate(global_model, local_weights, client_counts)\n",
        "        global_model.load_state_dict(new_weights, strict=False)\n",
        "\n",
        "        # 评估\n",
        "        test_loss, test_acc = evaluate_global(global_model, test_loader, DEVICE)\n",
        "        print(f\"Round {r+1}: Test Acc = {test_acc:.2f}%\")\n",
        "\n",
        "        if test_acc < 1.0:\n",
        "            print(\"  ⚠️  精度仍然过低!\")\n",
        "        elif test_acc > 3.0:\n",
        "            print(\"  ✓ 精度开始提升,基础流程正常\")\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    运行所有诊断\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"🔍\"*35)\n",
        "    print(\"      联邦Task Arithmetic 诊断工具\")\n",
        "    print(\"🔍\"*35)\n",
        "\n",
        "    # 诊断1: 掩码\n",
        "    mask_ok = diagnose_mask_problem(sparsity_ratio=0.1)\n",
        "\n",
        "    # 诊断2: 训练步骤\n",
        "    training_ok = diagnose_training_step()\n",
        "\n",
        "    # 诊断3: 聚合\n",
        "    aggregation_ok = diagnose_aggregation()\n",
        "\n",
        "    # 诊断4: 无TA的FedAvg\n",
        "    fedavg_ok = test_without_task_arithmetic()\n",
        "\n",
        "    # 总结\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"诊断总结\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"1. 掩码生成: {'✓ 正常' if mask_ok else '❌ 异常'}\")\n",
        "    print(f\"2. 训练步骤: {'✓ 正常' if training_ok else '❌ 异常'}\")\n",
        "    print(f\"3. FedAvg聚合: {'✓ 正常' if aggregation_ok else '❌ 异常'}\")\n",
        "    print(f\"4. 标准FedAvg: {'✓ 正常' if fedavg_ok else '❌ 异常'}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"建议:\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    if not mask_ok:\n",
        "        print(\"1. 检查calibrate_masks函数实现\")\n",
        "        print(\"2. 尝试更大的sparsity_ratio (如0.5)\")\n",
        "        print(\"3. 确认keep_least_sensitive逻辑正确\")\n",
        "\n",
        "    if not training_ok:\n",
        "        print(\"1. 检查模型初始化\")\n",
        "        print(\"2. 确认backbone正确冻结\")\n",
        "        print(\"3. 调整学习率\")\n",
        "\n",
        "    if not fedavg_ok:\n",
        "        print(\"1. 基础FedAvg就有问题,先修复它\")\n",
        "        print(\"2. 检查数据加载\")\n",
        "        print(\"3. 增加本地训练步数\")\n",
        "\n",
        "    if mask_ok and training_ok and aggregation_ok and not fedavg_ok:\n",
        "        print(\"1. 问题可能在数据处理或模型架构\")\n",
        "        print(\"2. 尝试运行fed_avg_iid.py看是否正常\")\n",
        "\n",
        "    print(\"\\n💡 快速修复建议:\")\n",
        "    print(\"   - 先确保标准FedAvg能work (精度>5%)\")\n",
        "    print(\"   - 再加入Task Arithmetic\")\n",
        "    print(\"   - 使用较大的sparsity_ratio开始测试\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24MgjhUNTAQh",
        "outputId": "b7147079-e7e3-44b9-997b-afcddf93fda1"
      },
      "id": "24MgjhUNTAQh",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading DINO backbone...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Device: cuda\n",
            "\n",
            "======================================================================\n",
            "DIAGNOSTIC TEST\n",
            "======================================================================\n",
            "\n",
            "1. Loading data...\n",
            "Creating IID partition for 10 clients...\n",
            "   Training samples: 4500\n",
            "   Test samples: 10000\n",
            "\n",
            "2. Initializing model...\n",
            "\n",
            "3. Model parameters:\n",
            "   backbone.cls_token: shape=torch.Size([1, 1, 384]), requires_grad=False\n",
            "   backbone.pos_embed: shape=torch.Size([1, 197, 384]), requires_grad=False\n",
            "   backbone.patch_embed.proj.weight: shape=torch.Size([384, 3, 16, 16]), requires_grad=False\n",
            "   backbone.patch_embed.proj.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.0.norm1.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.0.norm1.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.0.attn.qkv.weight: shape=torch.Size([1152, 384]), requires_grad=False\n",
            "   backbone.blocks.0.attn.qkv.bias: shape=torch.Size([1152]), requires_grad=False\n",
            "   backbone.blocks.0.attn.proj.weight: shape=torch.Size([384, 384]), requires_grad=False\n",
            "   backbone.blocks.0.attn.proj.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.0.norm2.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.0.norm2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.0.mlp.fc1.weight: shape=torch.Size([1536, 384]), requires_grad=False\n",
            "   backbone.blocks.0.mlp.fc1.bias: shape=torch.Size([1536]), requires_grad=False\n",
            "   backbone.blocks.0.mlp.fc2.weight: shape=torch.Size([384, 1536]), requires_grad=False\n",
            "   backbone.blocks.0.mlp.fc2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.1.norm1.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.1.norm1.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.1.attn.qkv.weight: shape=torch.Size([1152, 384]), requires_grad=False\n",
            "   backbone.blocks.1.attn.qkv.bias: shape=torch.Size([1152]), requires_grad=False\n",
            "   backbone.blocks.1.attn.proj.weight: shape=torch.Size([384, 384]), requires_grad=False\n",
            "   backbone.blocks.1.attn.proj.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.1.norm2.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.1.norm2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.1.mlp.fc1.weight: shape=torch.Size([1536, 384]), requires_grad=False\n",
            "   backbone.blocks.1.mlp.fc1.bias: shape=torch.Size([1536]), requires_grad=False\n",
            "   backbone.blocks.1.mlp.fc2.weight: shape=torch.Size([384, 1536]), requires_grad=False\n",
            "   backbone.blocks.1.mlp.fc2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.2.norm1.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.2.norm1.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.2.attn.qkv.weight: shape=torch.Size([1152, 384]), requires_grad=False\n",
            "   backbone.blocks.2.attn.qkv.bias: shape=torch.Size([1152]), requires_grad=False\n",
            "   backbone.blocks.2.attn.proj.weight: shape=torch.Size([384, 384]), requires_grad=False\n",
            "   backbone.blocks.2.attn.proj.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.2.norm2.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.2.norm2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.2.mlp.fc1.weight: shape=torch.Size([1536, 384]), requires_grad=False\n",
            "   backbone.blocks.2.mlp.fc1.bias: shape=torch.Size([1536]), requires_grad=False\n",
            "   backbone.blocks.2.mlp.fc2.weight: shape=torch.Size([384, 1536]), requires_grad=False\n",
            "   backbone.blocks.2.mlp.fc2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.3.norm1.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.3.norm1.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.3.attn.qkv.weight: shape=torch.Size([1152, 384]), requires_grad=False\n",
            "   backbone.blocks.3.attn.qkv.bias: shape=torch.Size([1152]), requires_grad=False\n",
            "   backbone.blocks.3.attn.proj.weight: shape=torch.Size([384, 384]), requires_grad=False\n",
            "   backbone.blocks.3.attn.proj.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.3.norm2.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.3.norm2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.3.mlp.fc1.weight: shape=torch.Size([1536, 384]), requires_grad=False\n",
            "   backbone.blocks.3.mlp.fc1.bias: shape=torch.Size([1536]), requires_grad=False\n",
            "   backbone.blocks.3.mlp.fc2.weight: shape=torch.Size([384, 1536]), requires_grad=False\n",
            "   backbone.blocks.3.mlp.fc2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.4.norm1.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.4.norm1.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.4.attn.qkv.weight: shape=torch.Size([1152, 384]), requires_grad=False\n",
            "   backbone.blocks.4.attn.qkv.bias: shape=torch.Size([1152]), requires_grad=False\n",
            "   backbone.blocks.4.attn.proj.weight: shape=torch.Size([384, 384]), requires_grad=False\n",
            "   backbone.blocks.4.attn.proj.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.4.norm2.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.4.norm2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.4.mlp.fc1.weight: shape=torch.Size([1536, 384]), requires_grad=False\n",
            "   backbone.blocks.4.mlp.fc1.bias: shape=torch.Size([1536]), requires_grad=False\n",
            "   backbone.blocks.4.mlp.fc2.weight: shape=torch.Size([384, 1536]), requires_grad=False\n",
            "   backbone.blocks.4.mlp.fc2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.5.norm1.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.5.norm1.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.5.attn.qkv.weight: shape=torch.Size([1152, 384]), requires_grad=False\n",
            "   backbone.blocks.5.attn.qkv.bias: shape=torch.Size([1152]), requires_grad=False\n",
            "   backbone.blocks.5.attn.proj.weight: shape=torch.Size([384, 384]), requires_grad=False\n",
            "   backbone.blocks.5.attn.proj.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.5.norm2.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.5.norm2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.5.mlp.fc1.weight: shape=torch.Size([1536, 384]), requires_grad=False\n",
            "   backbone.blocks.5.mlp.fc1.bias: shape=torch.Size([1536]), requires_grad=False\n",
            "   backbone.blocks.5.mlp.fc2.weight: shape=torch.Size([384, 1536]), requires_grad=False\n",
            "   backbone.blocks.5.mlp.fc2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.6.norm1.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.6.norm1.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.6.attn.qkv.weight: shape=torch.Size([1152, 384]), requires_grad=False\n",
            "   backbone.blocks.6.attn.qkv.bias: shape=torch.Size([1152]), requires_grad=False\n",
            "   backbone.blocks.6.attn.proj.weight: shape=torch.Size([384, 384]), requires_grad=False\n",
            "   backbone.blocks.6.attn.proj.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.6.norm2.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.6.norm2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.6.mlp.fc1.weight: shape=torch.Size([1536, 384]), requires_grad=False\n",
            "   backbone.blocks.6.mlp.fc1.bias: shape=torch.Size([1536]), requires_grad=False\n",
            "   backbone.blocks.6.mlp.fc2.weight: shape=torch.Size([384, 1536]), requires_grad=False\n",
            "   backbone.blocks.6.mlp.fc2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.7.norm1.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.7.norm1.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.7.attn.qkv.weight: shape=torch.Size([1152, 384]), requires_grad=False\n",
            "   backbone.blocks.7.attn.qkv.bias: shape=torch.Size([1152]), requires_grad=False\n",
            "   backbone.blocks.7.attn.proj.weight: shape=torch.Size([384, 384]), requires_grad=False\n",
            "   backbone.blocks.7.attn.proj.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.7.norm2.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.7.norm2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.7.mlp.fc1.weight: shape=torch.Size([1536, 384]), requires_grad=False\n",
            "   backbone.blocks.7.mlp.fc1.bias: shape=torch.Size([1536]), requires_grad=False\n",
            "   backbone.blocks.7.mlp.fc2.weight: shape=torch.Size([384, 1536]), requires_grad=False\n",
            "   backbone.blocks.7.mlp.fc2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.8.norm1.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.8.norm1.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.8.attn.qkv.weight: shape=torch.Size([1152, 384]), requires_grad=False\n",
            "   backbone.blocks.8.attn.qkv.bias: shape=torch.Size([1152]), requires_grad=False\n",
            "   backbone.blocks.8.attn.proj.weight: shape=torch.Size([384, 384]), requires_grad=False\n",
            "   backbone.blocks.8.attn.proj.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.8.norm2.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.8.norm2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.8.mlp.fc1.weight: shape=torch.Size([1536, 384]), requires_grad=False\n",
            "   backbone.blocks.8.mlp.fc1.bias: shape=torch.Size([1536]), requires_grad=False\n",
            "   backbone.blocks.8.mlp.fc2.weight: shape=torch.Size([384, 1536]), requires_grad=False\n",
            "   backbone.blocks.8.mlp.fc2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.9.norm1.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.9.norm1.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.9.attn.qkv.weight: shape=torch.Size([1152, 384]), requires_grad=False\n",
            "   backbone.blocks.9.attn.qkv.bias: shape=torch.Size([1152]), requires_grad=False\n",
            "   backbone.blocks.9.attn.proj.weight: shape=torch.Size([384, 384]), requires_grad=False\n",
            "   backbone.blocks.9.attn.proj.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.9.norm2.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.9.norm2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.9.mlp.fc1.weight: shape=torch.Size([1536, 384]), requires_grad=False\n",
            "   backbone.blocks.9.mlp.fc1.bias: shape=torch.Size([1536]), requires_grad=False\n",
            "   backbone.blocks.9.mlp.fc2.weight: shape=torch.Size([384, 1536]), requires_grad=False\n",
            "   backbone.blocks.9.mlp.fc2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.10.norm1.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.10.norm1.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.10.attn.qkv.weight: shape=torch.Size([1152, 384]), requires_grad=False\n",
            "   backbone.blocks.10.attn.qkv.bias: shape=torch.Size([1152]), requires_grad=False\n",
            "   backbone.blocks.10.attn.proj.weight: shape=torch.Size([384, 384]), requires_grad=False\n",
            "   backbone.blocks.10.attn.proj.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.10.norm2.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.10.norm2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.10.mlp.fc1.weight: shape=torch.Size([1536, 384]), requires_grad=False\n",
            "   backbone.blocks.10.mlp.fc1.bias: shape=torch.Size([1536]), requires_grad=False\n",
            "   backbone.blocks.10.mlp.fc2.weight: shape=torch.Size([384, 1536]), requires_grad=False\n",
            "   backbone.blocks.10.mlp.fc2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.11.norm1.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.11.norm1.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.11.attn.qkv.weight: shape=torch.Size([1152, 384]), requires_grad=False\n",
            "   backbone.blocks.11.attn.qkv.bias: shape=torch.Size([1152]), requires_grad=False\n",
            "   backbone.blocks.11.attn.proj.weight: shape=torch.Size([384, 384]), requires_grad=False\n",
            "   backbone.blocks.11.attn.proj.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.11.norm2.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.11.norm2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.blocks.11.mlp.fc1.weight: shape=torch.Size([1536, 384]), requires_grad=False\n",
            "   backbone.blocks.11.mlp.fc1.bias: shape=torch.Size([1536]), requires_grad=False\n",
            "   backbone.blocks.11.mlp.fc2.weight: shape=torch.Size([384, 1536]), requires_grad=False\n",
            "   backbone.blocks.11.mlp.fc2.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.norm.weight: shape=torch.Size([384]), requires_grad=False\n",
            "   backbone.norm.bias: shape=torch.Size([384]), requires_grad=False\n",
            "   head.weight: shape=torch.Size([100, 384]), requires_grad=True\n",
            "   head.bias: shape=torch.Size([100]), requires_grad=True\n",
            "\n",
            "   Total: 21,704,164, Trainable: 38,500\n",
            "\n",
            "4. Initial accuracy (random initialization):\n",
            "   Initial accuracy: 1.25%\n",
            "   Expected: ~1% (random guess for 100 classes)\n",
            "\n",
            "5. Computing Fisher sensitivity...\n",
            "   Computed sensitivity for 2 tensors\n",
            "\n",
            "6. Sensitivity statistics:\n",
            "   Tensor 0: min=0.000000, max=5.060300, mean=0.007197\n",
            "   Tensor 1: min=0.000005, max=0.014189, mean=0.000481\n",
            "\n",
            "7. Testing mask calibration:\n",
            "   Sparsity 0.1: 3850/38500 = 10.00%\n",
            "   Sparsity 0.5: 19250/38500 = 50.00%\n",
            "   Sparsity 0.9: 34650/38500 = 90.00%\n",
            "\n",
            "8. Test training WITHOUT mask (1 epoch):\n",
            "   Average loss: 60.0498\n",
            "   Accuracy after 1 epoch (NO mask): 38.09%\n",
            "   ✓ Model CAN learn without mask\n",
            "\n",
            "9. Test training WITH mask (sparsity=0.5, 1 epoch):\n",
            "   Active parameters: 19251/38500 (50.0%)\n",
            "   Average loss: 10.9050\n",
            "   Accuracy after 1 epoch (WITH mask): 12.75%\n",
            "   ✓ Model CAN learn with mask\n",
            "\n",
            "======================================================================\n",
            "DIAGNOSIS SUMMARY\n",
            "======================================================================\n",
            "\n",
            "✓ Both tests passed! The implementation should work.\n",
            "   If federated learning still gives 1%, check:\n",
            "   1. Aggregation function\n",
            "   2. Model copying between rounds\n",
            "======================================================================\n",
            "\n",
            "Final Results:\n",
            "  Without mask: 38.09%\n",
            "  With mask:    12.75%\n",
            "\n",
            "✓ Basic training works!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}