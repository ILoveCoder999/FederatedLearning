{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "47c918b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47c918b0",
        "outputId": "c6618f61-3130-4c75-d911-3f29f1f4aa96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# import module\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive')\n",
        "from preprocessing import FederatedDataBuilder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "69aac5f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "id": "69aac5f0",
        "outputId": "e29babf2-dbed-44eb-a782-16019e20864a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'GLOBAL_DINO_BACKBONE' from 'fed_avg_iid' (/content/drive/MyDrive/fed_avg_iid.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-782181338.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFederatedDataBuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtaskarithmetic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparseSGDM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_fisher_sensitivity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalibrate_masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfed_avg_iid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDINOCIFAR100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfed_avg_aggregate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGLOBAL_DINO_BACKBONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# ============================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'GLOBAL_DINO_BACKBONE' from 'fed_avg_iid' (/content/drive/MyDrive/fed_avg_iid.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from preprocessing import FederatedDataBuilder\n",
        "from taskarithmetic import SparseSGDM, calibrate_masks\n",
        "\n",
        "# ============================================================\n",
        "# 1. æ¨¡å‹å®šä¹‰ (ç‹¬ç«‹ç‰ˆæœ¬ï¼Œä¸ä¾èµ–fed_avg_iid)\n",
        "# ============================================================\n",
        "\n",
        "# å…¨å±€åŠ è½½ä¸€æ¬¡backboneï¼Œé¿å…é‡å¤åŠ è½½\n",
        "GLOBAL_DINO_BACKBONE = None\n",
        "\n",
        "def get_dino_backbone():\n",
        "    \"\"\"å…¨å±€å•ä¾‹æ¨¡å¼è·å–DINO backbone\"\"\"\n",
        "    global GLOBAL_DINO_BACKBONE\n",
        "    if GLOBAL_DINO_BACKBONE is None:\n",
        "        print(\"Loading DINO backbone (first time only)...\")\n",
        "        GLOBAL_DINO_BACKBONE = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
        "        print(\"âœ“ DINO backbone loaded\")\n",
        "    return GLOBAL_DINO_BACKBONE\n",
        "\n",
        "\n",
        "class DINOCIFAR100(nn.Module):\n",
        "    \"\"\"DINO ViT + Linear Head for CIFAR-100\"\"\"\n",
        "    def __init__(self, num_classes=100):\n",
        "        super().__init__()\n",
        "\n",
        "        # ä½¿ç”¨å…¨å±€backbone\n",
        "        self.backbone = get_dino_backbone()\n",
        "\n",
        "        # å†»ç»“backbone\n",
        "        for param in self.backbone.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # åˆ†ç±»å¤´\n",
        "        self.head = nn.Linear(384, num_classes)\n",
        "\n",
        "        # åˆå§‹åŒ–å¤´éƒ¨\n",
        "        nn.init.xavier_uniform_(self.head.weight)\n",
        "        nn.init.zeros_(self.head.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            features = self.backbone(x)\n",
        "        output = self.head(features)\n",
        "        return output\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2. FedAvg èšåˆå‡½æ•°\n",
        "# ============================================================\n",
        "\n",
        "def fed_avg_aggregate(global_model, local_weights, client_sample_counts):\n",
        "    \"\"\"FedAvgåŠ æƒå¹³å‡èšåˆ\"\"\"\n",
        "    global_dict = copy.deepcopy(global_model.state_dict())\n",
        "    total_samples = sum(client_sample_counts)\n",
        "\n",
        "    # åˆå§‹åŒ–ä¸º0\n",
        "    for k in global_dict.keys():\n",
        "        if 'num_batches_tracked' not in k and 'backbone' not in k:\n",
        "            global_dict[k] = global_dict[k] * 0.0\n",
        "\n",
        "    # åŠ æƒå¹³å‡\n",
        "    for i in range(len(local_weights)):\n",
        "        ratio = client_sample_counts[i] / total_samples\n",
        "        weights = local_weights[i]\n",
        "        for k in global_dict.keys():\n",
        "            if 'num_batches_tracked' not in k and 'backbone' not in k:\n",
        "                global_dict[k] += weights[k] * ratio\n",
        "\n",
        "    return global_dict\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3. æœ¬åœ°è®­ç»ƒå‡½æ•° (Task Arithmetic)\n",
        "# ============================================================\n",
        "\n",
        "def local_train_task_arithmetic(model, train_dataset, client_indices, device,\n",
        "                                 sparsity_ratio=0.1, local_epochs=4, lr=0.1):\n",
        "    \"\"\"\n",
        "    å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒï¼šTask Arithmeticæ–¹æ³•\n",
        "\n",
        "    å…³é”®ç‚¹:\n",
        "    1. åªå¯¹headå±‚è®¡ç®—Fisheræ•æ„Ÿåº¦\n",
        "    2. åªå¯¹headå±‚åº”ç”¨æ©ç \n",
        "    3. åªä¼˜åŒ–headå±‚å‚æ•°\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "\n",
        "    # å‡†å¤‡æœ¬åœ°æ•°æ®\n",
        "    local_sub = Subset(train_dataset, list(client_indices))\n",
        "    local_loader = DataLoader(local_sub, batch_size=128, shuffle=True)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(f\"  Local data: {len(local_sub)} samples\")\n",
        "\n",
        "    # --- é˜¶æ®µ A: Fisheræ•æ„Ÿåº¦è®¡ç®— (åªé’ˆå¯¹head) ---\n",
        "    print(f\"  Computing Fisher sensitivity (head only)...\")\n",
        "\n",
        "    head_sensitivity = {}\n",
        "    model.eval()\n",
        "\n",
        "    for p in model.head.parameters():\n",
        "        if p.requires_grad:\n",
        "            head_sensitivity[p] = torch.zeros_like(p.data)\n",
        "\n",
        "    # é™åˆ¶batchæ•°é‡ä»¥åŠ é€Ÿ\n",
        "    num_batches = min(len(local_loader), 5)\n",
        "    processed = 0\n",
        "\n",
        "    for inputs, labels in local_loader:\n",
        "        if processed >= num_batches:\n",
        "            break\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        model.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # ç´¯ç§¯headæ¢¯åº¦çš„å¹³æ–¹\n",
        "        for p in model.head.parameters():\n",
        "            if p.requires_grad and p.grad is not None:\n",
        "                head_sensitivity[p] += p.grad.data ** 2\n",
        "\n",
        "        processed += 1\n",
        "\n",
        "    # å½’ä¸€åŒ–\n",
        "    for p in head_sensitivity:\n",
        "        head_sensitivity[p] /= processed\n",
        "\n",
        "    print(f\"  Computed sensitivity for {len(head_sensitivity)} parameter tensors\")\n",
        "\n",
        "    # --- é˜¶æ®µ B: æ©ç æ ¡å‡† ---\n",
        "    print(f\"  Calibrating masks (sparsity={sparsity_ratio})...\")\n",
        "\n",
        "    masks = calibrate_masks(\n",
        "        head_sensitivity,\n",
        "        sparsity_ratio=sparsity_ratio,\n",
        "        keep_least_sensitive=True\n",
        "    )\n",
        "\n",
        "    # ç»Ÿè®¡\n",
        "    total_params = sum(p.numel() for p in model.head.parameters())\n",
        "    masked_params = sum((masks[p] > 0).sum().item() for p in masks)\n",
        "    actual_sparsity = masked_params / total_params\n",
        "\n",
        "    print(f\"  Mask stats: {masked_params}/{total_params} params active ({actual_sparsity:.2%})\")\n",
        "\n",
        "    # --- é˜¶æ®µ C: ç¨€ç–å¾®è°ƒ ---\n",
        "    print(f\"  Sparse fine-tuning ({local_epochs} epochs)...\")\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    optimizer = SparseSGDM(\n",
        "        model.head.parameters(),  # åªä¼˜åŒ–head\n",
        "        lr=lr,\n",
        "        momentum=0.9,\n",
        "        masks=masks\n",
        "    )\n",
        "\n",
        "    epoch_losses = []\n",
        "    for epoch in range(local_epochs):\n",
        "        batch_losses = []\n",
        "        for inputs, labels in local_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            # æ¢¯åº¦è£å‰ª\n",
        "            torch.nn.utils.clip_grad_norm_(model.head.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "            batch_losses.append(loss.item())\n",
        "\n",
        "        epoch_loss = np.mean(batch_losses)\n",
        "        epoch_losses.append(epoch_loss)\n",
        "        print(f\"    Epoch {epoch+1}/{local_epochs}: loss={epoch_loss:.4f}\")\n",
        "\n",
        "    return model.state_dict(), len(local_sub)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. è¯„ä¼°å‡½æ•°\n",
        "# ============================================================\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    \"\"\"è¯„ä¼°æ¨¡å‹æ€§èƒ½\"\"\"\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return total_loss / len(loader), 100 * correct / total\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. ä¸»è”é‚¦è®­ç»ƒå¾ªç¯\n",
        "# ============================================================\n",
        "\n",
        "def run_fed_task_arithmetic(rounds=50, num_clients=100, sampling_rate=0.1,\n",
        "                             sparsity=0.1, local_epochs=4, lr=0.1):\n",
        "    \"\"\"\n",
        "    FedAvg + Task Arithmetic è”é‚¦å­¦ä¹ \n",
        "\n",
        "    å‚æ•°:\n",
        "        rounds: é€šä¿¡è½®æ•°\n",
        "        num_clients: å®¢æˆ·ç«¯æ€»æ•°\n",
        "        sampling_rate: æ¯è½®é‡‡æ ·æ¯”ä¾‹\n",
        "        sparsity: ç¨€ç–åº¦ï¼ˆæ›´æ–°å‚æ•°çš„æ¯”ä¾‹ï¼‰\n",
        "        local_epochs: æœ¬åœ°è®­ç»ƒè½®æ•°\n",
        "        lr: å­¦ä¹ ç‡\n",
        "    \"\"\"\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"FedAvg + Task Arithmetic\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Clients: {num_clients}, Sampling Rate: {sampling_rate}\")\n",
        "    print(f\"Rounds: {rounds}, Local Epochs: {local_epochs}\")\n",
        "    print(f\"Sparsity: {sparsity}, Learning Rate: {lr}\")\n",
        "    print(f\"Device: {DEVICE}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # æ•°æ®å‡†å¤‡\n",
        "    print(\"Preparing data...\")\n",
        "    builder = FederatedDataBuilder(K=num_clients)\n",
        "    dict_users = builder.get_iid_partition()\n",
        "    builder.verify_partition(dict_users)\n",
        "\n",
        "    test_loader = DataLoader(builder.test_dataset, batch_size=256, shuffle=False)\n",
        "\n",
        "    # åˆå§‹åŒ–å…¨å±€æ¨¡å‹\n",
        "    print(\"\\nInitializing global model...\")\n",
        "    global_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    # æ£€æŸ¥æ¨¡å‹\n",
        "    total_params = sum(p.numel() for p in global_model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in global_model.head.parameters())\n",
        "    print(f\"Total params: {total_params:,}\")\n",
        "    print(f\"Trainable params (head): {trainable_params:,}\")\n",
        "    print(f\"Frozen params (backbone): {total_params - trainable_params:,}\\n\")\n",
        "\n",
        "    history = {\"accuracy\": [], \"loss\": [], \"round\": []}\n",
        "\n",
        "    # è”é‚¦è®­ç»ƒ\n",
        "    m = max(int(sampling_rate * num_clients), 1)\n",
        "    print(f\"Starting training ({m} clients per round)...\\n\")\n",
        "\n",
        "    for r in range(rounds):\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Round {r+1}/{rounds}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        local_weights = []\n",
        "        local_counts = []\n",
        "\n",
        "        # éšæœºé€‰æ‹©å®¢æˆ·ç«¯\n",
        "        selected_clients = np.random.choice(range(num_clients), m, replace=False)\n",
        "        print(f\"Selected clients: {selected_clients[:5]}...\" if m > 5 else f\"Selected clients: {selected_clients}\")\n",
        "\n",
        "        for idx, client_id in enumerate(selected_clients):\n",
        "            print(f\"\\nClient {idx+1}/{m} (ID: {client_id}):\")\n",
        "\n",
        "            # æ·±æ‹·è´å…¨å±€æ¨¡å‹\n",
        "            local_model = copy.deepcopy(global_model)\n",
        "\n",
        "            # æœ¬åœ°è®­ç»ƒ\n",
        "            w, count = local_train_task_arithmetic(\n",
        "                local_model,\n",
        "                builder.train_dataset,\n",
        "                dict_users[client_id],\n",
        "                DEVICE,\n",
        "                sparsity_ratio=sparsity,\n",
        "                local_epochs=local_epochs,\n",
        "                lr=lr\n",
        "            )\n",
        "\n",
        "            local_weights.append(w)\n",
        "            local_counts.append(count)\n",
        "\n",
        "        # FedAvgèšåˆ\n",
        "        print(f\"\\nAggregating {len(local_weights)} local models...\")\n",
        "        global_weights = fed_avg_aggregate(global_model, local_weights, local_counts)\n",
        "        global_model.load_state_dict(global_weights, strict=False)\n",
        "\n",
        "        # å…¨å±€è¯„ä¼°\n",
        "        test_loss, test_acc = evaluate(global_model, test_loader, DEVICE)\n",
        "        history[\"accuracy\"].append(test_acc)\n",
        "        history[\"loss\"].append(test_loss)\n",
        "        history[\"round\"].append(r + 1)\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Round {r+1} Global Results:\")\n",
        "        print(f\"  Test Loss: {test_loss:.4f}\")\n",
        "        print(f\"  Test Accuracy: {test_acc:.2f}%\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "    # æœ€ç»ˆç»“æœ\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Training Complete!\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Final Test Accuracy: {history['accuracy'][-1]:.2f}%\")\n",
        "    print(f\"Best Test Accuracy: {max(history['accuracy']):.2f}%\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    return history, global_model\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6. ä¸»ç¨‹åº\n",
        "# ============================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # æµ‹è¯•ä¸åŒç¨€ç–åº¦\n",
        "    sparsity_values = [0.1, 0.3, 0.5]\n",
        "    results = {}\n",
        "\n",
        "    for sparsity in sparsity_values:\n",
        "        print(f\"\\n\\n{'#'*70}\")\n",
        "        print(f\"# Experiment: Sparsity = {sparsity}\")\n",
        "        print(f\"{'#'*70}\\n\")\n",
        "\n",
        "        history, model = run_fed_task_arithmetic(\n",
        "            rounds=20,\n",
        "            num_clients=100,\n",
        "            sampling_rate=0.1,\n",
        "            sparsity=sparsity,\n",
        "            local_epochs=4,\n",
        "            lr=0.1\n",
        "        )\n",
        "\n",
        "        results[sparsity] = history\n",
        "\n",
        "    # ç»˜åˆ¶å¯¹æ¯”å›¾\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # å‡†ç¡®ç‡å¯¹æ¯”\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for sparsity, history in results.items():\n",
        "        plt.plot(history['round'], history['accuracy'],\n",
        "                marker='o', label=f'Sparsity={sparsity}', linewidth=2)\n",
        "    plt.xlabel('Round', fontsize=12)\n",
        "    plt.ylabel('Test Accuracy (%)', fontsize=12)\n",
        "    plt.title('Task Arithmetic: Impact of Sparsity', fontsize=14, fontweight='bold')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # æŸå¤±å¯¹æ¯”\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for sparsity, history in results.items():\n",
        "        plt.plot(history['round'], history['loss'],\n",
        "                marker='s', label=f'Sparsity={sparsity}', linewidth=2)\n",
        "    plt.xlabel('Round', fontsize=12)\n",
        "    plt.ylabel('Test Loss', fontsize=12)\n",
        "    plt.title('Task Arithmetic: Loss Curves', fontsize=14, fontweight='bold')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('task_arithmetic_comparison.png', dpi=150, bbox_inches='tight')\n",
        "    print(\"\\nâœ“ Figure saved: task_arithmetic_comparison.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # æ‰“å°æ€»ç»“\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"Experiment Summary\")\n",
        "    print(f\"{'='*70}\")\n",
        "    for sparsity, history in results.items():\n",
        "        final_acc = history['accuracy'][-1]\n",
        "        best_acc = max(history['accuracy'])\n",
        "        print(f\"Sparsity {sparsity}: Final={final_acc:.2f}%, Best={best_acc:.2f}%\")\n",
        "    print(f\"{'='*70}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "è”é‚¦Task Arithmeticè¯Šæ–­è„šæœ¬ (æœ€ç»ˆç‰ˆ)\n",
        "ç”¨äºæ’æŸ¥ä¸ºä»€ä¹ˆæ¨¡å‹ç²¾åº¦æä½(~1%)\n",
        "\n",
        "ä½¿ç”¨ DINOCIFAR100 æ¨¡å‹ç±»\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "\n",
        "from preprocessing import FederatedDataBuilder\n",
        "from taskarithmetic import compute_fisher_sensitivity, calibrate_masks\n",
        "\n",
        "# å¯¼å…¥æ¨¡å‹ - å…¼å®¹ä¸åŒçš„å‘½å\n",
        "try:\n",
        "    from fed_avg_iid import DINOCIFAR100Fixed as DINOCIFAR100\n",
        "except ImportError:\n",
        "    from fed_avg_iid import DINOCIFAR100\n",
        "\n",
        "\n",
        "def diagnose_mask_problem(sparsity_ratio=0.1):\n",
        "    \"\"\"\n",
        "    è¯Šæ–­æ©ç æ˜¯å¦è¿‡äºä¸¥æ ¼\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"è¯Šæ–­ 1: æ£€æŸ¥æ©ç ç”Ÿæˆ\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # å‡†å¤‡æ•°æ®\n",
        "    builder = FederatedDataBuilder(K=10)\n",
        "    dict_users = builder.get_iid_partition()\n",
        "\n",
        "    # åˆ›å»ºæ¨¡å‹\n",
        "    model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    # å‡†å¤‡ä¸€ä¸ªå®¢æˆ·ç«¯çš„æ•°æ®\n",
        "    local_subset = Subset(builder.train_dataset, list(dict_users[0]))\n",
        "    local_loader = DataLoader(local_subset, batch_size=32, shuffle=True)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # è®¡ç®—æ•æ„Ÿåº¦\n",
        "    print(f\"\\nè®¡ç®—Fisheræ•æ„Ÿåº¦ (sparsity={sparsity_ratio})...\")\n",
        "    sensitivity_scores = compute_fisher_sensitivity(\n",
        "        model, local_loader, criterion, DEVICE, num_batches=5\n",
        "    )\n",
        "\n",
        "    # ç”Ÿæˆæ©ç \n",
        "    masks = calibrate_masks(\n",
        "        sensitivity_scores,\n",
        "        sparsity_ratio=sparsity_ratio,\n",
        "        keep_least_sensitive=True\n",
        "    )\n",
        "\n",
        "    # åˆ†ææ©ç \n",
        "    print(\"\\næ©ç ç»Ÿè®¡:\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    total_params = 0\n",
        "    frozen_params = 0\n",
        "    active_params = 0\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            mask = masks.get(param)\n",
        "            if mask is not None:\n",
        "                num_params = int(param.numel())\n",
        "                num_active = int(mask.sum().item())\n",
        "                num_frozen = num_params - num_active\n",
        "\n",
        "                total_params += num_params\n",
        "                frozen_params += num_frozen\n",
        "                active_params += num_active\n",
        "\n",
        "                active_ratio = 100 * num_active / num_params\n",
        "                print(f\"{name:30s} | Total: {num_params:8d} | \"\n",
        "                      f\"Active: {num_active:8d} ({active_ratio:5.1f}%) | \"\n",
        "                      f\"Frozen: {num_frozen:8d}\")\n",
        "\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"{'æ€»è®¡':30s} | Total: {total_params:8d} | \"\n",
        "          f\"Active: {active_params:8d} ({100*active_params/total_params:5.1f}%) | \"\n",
        "          f\"Frozen: {frozen_params:8d}\")\n",
        "\n",
        "    # å…³é”®æ£€æŸ¥\n",
        "    if active_params == 0:\n",
        "        print(\"\\nâŒ ä¸¥é‡é”™è¯¯: æ‰€æœ‰å‚æ•°éƒ½è¢«å†»ç»“!\")\n",
        "        print(\"   - æ¨¡å‹æ— æ³•å­¦ä¹ \")\n",
        "        print(\"   - éœ€è¦æ£€æŸ¥calibrate_maskså®ç°\")\n",
        "        return False\n",
        "\n",
        "    if active_params < total_params * 0.01:  # å°äº1%\n",
        "        print(\"\\nâš ï¸  è­¦å‘Š: å¯æ›´æ–°å‚æ•°è¿‡å°‘!\")\n",
        "        print(f\"   - åªæœ‰{100*active_params/total_params:.2f}%çš„å‚æ•°å¯ä»¥æ›´æ–°\")\n",
        "        print(\"   - å»ºè®®å¢å¤§sparsity_ratio\")\n",
        "        return False\n",
        "\n",
        "    print(\"\\nâœ“ æ©ç ç”Ÿæˆæ­£å¸¸\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def diagnose_training_step():\n",
        "    \"\"\"\n",
        "    è¯Šæ–­å•æ­¥è®­ç»ƒæ˜¯å¦æ­£å¸¸\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"è¯Šæ–­ 2: æ£€æŸ¥è®­ç»ƒæ­¥éª¤\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # å‡†å¤‡æ•°æ®\n",
        "    builder = FederatedDataBuilder(K=10)\n",
        "    dict_users = builder.get_iid_partition()\n",
        "\n",
        "    # åˆ›å»ºæ¨¡å‹\n",
        "    model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    # æ£€æŸ¥backboneæ˜¯å¦å†»ç»“\n",
        "    print(\"\\næ£€æŸ¥backboneå†»ç»“çŠ¶æ€:\")\n",
        "    backbone_params_trainable = sum(p.requires_grad for p in model.backbone.parameters())\n",
        "    print(f\"Backboneå¯è®­ç»ƒå‚æ•°æ•°: {backbone_params_trainable}\")\n",
        "    if backbone_params_trainable > 0:\n",
        "        print(\"âŒ é”™è¯¯: Backboneåº”è¯¥è¢«å®Œå…¨å†»ç»“!\")\n",
        "        return False\n",
        "    print(\"âœ“ Backboneå·²æ­£ç¡®å†»ç»“\")\n",
        "\n",
        "    # æ£€æŸ¥head\n",
        "    print(\"\\nHeadå‚æ•°:\")\n",
        "    for name, param in model.head.named_parameters():\n",
        "        print(f\"  {name}: requires_grad={param.requires_grad}, shape={param.shape}\")\n",
        "\n",
        "    # å‡†å¤‡æœ¬åœ°æ•°æ®\n",
        "    local_subset = Subset(builder.train_dataset, list(dict_users[0]))\n",
        "    local_loader = DataLoader(local_subset, batch_size=32, shuffle=True)\n",
        "\n",
        "    # è·å–ä¸€ä¸ªbatch\n",
        "    inputs, targets = next(iter(local_loader))\n",
        "    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "    # å‰å‘ä¼ æ’­\n",
        "    print(\"\\næµ‹è¯•å‰å‘ä¼ æ’­:\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs)\n",
        "        print(f\"  è¾“å‡ºå½¢çŠ¶: {outputs.shape}\")\n",
        "        print(f\"  è¾“å‡ºèŒƒå›´: [{outputs.min().item():.2f}, {outputs.max().item():.2f}]\")\n",
        "\n",
        "        # æ£€æŸ¥åˆå§‹ç²¾åº¦\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct = predicted.eq(targets).sum().item()\n",
        "        acc = 100. * correct / targets.size(0)\n",
        "        print(f\"  åˆå§‹ç²¾åº¦ (éšæœº): {acc:.2f}%\")\n",
        "\n",
        "        if acc < 0.5 or acc > 5:\n",
        "            print(f\"  âš ï¸  è­¦å‘Š: åˆå§‹ç²¾åº¦å¼‚å¸¸ (æœŸæœ›~1%)\")\n",
        "\n",
        "    # æµ‹è¯•åå‘ä¼ æ’­\n",
        "    print(\"\\næµ‹è¯•åå‘ä¼ æ’­:\")\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # è®°å½•åˆå§‹æƒé‡\n",
        "    initial_weight = model.head.weight.clone()\n",
        "\n",
        "    # è®­ç»ƒä¸€æ­¥\n",
        "    optimizer = torch.optim.SGD(model.head.parameters(), lr=0.1)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "\n",
        "    # æ£€æŸ¥æ¢¯åº¦\n",
        "    if model.head.weight.grad is None:\n",
        "        print(\"  âŒ é”™è¯¯: æ²¡æœ‰è®¡ç®—æ¢¯åº¦!\")\n",
        "        return False\n",
        "\n",
        "    grad_norm = model.head.weight.grad.norm().item()\n",
        "    print(f\"  æ¢¯åº¦èŒƒæ•°: {grad_norm:.4f}\")\n",
        "\n",
        "    if grad_norm < 1e-6:\n",
        "        print(\"  âš ï¸  è­¦å‘Š: æ¢¯åº¦è¿‡å°\")\n",
        "\n",
        "    # æ›´æ–°æƒé‡\n",
        "    optimizer.step()\n",
        "\n",
        "    # æ£€æŸ¥æƒé‡æ˜¯å¦æ”¹å˜\n",
        "    weight_change = (model.head.weight - initial_weight).abs().max().item()\n",
        "    print(f\"  æƒé‡æœ€å¤§å˜åŒ–: {weight_change:.6f}\")\n",
        "\n",
        "    if weight_change < 1e-8:\n",
        "        print(\"  âŒ é”™è¯¯: æƒé‡æ²¡æœ‰æ›´æ–°!\")\n",
        "        return False\n",
        "\n",
        "    print(\"  âœ“ è®­ç»ƒæ­¥éª¤æ­£å¸¸\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def diagnose_aggregation():\n",
        "    \"\"\"\n",
        "    è¯Šæ–­èšåˆæ˜¯å¦æ­£å¸¸\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"è¯Šæ–­ 3: æ£€æŸ¥FedAvgèšåˆ\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    from fed_avg_iid import fed_avg_aggregate\n",
        "\n",
        "    # åˆ›å»ºå…¨å±€æ¨¡å‹\n",
        "    global_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    # åˆ›å»ºä¸¤ä¸ªæ¨¡æ‹Ÿçš„æœ¬åœ°æ¨¡å‹æƒé‡\n",
        "    local_weights = []\n",
        "\n",
        "    for i in range(2):\n",
        "        local_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "        # éšæœºä¿®æ”¹æƒé‡\n",
        "        with torch.no_grad():\n",
        "            local_model.head.weight += torch.randn_like(local_model.head.weight) * 0.1\n",
        "        local_weights.append(local_model.state_dict())\n",
        "\n",
        "    client_counts = [100, 100]\n",
        "\n",
        "    # æ‰§è¡Œèšåˆ\n",
        "    print(\"\\næ‰§è¡Œèšåˆ...\")\n",
        "    global_weight_before = global_model.head.weight.clone()\n",
        "\n",
        "    new_weights = fed_avg_aggregate(global_model, local_weights, client_counts)\n",
        "    global_model.load_state_dict(new_weights, strict=False)\n",
        "\n",
        "    global_weight_after = global_model.head.weight\n",
        "\n",
        "    # æ£€æŸ¥æƒé‡æ˜¯å¦æ”¹å˜\n",
        "    weight_change = (global_weight_after - global_weight_before).abs().max().item()\n",
        "    print(f\"å…¨å±€æ¨¡å‹æƒé‡æœ€å¤§å˜åŒ–: {weight_change:.6f}\")\n",
        "\n",
        "    if weight_change < 1e-8:\n",
        "        print(\"âŒ é”™è¯¯: èšåˆåå…¨å±€æ¨¡å‹æƒé‡æ²¡æœ‰æ”¹å˜!\")\n",
        "        return False\n",
        "\n",
        "    print(\"âœ“ èšåˆæ­£å¸¸\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def test_without_task_arithmetic():\n",
        "    \"\"\"\n",
        "    æµ‹è¯•ä¸ä½¿ç”¨Task Arithmeticçš„æ ‡å‡†FedAvg\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"è¯Šæ–­ 4: æµ‹è¯•æ ‡å‡†FedAvg (æ— Task Arithmetic)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # æ•°æ®å‡†å¤‡\n",
        "    builder = FederatedDataBuilder(K=10)\n",
        "    dict_users = builder.get_iid_partition()\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        builder.test_dataset,\n",
        "        batch_size=256,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # å…¨å±€æ¨¡å‹\n",
        "    global_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    from fed_avg_iid import fed_avg_aggregate, evaluate_global\n",
        "\n",
        "    print(\"\\nè¿è¡Œ3è½®æ ‡å‡†FedAvg...\")\n",
        "\n",
        "    for r in range(3):\n",
        "        # é€‰æ‹©2ä¸ªå®¢æˆ·ç«¯\n",
        "        selected_clients = np.random.choice(range(10), 2, replace=False)\n",
        "\n",
        "        local_weights = []\n",
        "        client_counts = []\n",
        "\n",
        "        for client_idx in selected_clients:\n",
        "            # æœ¬åœ°è®­ç»ƒ\n",
        "            local_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "            local_model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "            local_subset = Subset(builder.train_dataset, list(dict_users[client_idx]))\n",
        "            local_loader = DataLoader(local_subset, batch_size=32, shuffle=True)\n",
        "\n",
        "            optimizer = torch.optim.SGD(local_model.head.parameters(), lr=0.1, momentum=0.9)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            local_model.train()\n",
        "            step_count = 0\n",
        "            iterator = iter(local_loader)\n",
        "\n",
        "            # æ­£ç¡®å®ç°J=4æ­¥\n",
        "            while step_count < 4:\n",
        "                try:\n",
        "                    inputs, targets = next(iterator)\n",
        "                    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = local_model(inputs)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    step_count += 1\n",
        "                except StopIteration:\n",
        "                    break\n",
        "\n",
        "            local_weights.append(local_model.state_dict())\n",
        "            client_counts.append(len(dict_users[client_idx]))\n",
        "\n",
        "        # èšåˆ\n",
        "        new_weights = fed_avg_aggregate(global_model, local_weights, client_counts)\n",
        "        global_model.load_state_dict(new_weights, strict=False)\n",
        "\n",
        "        # è¯„ä¼°\n",
        "        test_loss, test_acc = evaluate_global(global_model, test_loader, DEVICE)\n",
        "        print(f\"Round {r+1}: Test Acc = {test_acc:.2f}%\")\n",
        "\n",
        "        if test_acc < 1.0:\n",
        "            print(\"  âš ï¸  ç²¾åº¦ä»ç„¶è¿‡ä½!\")\n",
        "        elif test_acc > 3.0:\n",
        "            print(\"  âœ“ ç²¾åº¦å¼€å§‹æå‡,åŸºç¡€æµç¨‹æ­£å¸¸\")\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    è¿è¡Œæ‰€æœ‰è¯Šæ–­\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"ğŸ”\"*35)\n",
        "    print(\"      è”é‚¦Task Arithmetic è¯Šæ–­å·¥å…·\")\n",
        "    print(\"ğŸ”\"*35)\n",
        "\n",
        "    # è¯Šæ–­1: æ©ç \n",
        "    mask_ok = diagnose_mask_problem(sparsity_ratio=0.1)\n",
        "\n",
        "    # è¯Šæ–­2: è®­ç»ƒæ­¥éª¤\n",
        "    training_ok = diagnose_training_step()\n",
        "\n",
        "    # è¯Šæ–­3: èšåˆ\n",
        "    aggregation_ok = diagnose_aggregation()\n",
        "\n",
        "    # è¯Šæ–­4: æ— TAçš„FedAvg\n",
        "    fedavg_ok = test_without_task_arithmetic()\n",
        "\n",
        "    # æ€»ç»“\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"è¯Šæ–­æ€»ç»“\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"1. æ©ç ç”Ÿæˆ: {'âœ“ æ­£å¸¸' if mask_ok else 'âŒ å¼‚å¸¸'}\")\n",
        "    print(f\"2. è®­ç»ƒæ­¥éª¤: {'âœ“ æ­£å¸¸' if training_ok else 'âŒ å¼‚å¸¸'}\")\n",
        "    print(f\"3. FedAvgèšåˆ: {'âœ“ æ­£å¸¸' if aggregation_ok else 'âŒ å¼‚å¸¸'}\")\n",
        "    print(f\"4. æ ‡å‡†FedAvg: {'âœ“ æ­£å¸¸' if fedavg_ok else 'âŒ å¼‚å¸¸'}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"å»ºè®®:\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    if not mask_ok:\n",
        "        print(\"1. æ£€æŸ¥calibrate_maskså‡½æ•°å®ç°\")\n",
        "        print(\"2. å°è¯•æ›´å¤§çš„sparsity_ratio (å¦‚0.5)\")\n",
        "        print(\"3. ç¡®è®¤keep_least_sensitiveé€»è¾‘æ­£ç¡®\")\n",
        "\n",
        "    if not training_ok:\n",
        "        print(\"1. æ£€æŸ¥æ¨¡å‹åˆå§‹åŒ–\")\n",
        "        print(\"2. ç¡®è®¤backboneæ­£ç¡®å†»ç»“\")\n",
        "        print(\"3. è°ƒæ•´å­¦ä¹ ç‡\")\n",
        "\n",
        "    if not fedavg_ok:\n",
        "        print(\"1. åŸºç¡€FedAvgå°±æœ‰é—®é¢˜,å…ˆä¿®å¤å®ƒ\")\n",
        "        print(\"2. æ£€æŸ¥æ•°æ®åŠ è½½\")\n",
        "        print(\"3. å¢åŠ æœ¬åœ°è®­ç»ƒæ­¥æ•°\")\n",
        "\n",
        "    if mask_ok and training_ok and aggregation_ok and not fedavg_ok:\n",
        "        print(\"1. é—®é¢˜å¯èƒ½åœ¨æ•°æ®å¤„ç†æˆ–æ¨¡å‹æ¶æ„\")\n",
        "        print(\"2. å°è¯•è¿è¡Œfed_avg_iid.pyçœ‹æ˜¯å¦æ­£å¸¸\")\n",
        "\n",
        "    print(\"\\nğŸ’¡ å¿«é€Ÿä¿®å¤å»ºè®®:\")\n",
        "    print(\"   - å…ˆç¡®ä¿æ ‡å‡†FedAvgèƒ½work (ç²¾åº¦>5%)\")\n",
        "    print(\"   - å†åŠ å…¥Task Arithmetic\")\n",
        "    print(\"   - ä½¿ç”¨è¾ƒå¤§çš„sparsity_ratioå¼€å§‹æµ‹è¯•\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24MgjhUNTAQh",
        "outputId": "8c59d3c7-d232-4177-8ec7-91376c025610"
      },
      "id": "24MgjhUNTAQh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”\n",
            "      è”é‚¦Task Arithmetic è¯Šæ–­å·¥å…·\n",
            "ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”\n",
            "\n",
            "======================================================================\n",
            "è¯Šæ–­ 1: æ£€æŸ¥æ©ç ç”Ÿæˆ\n",
            "======================================================================\n",
            "Creating IID partition for 10 clients...\n",
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "è®¡ç®—Fisheræ•æ„Ÿåº¦ (sparsity=0.1)...\n",
            "Calculating sensitivity over 5 batches...\n",
            "\n",
            "æ©ç ç»Ÿè®¡:\n",
            "----------------------------------------------------------------------\n",
            "backbone.cls_token             | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.pos_embed             | Total:    75648 | Active:      316 (  0.4%) | Frozen:    75332\n",
            "backbone.patch_embed.proj.weight | Total:   294912 | Active:        0 (  0.0%) | Frozen:   294912\n",
            "backbone.patch_embed.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.0.norm1.weight | Total:      384 | Active:      207 ( 53.9%) | Frozen:      177\n",
            "backbone.blocks.0.norm1.bias   | Total:      384 | Active:       44 ( 11.5%) | Frozen:      340\n",
            "backbone.blocks.0.attn.qkv.weight | Total:   442368 | Active:   351693 ( 79.5%) | Frozen:    90675\n",
            "backbone.blocks.0.attn.qkv.bias | Total:     1152 | Active:      685 ( 59.5%) | Frozen:      467\n",
            "backbone.blocks.0.attn.proj.weight | Total:   147456 | Active:    50960 ( 34.6%) | Frozen:    96496\n",
            "backbone.blocks.0.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.0.norm2.weight | Total:      384 | Active:      167 ( 43.5%) | Frozen:      217\n",
            "backbone.blocks.0.norm2.bias   | Total:      384 | Active:       81 ( 21.1%) | Frozen:      303\n",
            "backbone.blocks.0.mlp.fc1.weight | Total:   589824 | Active:   160498 ( 27.2%) | Frozen:   429326\n",
            "backbone.blocks.0.mlp.fc1.bias | Total:     1536 | Active:      416 ( 27.1%) | Frozen:     1120\n",
            "backbone.blocks.0.mlp.fc2.weight | Total:   589824 | Active:     3503 (  0.6%) | Frozen:   586321\n",
            "backbone.blocks.0.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.1.norm1.weight | Total:      384 | Active:      177 ( 46.1%) | Frozen:      207\n",
            "backbone.blocks.1.norm1.bias   | Total:      384 | Active:       19 (  4.9%) | Frozen:      365\n",
            "backbone.blocks.1.attn.qkv.weight | Total:   442368 | Active:   256093 ( 57.9%) | Frozen:   186275\n",
            "backbone.blocks.1.attn.qkv.bias | Total:     1152 | Active:      729 ( 63.3%) | Frozen:      423\n",
            "backbone.blocks.1.attn.proj.weight | Total:   147456 | Active:     6124 (  4.2%) | Frozen:   141332\n",
            "backbone.blocks.1.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.1.norm2.weight | Total:      384 | Active:      228 ( 59.4%) | Frozen:      156\n",
            "backbone.blocks.1.norm2.bias   | Total:      384 | Active:       81 ( 21.1%) | Frozen:      303\n",
            "backbone.blocks.1.mlp.fc1.weight | Total:   589824 | Active:    42255 (  7.2%) | Frozen:   547569\n",
            "backbone.blocks.1.mlp.fc1.bias | Total:     1536 | Active:      105 (  6.8%) | Frozen:     1431\n",
            "backbone.blocks.1.mlp.fc2.weight | Total:   589824 | Active:      446 (  0.1%) | Frozen:   589378\n",
            "backbone.blocks.1.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.2.norm1.weight | Total:      384 | Active:      125 ( 32.6%) | Frozen:      259\n",
            "backbone.blocks.2.norm1.bias   | Total:      384 | Active:        4 (  1.0%) | Frozen:      380\n",
            "backbone.blocks.2.attn.qkv.weight | Total:   442368 | Active:   194159 ( 43.9%) | Frozen:   248209\n",
            "backbone.blocks.2.attn.qkv.bias | Total:     1152 | Active:      679 ( 58.9%) | Frozen:      473\n",
            "backbone.blocks.2.attn.proj.weight | Total:   147456 | Active:      230 (  0.2%) | Frozen:   147226\n",
            "backbone.blocks.2.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.2.norm2.weight | Total:      384 | Active:      161 ( 41.9%) | Frozen:      223\n",
            "backbone.blocks.2.norm2.bias   | Total:      384 | Active:       15 (  3.9%) | Frozen:      369\n",
            "backbone.blocks.2.mlp.fc1.weight | Total:   589824 | Active:    13375 (  2.3%) | Frozen:   576449\n",
            "backbone.blocks.2.mlp.fc1.bias | Total:     1536 | Active:       26 (  1.7%) | Frozen:     1510\n",
            "backbone.blocks.2.mlp.fc2.weight | Total:   589824 | Active:      306 (  0.1%) | Frozen:   589518\n",
            "backbone.blocks.2.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.3.norm1.weight | Total:      384 | Active:      136 ( 35.4%) | Frozen:      248\n",
            "backbone.blocks.3.norm1.bias   | Total:      384 | Active:        4 (  1.0%) | Frozen:      380\n",
            "backbone.blocks.3.attn.qkv.weight | Total:   442368 | Active:   138281 ( 31.3%) | Frozen:   304087\n",
            "backbone.blocks.3.attn.qkv.bias | Total:     1152 | Active:      593 ( 51.5%) | Frozen:      559\n",
            "backbone.blocks.3.attn.proj.weight | Total:   147456 | Active:       76 (  0.1%) | Frozen:   147380\n",
            "backbone.blocks.3.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.3.norm2.weight | Total:      384 | Active:      121 ( 31.5%) | Frozen:      263\n",
            "backbone.blocks.3.norm2.bias   | Total:      384 | Active:        3 (  0.8%) | Frozen:      381\n",
            "backbone.blocks.3.mlp.fc1.weight | Total:   589824 | Active:    11443 (  1.9%) | Frozen:   578381\n",
            "backbone.blocks.3.mlp.fc1.bias | Total:     1536 | Active:       44 (  2.9%) | Frozen:     1492\n",
            "backbone.blocks.3.mlp.fc2.weight | Total:   589824 | Active:       24 (  0.0%) | Frozen:   589800\n",
            "backbone.blocks.3.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.4.norm1.weight | Total:      384 | Active:      100 ( 26.0%) | Frozen:      284\n",
            "backbone.blocks.4.norm1.bias   | Total:      384 | Active:        4 (  1.0%) | Frozen:      380\n",
            "backbone.blocks.4.attn.qkv.weight | Total:   442368 | Active:    94084 ( 21.3%) | Frozen:   348284\n",
            "backbone.blocks.4.attn.qkv.bias | Total:     1152 | Active:      498 ( 43.2%) | Frozen:      654\n",
            "backbone.blocks.4.attn.proj.weight | Total:   147456 | Active:        8 (  0.0%) | Frozen:   147448\n",
            "backbone.blocks.4.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.4.norm2.weight | Total:      384 | Active:      108 ( 28.1%) | Frozen:      276\n",
            "backbone.blocks.4.norm2.bias   | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.4.mlp.fc1.weight | Total:   589824 | Active:    14884 (  2.5%) | Frozen:   574940\n",
            "backbone.blocks.4.mlp.fc1.bias | Total:     1536 | Active:       77 (  5.0%) | Frozen:     1459\n",
            "backbone.blocks.4.mlp.fc2.weight | Total:   589824 | Active:      651 (  0.1%) | Frozen:   589173\n",
            "backbone.blocks.4.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.5.norm1.weight | Total:      384 | Active:      103 ( 26.8%) | Frozen:      281\n",
            "backbone.blocks.5.norm1.bias   | Total:      384 | Active:        2 (  0.5%) | Frozen:      382\n",
            "backbone.blocks.5.attn.qkv.weight | Total:   442368 | Active:    57751 ( 13.1%) | Frozen:   384617\n",
            "backbone.blocks.5.attn.qkv.bias | Total:     1152 | Active:      527 ( 45.7%) | Frozen:      625\n",
            "backbone.blocks.5.attn.proj.weight | Total:   147456 | Active:       10 (  0.0%) | Frozen:   147446\n",
            "backbone.blocks.5.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.5.norm2.weight | Total:      384 | Active:      136 ( 35.4%) | Frozen:      248\n",
            "backbone.blocks.5.norm2.bias   | Total:      384 | Active:        6 (  1.6%) | Frozen:      378\n",
            "backbone.blocks.5.mlp.fc1.weight | Total:   589824 | Active:    15229 (  2.6%) | Frozen:   574595\n",
            "backbone.blocks.5.mlp.fc1.bias | Total:     1536 | Active:      125 (  8.1%) | Frozen:     1411\n",
            "backbone.blocks.5.mlp.fc2.weight | Total:   589824 | Active:      976 (  0.2%) | Frozen:   588848\n",
            "backbone.blocks.5.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.6.norm1.weight | Total:      384 | Active:      107 ( 27.9%) | Frozen:      277\n",
            "backbone.blocks.6.norm1.bias   | Total:      384 | Active:        6 (  1.6%) | Frozen:      378\n",
            "backbone.blocks.6.attn.qkv.weight | Total:   442368 | Active:    52698 ( 11.9%) | Frozen:   389670\n",
            "backbone.blocks.6.attn.qkv.bias | Total:     1152 | Active:      466 ( 40.5%) | Frozen:      686\n",
            "backbone.blocks.6.attn.proj.weight | Total:   147456 | Active:        1 (  0.0%) | Frozen:   147455\n",
            "backbone.blocks.6.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.6.norm2.weight | Total:      384 | Active:      162 ( 42.2%) | Frozen:      222\n",
            "backbone.blocks.6.norm2.bias   | Total:      384 | Active:       18 (  4.7%) | Frozen:      366\n",
            "backbone.blocks.6.mlp.fc1.weight | Total:   589824 | Active:     8376 (  1.4%) | Frozen:   581448\n",
            "backbone.blocks.6.mlp.fc1.bias | Total:     1536 | Active:      153 ( 10.0%) | Frozen:     1383\n",
            "backbone.blocks.6.mlp.fc2.weight | Total:   589824 | Active:     1502 (  0.3%) | Frozen:   588322\n",
            "backbone.blocks.6.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.7.norm1.weight | Total:      384 | Active:      114 ( 29.7%) | Frozen:      270\n",
            "backbone.blocks.7.norm1.bias   | Total:      384 | Active:       13 (  3.4%) | Frozen:      371\n",
            "backbone.blocks.7.attn.qkv.weight | Total:   442368 | Active:    41040 (  9.3%) | Frozen:   401328\n",
            "backbone.blocks.7.attn.qkv.bias | Total:     1152 | Active:      521 ( 45.2%) | Frozen:      631\n",
            "backbone.blocks.7.attn.proj.weight | Total:   147456 | Active:        4 (  0.0%) | Frozen:   147452\n",
            "backbone.blocks.7.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.7.norm2.weight | Total:      384 | Active:      226 ( 58.9%) | Frozen:      158\n",
            "backbone.blocks.7.norm2.bias   | Total:      384 | Active:       70 ( 18.2%) | Frozen:      314\n",
            "backbone.blocks.7.mlp.fc1.weight | Total:   589824 | Active:     7998 (  1.4%) | Frozen:   581826\n",
            "backbone.blocks.7.mlp.fc1.bias | Total:     1536 | Active:      205 ( 13.3%) | Frozen:     1331\n",
            "backbone.blocks.7.mlp.fc2.weight | Total:   589824 | Active:     1180 (  0.2%) | Frozen:   588644\n",
            "backbone.blocks.7.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.8.norm1.weight | Total:      384 | Active:      151 ( 39.3%) | Frozen:      233\n",
            "backbone.blocks.8.norm1.bias   | Total:      384 | Active:       23 (  6.0%) | Frozen:      361\n",
            "backbone.blocks.8.attn.qkv.weight | Total:   442368 | Active:    23144 (  5.2%) | Frozen:   419224\n",
            "backbone.blocks.8.attn.qkv.bias | Total:     1152 | Active:      497 ( 43.1%) | Frozen:      655\n",
            "backbone.blocks.8.attn.proj.weight | Total:   147456 | Active:        0 (  0.0%) | Frozen:   147456\n",
            "backbone.blocks.8.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.8.norm2.weight | Total:      384 | Active:      315 ( 82.0%) | Frozen:       69\n",
            "backbone.blocks.8.norm2.bias   | Total:      384 | Active:      133 ( 34.6%) | Frozen:      251\n",
            "backbone.blocks.8.mlp.fc1.weight | Total:   589824 | Active:    10261 (  1.7%) | Frozen:   579563\n",
            "backbone.blocks.8.mlp.fc1.bias | Total:     1536 | Active:      280 ( 18.2%) | Frozen:     1256\n",
            "backbone.blocks.8.mlp.fc2.weight | Total:   589824 | Active:     2751 (  0.5%) | Frozen:   587073\n",
            "backbone.blocks.8.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.9.norm1.weight | Total:      384 | Active:      163 ( 42.4%) | Frozen:      221\n",
            "backbone.blocks.9.norm1.bias   | Total:      384 | Active:       22 (  5.7%) | Frozen:      362\n",
            "backbone.blocks.9.attn.qkv.weight | Total:   442368 | Active:    13536 (  3.1%) | Frozen:   428832\n",
            "backbone.blocks.9.attn.qkv.bias | Total:     1152 | Active:      556 ( 48.3%) | Frozen:      596\n",
            "backbone.blocks.9.attn.proj.weight | Total:   147456 | Active:        0 (  0.0%) | Frozen:   147456\n",
            "backbone.blocks.9.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.9.norm2.weight | Total:      384 | Active:      381 ( 99.2%) | Frozen:        3\n",
            "backbone.blocks.9.norm2.bias   | Total:      384 | Active:      384 (100.0%) | Frozen:        0\n",
            "backbone.blocks.9.mlp.fc1.weight | Total:   589824 | Active:    81918 ( 13.9%) | Frozen:   507906\n",
            "backbone.blocks.9.mlp.fc1.bias | Total:     1536 | Active:     1327 ( 86.4%) | Frozen:      209\n",
            "backbone.blocks.9.mlp.fc2.weight | Total:   589824 | Active:   198911 ( 33.7%) | Frozen:   390913\n",
            "backbone.blocks.9.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.10.norm1.weight | Total:      384 | Active:      138 ( 35.9%) | Frozen:      246\n",
            "backbone.blocks.10.norm1.bias  | Total:      384 | Active:        2 (  0.5%) | Frozen:      382\n",
            "backbone.blocks.10.attn.qkv.weight | Total:   442368 | Active:    11979 (  2.7%) | Frozen:   430389\n",
            "backbone.blocks.10.attn.qkv.bias | Total:     1152 | Active:      559 ( 48.5%) | Frozen:      593\n",
            "backbone.blocks.10.attn.proj.weight | Total:   147456 | Active:        3 (  0.0%) | Frozen:   147453\n",
            "backbone.blocks.10.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.10.norm2.weight | Total:      384 | Active:      315 ( 82.0%) | Frozen:       69\n",
            "backbone.blocks.10.norm2.bias  | Total:      384 | Active:      223 ( 58.1%) | Frozen:      161\n",
            "backbone.blocks.10.mlp.fc1.weight | Total:   589824 | Active:    31819 (  5.4%) | Frozen:   558005\n",
            "backbone.blocks.10.mlp.fc1.bias | Total:     1536 | Active:      539 ( 35.1%) | Frozen:      997\n",
            "backbone.blocks.10.mlp.fc2.weight | Total:   589824 | Active:    27230 (  4.6%) | Frozen:   562594\n",
            "backbone.blocks.10.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.11.norm1.weight | Total:      384 | Active:      109 ( 28.4%) | Frozen:      275\n",
            "backbone.blocks.11.norm1.bias  | Total:      384 | Active:        4 (  1.0%) | Frozen:      380\n",
            "backbone.blocks.11.attn.qkv.weight | Total:   442368 | Active:    13995 (  3.2%) | Frozen:   428373\n",
            "backbone.blocks.11.attn.qkv.bias | Total:     1152 | Active:      424 ( 36.8%) | Frozen:      728\n",
            "backbone.blocks.11.attn.proj.weight | Total:   147456 | Active:        4 (  0.0%) | Frozen:   147452\n",
            "backbone.blocks.11.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.11.norm2.weight | Total:      384 | Active:      335 ( 87.2%) | Frozen:       49\n",
            "backbone.blocks.11.norm2.bias  | Total:      384 | Active:      307 ( 79.9%) | Frozen:       77\n",
            "backbone.blocks.11.mlp.fc1.weight | Total:   589824 | Active:    99344 ( 16.8%) | Frozen:   490480\n",
            "backbone.blocks.11.mlp.fc1.bias | Total:     1536 | Active:      797 ( 51.9%) | Frozen:      739\n",
            "backbone.blocks.11.mlp.fc2.weight | Total:   589824 | Active:   109163 ( 18.5%) | Frozen:   480661\n",
            "backbone.blocks.11.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.norm.weight           | Total:      384 | Active:        6 (  1.6%) | Frozen:      378\n",
            "backbone.norm.bias             | Total:      384 | Active:        2 (  0.5%) | Frozen:      382\n",
            "head.weight                    | Total:    38400 | Active:     3582 (  9.3%) | Frozen:    34818\n",
            "head.bias                      | Total:      100 | Active:       13 ( 13.0%) | Frozen:       87\n",
            "----------------------------------------------------------------------\n",
            "æ€»è®¡                             | Total: 21704164 | Active:  2170416 ( 10.0%) | Frozen: 19533748\n",
            "\n",
            "âœ“ æ©ç ç”Ÿæˆæ­£å¸¸\n",
            "\n",
            "======================================================================\n",
            "è¯Šæ–­ 2: æ£€æŸ¥è®­ç»ƒæ­¥éª¤\n",
            "======================================================================\n",
            "Creating IID partition for 10 clients...\n",
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "æ£€æŸ¥backboneå†»ç»“çŠ¶æ€:\n",
            "Backboneå¯è®­ç»ƒå‚æ•°æ•°: 150\n",
            "âŒ é”™è¯¯: Backboneåº”è¯¥è¢«å®Œå…¨å†»ç»“!\n",
            "\n",
            "======================================================================\n",
            "è¯Šæ–­ 3: æ£€æŸ¥FedAvgèšåˆ\n",
            "======================================================================\n",
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "æ‰§è¡Œèšåˆ...\n",
            "å…¨å±€æ¨¡å‹æƒé‡æœ€å¤§å˜åŒ–: 0.325009\n",
            "âœ“ èšåˆæ­£å¸¸\n",
            "\n",
            "======================================================================\n",
            "è¯Šæ–­ 4: æµ‹è¯•æ ‡å‡†FedAvg (æ— Task Arithmetic)\n",
            "======================================================================\n",
            "Creating IID partition for 10 clients...\n",
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "è¿è¡Œ3è½®æ ‡å‡†FedAvg...\n",
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1: Test Acc = 6.55%\n",
            "  âœ“ ç²¾åº¦å¼€å§‹æå‡,åŸºç¡€æµç¨‹æ­£å¸¸\n",
            "\n",
            "======================================================================\n",
            "è¯Šæ–­æ€»ç»“\n",
            "======================================================================\n",
            "1. æ©ç ç”Ÿæˆ: âœ“ æ­£å¸¸\n",
            "2. è®­ç»ƒæ­¥éª¤: âŒ å¼‚å¸¸\n",
            "3. FedAvgèšåˆ: âœ“ æ­£å¸¸\n",
            "4. æ ‡å‡†FedAvg: âœ“ æ­£å¸¸\n",
            "\n",
            "======================================================================\n",
            "å»ºè®®:\n",
            "======================================================================\n",
            "1. æ£€æŸ¥æ¨¡å‹åˆå§‹åŒ–\n",
            "2. ç¡®è®¤backboneæ­£ç¡®å†»ç»“\n",
            "3. è°ƒæ•´å­¦ä¹ ç‡\n",
            "\n",
            "ğŸ’¡ å¿«é€Ÿä¿®å¤å»ºè®®:\n",
            "   - å…ˆç¡®ä¿æ ‡å‡†FedAvgèƒ½work (ç²¾åº¦>5%)\n",
            "   - å†åŠ å…¥Task Arithmetic\n",
            "   - ä½¿ç”¨è¾ƒå¤§çš„sparsity_ratioå¼€å§‹æµ‹è¯•\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}