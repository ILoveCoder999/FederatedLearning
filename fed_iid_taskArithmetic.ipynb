{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "47c918b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47c918b0",
        "outputId": "dce94327-0b4a-47c3-a598-88eda839f36d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# import module\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive')\n",
        "from preprocessing import FederatedDataBuilder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "69aac5f0",
      "metadata": {
        "id": "69aac5f0"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from preprocessing import FederatedDataBuilder\n",
        "from taskarithmetic import SparseSGDM, compute_fisher_sensitivity, calibrate_masks\n",
        "from fed_avg_iid import DINOCIFAR100, fed_avg_aggregate # å¤ç”¨ä½ ä¹‹å‰çš„æ¨¡å‹å’Œèšåˆå‡½æ•°\n",
        "\n",
        "# ============================================================\n",
        "# 1. æœ¬åœ°è®­ç»ƒå‡½æ•° (é›†æˆäº† Task Arithmetic)\n",
        "# ============================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from taskarithmetic import SparseSGDM, compute_fisher_sensitivity, calibrate_masks\n",
        "\n",
        "def _split_head_and_backbone_params(model):\n",
        "    head_params, backbone_params = [], []\n",
        "    head_names = []\n",
        "    for name, p in model.named_parameters():\n",
        "        if not p.requires_grad:\n",
        "            continue\n",
        "        # é€‚é…å¸¸è§å‘½åï¼šhead / classifier / fc\n",
        "        if (\"head\" in name) or (\"classifier\" in name) or (name.endswith(\".fc.weight\") or name.endswith(\".fc.bias\")):\n",
        "            head_params.append(p)\n",
        "            head_names.append(name)\n",
        "        else:\n",
        "            backbone_params.append(p)\n",
        "    return head_params, backbone_params, head_names\n",
        "\n",
        "def _freeze_params(params):\n",
        "    for p in params:\n",
        "        p.requires_grad = False\n",
        "\n",
        "def _unfreeze_params(params):\n",
        "    for p in params:\n",
        "        p.requires_grad = True\n",
        "\n",
        "def local_train_task_arithmetic_aligned(\n",
        "    model,\n",
        "    train_dataset,\n",
        "    client_indices,\n",
        "    device,\n",
        "    sparsity_ratio=0.1,\n",
        "    local_epochs_backbone=4,\n",
        "    head_warmup_epochs=1,\n",
        "    calib_rounds=3,\n",
        "    calib_batches_per_round=5,\n",
        "    batch_size=32,\n",
        "    lr_head=0.05,\n",
        "    lr_backbone=0.01,\n",
        "    momentum=0.9,\n",
        "):\n",
        "    \"\"\"\n",
        "    å¯¹é½é¡¹ç›®è¯´æ˜çš„æœ¬åœ°è®­ç»ƒï¼š\n",
        "    step0: æœ¬åœ°è®­ç»ƒåˆ†ç±»å¤´ï¼Œç„¶åå†»ç»“\n",
        "    step1: å¤šè½®æ ¡å‡† least-sensitive maskï¼ˆç”¨äº backboneï¼‰\n",
        "    step2: SparseSGDM åªæ›´æ–° backbone çš„ least-sensitive å­é›†\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    local_sub = Subset(train_dataset, list(client_indices))\n",
        "    local_loader = DataLoader(local_sub, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    head_params, backbone_params, head_names = _split_head_and_backbone_params(model)\n",
        "\n",
        "    # ----------------------------\n",
        "    # Step 0: Head warmup (train head only)\n",
        "    # ----------------------------\n",
        "    if len(head_params) == 0:\n",
        "        # å¦‚æœä½ æ¨¡å‹æ²¡æŒ‰ head/classifier/fc å‘½åï¼Œè¿™é‡Œå°±éœ€è¦ä½ è‡ªå·±æ”¹åˆ¤æ–­è§„åˆ™\n",
        "        raise RuntimeError(\"No head parameters found. Check DINOCIFAR100 head naming.\")\n",
        "\n",
        "    _freeze_params(backbone_params)\n",
        "    _unfreeze_params(head_params)\n",
        "\n",
        "    opt_head = torch.optim.SGD(head_params, lr=lr_head, momentum=momentum)\n",
        "    for _ in range(head_warmup_epochs):\n",
        "        for x, y in local_loader:\n",
        "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "            opt_head.zero_grad(set_to_none=True)\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            opt_head.step()\n",
        "\n",
        "    # Freeze head after warmup (as per spec)\n",
        "    _freeze_params(head_params)\n",
        "    _unfreeze_params(backbone_params)\n",
        "\n",
        "    # ----------------------------\n",
        "    # Step 1: Mask calibration (multiple rounds) on BACKBONE ONLY\n",
        "    # ----------------------------\n",
        "    # æ³¨æ„ï¼šcompute_fisher_sensitivity ä¼šå¯¹æ‰€æœ‰ requires_grad=True çš„å‚æ•°ç®—åˆ†æ•°\n",
        "    # æˆ‘ä»¬å·²ç»å†»ç»“äº† headï¼Œæ‰€ä»¥è¿™é‡Œåªä¼šå¯¹ backbone è®¡ç®—\n",
        "    sensitivity_accum = None\n",
        "    for _ in range(calib_rounds):\n",
        "        sens = compute_fisher_sensitivity(\n",
        "            model,\n",
        "            local_loader,\n",
        "            criterion,\n",
        "            device,\n",
        "            num_batches=min(calib_batches_per_round, len(local_loader))\n",
        "        )\n",
        "        if sensitivity_accum is None:\n",
        "            sensitivity_accum = sens\n",
        "        else:\n",
        "            # åšä¸ªç®€å•å¹³å‡ï¼Œç¨³å®š maskï¼ˆä¹Ÿå¯ä»¥ç”¨ EMAï¼‰\n",
        "            for k in sensitivity_accum:\n",
        "                sensitivity_accum[k] = 0.5 * sensitivity_accum[k] + 0.5 * sens[k]\n",
        "\n",
        "    masks = calibrate_masks(\n",
        "        sensitivity_accum,\n",
        "        sparsity_ratio=sparsity_ratio,\n",
        "        keep_least_sensitive=True  # é¡¹ç›®è¯´æ˜ï¼šleast-sensitive\n",
        "    )\n",
        "\n",
        "    # ----------------------------\n",
        "    # Step 2: Sparse fine-tuning (BACKBONE ONLY)\n",
        "    # ----------------------------\n",
        "    # SparseSGDM åªæ¥æ”¶ backbone å‚æ•°ï¼ˆé¿å… head è¢« mask å½±å“ï¼‰\n",
        "    optimizer = SparseSGDM(\n",
        "        backbone_params,\n",
        "        lr=lr_backbone,\n",
        "        momentum=momentum,\n",
        "        masks=masks\n",
        "    )\n",
        "\n",
        "    model.train()\n",
        "    for _ in range(local_epochs_backbone):\n",
        "        for x, y in local_loader:\n",
        "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model.state_dict(), len(local_sub)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2. ä¸»è”é‚¦è®­ç»ƒå¾ªç¯\n",
        "# ============================================================\n",
        "def run_fed_iid_task_arithmetic(rounds=50, num_clients=100, sampling_rate=0.1, sparsity=0.1):\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # æ•°æ®å‡†å¤‡\n",
        "    builder = FederatedDataBuilder(K=num_clients)\n",
        "    # è·å– IID åˆ’åˆ†\n",
        "    dict_users = builder.get_iid_partition()\n",
        "    test_loader = DataLoader(builder.test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "    # åˆå§‹åŒ–å…¨å±€æ¨¡å‹\n",
        "    global_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    history = {\"accuracy\": [], \"loss\": []}\n",
        "\n",
        "    for r in range(rounds):\n",
        "        print(f\"\\n--- Round {r+1}/{rounds} (Sparsity: {sparsity}) ---\")\n",
        "\n",
        "        local_weights = []\n",
        "        local_counts = []\n",
        "\n",
        "        # éšæœºé€‰æ‹©å®¢æˆ·ç«¯\n",
        "        m = max(int(sampling_rate * num_clients), 1)\n",
        "        selected_clients = np.random.choice(range(num_clients), m, replace=False)\n",
        "\n",
        "        for client_id in selected_clients:\n",
        "            # æ·±æ‹·è´å…¨å±€æ¨¡å‹åˆ°æœ¬åœ°\n",
        "            local_model = copy.deepcopy(global_model)\n",
        "\n",
        "            # æœ¬åœ°ä»»åŠ¡ç®—æœ¯è®­ç»ƒ\n",
        "            w, count = local_train_task_arithmetic(\n",
        "                local_model,\n",
        "                builder.train_dataset,\n",
        "                dict_users[client_id],\n",
        "                DEVICE,\n",
        "                sparsity_ratio=sparsity\n",
        "            )\n",
        "\n",
        "            local_weights.append(w)\n",
        "            local_counts.append(count)\n",
        "\n",
        "        # èšåˆ (FedAvg)\n",
        "        global_weights = fed_avg_aggregate(global_model, local_weights, local_counts)\n",
        "        global_model.load_state_dict(global_weights)\n",
        "\n",
        "        # å…¨å±€è¯„ä¼°\n",
        "        acc, loss = evaluate(global_model, test_loader, DEVICE)\n",
        "        history[\"accuracy\"].append(acc)\n",
        "        history[\"loss\"].append(loss)\n",
        "        print(f\"Round {r+1} Global Test Acc: {acc:.2f}%\")\n",
        "\n",
        "    return history\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total, total_loss / len(loader)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import numpy as np\n",
        "    # è¿è¡Œå®éªŒ\n",
        "    run_fed_iid_task_arithmetic(rounds=20, sparsity=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    run_fed_iid_task_arithmetic(rounds=20, sparsity=0.1)"
      ],
      "metadata": {
        "id": "PRnJzSf8wxrN",
        "outputId": "374fc630-5ccf-4ed9-ecf0-232a84896a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "id": "PRnJzSf8wxrN",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'run_fed_iid_task_arithmetic' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-442898188.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun_fed_iid_task_arithmetic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparsity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'run_fed_iid_task_arithmetic' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "è”é‚¦Task Arithmeticè¯Šæ–­è„šæœ¬ (æœ€ç»ˆç‰ˆ)\n",
        "ç”¨äºæ’æŸ¥ä¸ºä»€ä¹ˆæ¨¡å‹ç²¾åº¦æä½(~1%)\n",
        "\n",
        "ä½¿ç”¨ DINOCIFAR100 æ¨¡å‹ç±»\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "\n",
        "from preprocessing import FederatedDataBuilder\n",
        "from taskarithmetic import compute_fisher_sensitivity, calibrate_masks\n",
        "\n",
        "# å¯¼å…¥æ¨¡å‹ - å…¼å®¹ä¸åŒçš„å‘½å\n",
        "try:\n",
        "    from fed_avg_iid import DINOCIFAR100Fixed as DINOCIFAR100\n",
        "except ImportError:\n",
        "    from fed_avg_iid import DINOCIFAR100\n",
        "\n",
        "\n",
        "def diagnose_mask_problem(sparsity_ratio=0.1):\n",
        "    \"\"\"\n",
        "    è¯Šæ–­æ©ç æ˜¯å¦è¿‡äºä¸¥æ ¼\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"è¯Šæ–­ 1: æ£€æŸ¥æ©ç ç”Ÿæˆ\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # å‡†å¤‡æ•°æ®\n",
        "    builder = FederatedDataBuilder(K=10)\n",
        "    dict_users = builder.get_iid_partition()\n",
        "\n",
        "    # åˆ›å»ºæ¨¡å‹\n",
        "    model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    # å‡†å¤‡ä¸€ä¸ªå®¢æˆ·ç«¯çš„æ•°æ®\n",
        "    local_subset = Subset(builder.train_dataset, list(dict_users[0]))\n",
        "    local_loader = DataLoader(local_subset, batch_size=32, shuffle=True)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # è®¡ç®—æ•æ„Ÿåº¦\n",
        "    print(f\"\\nè®¡ç®—Fisheræ•æ„Ÿåº¦ (sparsity={sparsity_ratio})...\")\n",
        "    sensitivity_scores = compute_fisher_sensitivity(\n",
        "        model, local_loader, criterion, DEVICE, num_batches=5\n",
        "    )\n",
        "\n",
        "    # ç”Ÿæˆæ©ç \n",
        "    masks = calibrate_masks(\n",
        "        sensitivity_scores,\n",
        "        sparsity_ratio=sparsity_ratio,\n",
        "        keep_least_sensitive=True\n",
        "    )\n",
        "\n",
        "    # åˆ†ææ©ç \n",
        "    print(\"\\næ©ç ç»Ÿè®¡:\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    total_params = 0\n",
        "    frozen_params = 0\n",
        "    active_params = 0\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            mask = masks.get(param)\n",
        "            if mask is not None:\n",
        "                num_params = int(param.numel())\n",
        "                num_active = int(mask.sum().item())\n",
        "                num_frozen = num_params - num_active\n",
        "\n",
        "                total_params += num_params\n",
        "                frozen_params += num_frozen\n",
        "                active_params += num_active\n",
        "\n",
        "                active_ratio = 100 * num_active / num_params\n",
        "                print(f\"{name:30s} | Total: {num_params:8d} | \"\n",
        "                      f\"Active: {num_active:8d} ({active_ratio:5.1f}%) | \"\n",
        "                      f\"Frozen: {num_frozen:8d}\")\n",
        "\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"{'æ€»è®¡':30s} | Total: {total_params:8d} | \"\n",
        "          f\"Active: {active_params:8d} ({100*active_params/total_params:5.1f}%) | \"\n",
        "          f\"Frozen: {frozen_params:8d}\")\n",
        "\n",
        "    # å…³é”®æ£€æŸ¥\n",
        "    if active_params == 0:\n",
        "        print(\"\\nâŒ ä¸¥é‡é”™è¯¯: æ‰€æœ‰å‚æ•°éƒ½è¢«å†»ç»“!\")\n",
        "        print(\"   - æ¨¡å‹æ— æ³•å­¦ä¹ \")\n",
        "        print(\"   - éœ€è¦æ£€æŸ¥calibrate_maskså®ç°\")\n",
        "        return False\n",
        "\n",
        "    if active_params < total_params * 0.01:  # å°äº1%\n",
        "        print(\"\\nâš ï¸  è­¦å‘Š: å¯æ›´æ–°å‚æ•°è¿‡å°‘!\")\n",
        "        print(f\"   - åªæœ‰{100*active_params/total_params:.2f}%çš„å‚æ•°å¯ä»¥æ›´æ–°\")\n",
        "        print(\"   - å»ºè®®å¢å¤§sparsity_ratio\")\n",
        "        return False\n",
        "\n",
        "    print(\"\\nâœ“ æ©ç ç”Ÿæˆæ­£å¸¸\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def diagnose_training_step():\n",
        "    \"\"\"\n",
        "    è¯Šæ–­å•æ­¥è®­ç»ƒæ˜¯å¦æ­£å¸¸\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"è¯Šæ–­ 2: æ£€æŸ¥è®­ç»ƒæ­¥éª¤\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # å‡†å¤‡æ•°æ®\n",
        "    builder = FederatedDataBuilder(K=10)\n",
        "    dict_users = builder.get_iid_partition()\n",
        "\n",
        "    # åˆ›å»ºæ¨¡å‹\n",
        "    model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    # æ£€æŸ¥backboneæ˜¯å¦å†»ç»“\n",
        "    print(\"\\næ£€æŸ¥backboneå†»ç»“çŠ¶æ€:\")\n",
        "    backbone_params_trainable = sum(p.requires_grad for p in model.backbone.parameters())\n",
        "    print(f\"Backboneå¯è®­ç»ƒå‚æ•°æ•°: {backbone_params_trainable}\")\n",
        "    if backbone_params_trainable > 0:\n",
        "        print(\"âŒ é”™è¯¯: Backboneåº”è¯¥è¢«å®Œå…¨å†»ç»“!\")\n",
        "        return False\n",
        "    print(\"âœ“ Backboneå·²æ­£ç¡®å†»ç»“\")\n",
        "\n",
        "    # æ£€æŸ¥head\n",
        "    print(\"\\nHeadå‚æ•°:\")\n",
        "    for name, param in model.head.named_parameters():\n",
        "        print(f\"  {name}: requires_grad={param.requires_grad}, shape={param.shape}\")\n",
        "\n",
        "    # å‡†å¤‡æœ¬åœ°æ•°æ®\n",
        "    local_subset = Subset(builder.train_dataset, list(dict_users[0]))\n",
        "    local_loader = DataLoader(local_subset, batch_size=32, shuffle=True)\n",
        "\n",
        "    # è·å–ä¸€ä¸ªbatch\n",
        "    inputs, targets = next(iter(local_loader))\n",
        "    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "    # å‰å‘ä¼ æ’­\n",
        "    print(\"\\næµ‹è¯•å‰å‘ä¼ æ’­:\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs)\n",
        "        print(f\"  è¾“å‡ºå½¢çŠ¶: {outputs.shape}\")\n",
        "        print(f\"  è¾“å‡ºèŒƒå›´: [{outputs.min().item():.2f}, {outputs.max().item():.2f}]\")\n",
        "\n",
        "        # æ£€æŸ¥åˆå§‹ç²¾åº¦\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct = predicted.eq(targets).sum().item()\n",
        "        acc = 100. * correct / targets.size(0)\n",
        "        print(f\"  åˆå§‹ç²¾åº¦ (éšæœº): {acc:.2f}%\")\n",
        "\n",
        "        if acc < 0.5 or acc > 5:\n",
        "            print(f\"  âš ï¸  è­¦å‘Š: åˆå§‹ç²¾åº¦å¼‚å¸¸ (æœŸæœ›~1%)\")\n",
        "\n",
        "    # æµ‹è¯•åå‘ä¼ æ’­\n",
        "    print(\"\\næµ‹è¯•åå‘ä¼ æ’­:\")\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # è®°å½•åˆå§‹æƒé‡\n",
        "    initial_weight = model.head.weight.clone()\n",
        "\n",
        "    # è®­ç»ƒä¸€æ­¥\n",
        "    optimizer = torch.optim.SGD(model.head.parameters(), lr=0.1)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "\n",
        "    # æ£€æŸ¥æ¢¯åº¦\n",
        "    if model.head.weight.grad is None:\n",
        "        print(\"  âŒ é”™è¯¯: æ²¡æœ‰è®¡ç®—æ¢¯åº¦!\")\n",
        "        return False\n",
        "\n",
        "    grad_norm = model.head.weight.grad.norm().item()\n",
        "    print(f\"  æ¢¯åº¦èŒƒæ•°: {grad_norm:.4f}\")\n",
        "\n",
        "    if grad_norm < 1e-6:\n",
        "        print(\"  âš ï¸  è­¦å‘Š: æ¢¯åº¦è¿‡å°\")\n",
        "\n",
        "    # æ›´æ–°æƒé‡\n",
        "    optimizer.step()\n",
        "\n",
        "    # æ£€æŸ¥æƒé‡æ˜¯å¦æ”¹å˜\n",
        "    weight_change = (model.head.weight - initial_weight).abs().max().item()\n",
        "    print(f\"  æƒé‡æœ€å¤§å˜åŒ–: {weight_change:.6f}\")\n",
        "\n",
        "    if weight_change < 1e-8:\n",
        "        print(\"  âŒ é”™è¯¯: æƒé‡æ²¡æœ‰æ›´æ–°!\")\n",
        "        return False\n",
        "\n",
        "    print(\"  âœ“ è®­ç»ƒæ­¥éª¤æ­£å¸¸\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def diagnose_aggregation():\n",
        "    \"\"\"\n",
        "    è¯Šæ–­èšåˆæ˜¯å¦æ­£å¸¸\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"è¯Šæ–­ 3: æ£€æŸ¥FedAvgèšåˆ\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    from fed_avg_iid import fed_avg_aggregate\n",
        "\n",
        "    # åˆ›å»ºå…¨å±€æ¨¡å‹\n",
        "    global_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    # åˆ›å»ºä¸¤ä¸ªæ¨¡æ‹Ÿçš„æœ¬åœ°æ¨¡å‹æƒé‡\n",
        "    local_weights = []\n",
        "\n",
        "    for i in range(2):\n",
        "        local_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "        # éšæœºä¿®æ”¹æƒé‡\n",
        "        with torch.no_grad():\n",
        "            local_model.head.weight += torch.randn_like(local_model.head.weight) * 0.1\n",
        "        local_weights.append(local_model.state_dict())\n",
        "\n",
        "    client_counts = [100, 100]\n",
        "\n",
        "    # æ‰§è¡Œèšåˆ\n",
        "    print(\"\\næ‰§è¡Œèšåˆ...\")\n",
        "    global_weight_before = global_model.head.weight.clone()\n",
        "\n",
        "    new_weights = fed_avg_aggregate(global_model, local_weights, client_counts)\n",
        "    global_model.load_state_dict(new_weights, strict=False)\n",
        "\n",
        "    global_weight_after = global_model.head.weight\n",
        "\n",
        "    # æ£€æŸ¥æƒé‡æ˜¯å¦æ”¹å˜\n",
        "    weight_change = (global_weight_after - global_weight_before).abs().max().item()\n",
        "    print(f\"å…¨å±€æ¨¡å‹æƒé‡æœ€å¤§å˜åŒ–: {weight_change:.6f}\")\n",
        "\n",
        "    if weight_change < 1e-8:\n",
        "        print(\"âŒ é”™è¯¯: èšåˆåå…¨å±€æ¨¡å‹æƒé‡æ²¡æœ‰æ”¹å˜!\")\n",
        "        return False\n",
        "\n",
        "    print(\"âœ“ èšåˆæ­£å¸¸\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def test_without_task_arithmetic():\n",
        "    \"\"\"\n",
        "    æµ‹è¯•ä¸ä½¿ç”¨Task Arithmeticçš„æ ‡å‡†FedAvg\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"è¯Šæ–­ 4: æµ‹è¯•æ ‡å‡†FedAvg (æ— Task Arithmetic)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # æ•°æ®å‡†å¤‡\n",
        "    builder = FederatedDataBuilder(K=10)\n",
        "    dict_users = builder.get_iid_partition()\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        builder.test_dataset,\n",
        "        batch_size=256,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # å…¨å±€æ¨¡å‹\n",
        "    global_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "\n",
        "    from fed_avg_iid import fed_avg_aggregate, evaluate_global\n",
        "\n",
        "    print(\"\\nè¿è¡Œ3è½®æ ‡å‡†FedAvg...\")\n",
        "\n",
        "    for r in range(3):\n",
        "        # é€‰æ‹©2ä¸ªå®¢æˆ·ç«¯\n",
        "        selected_clients = np.random.choice(range(10), 2, replace=False)\n",
        "\n",
        "        local_weights = []\n",
        "        client_counts = []\n",
        "\n",
        "        for client_idx in selected_clients:\n",
        "            # æœ¬åœ°è®­ç»ƒ\n",
        "            local_model = DINOCIFAR100(num_classes=100).to(DEVICE)\n",
        "            local_model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "            local_subset = Subset(builder.train_dataset, list(dict_users[client_idx]))\n",
        "            local_loader = DataLoader(local_subset, batch_size=32, shuffle=True)\n",
        "\n",
        "            optimizer = torch.optim.SGD(local_model.head.parameters(), lr=0.1, momentum=0.9)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            local_model.train()\n",
        "            step_count = 0\n",
        "            iterator = iter(local_loader)\n",
        "\n",
        "            # æ­£ç¡®å®ç°J=4æ­¥\n",
        "            while step_count < 4:\n",
        "                try:\n",
        "                    inputs, targets = next(iterator)\n",
        "                    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = local_model(inputs)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    step_count += 1\n",
        "                except StopIteration:\n",
        "                    break\n",
        "\n",
        "            local_weights.append(local_model.state_dict())\n",
        "            client_counts.append(len(dict_users[client_idx]))\n",
        "\n",
        "        # èšåˆ\n",
        "        new_weights = fed_avg_aggregate(global_model, local_weights, client_counts)\n",
        "        global_model.load_state_dict(new_weights, strict=False)\n",
        "\n",
        "        # è¯„ä¼°\n",
        "        test_loss, test_acc = evaluate_global(global_model, test_loader, DEVICE)\n",
        "        print(f\"Round {r+1}: Test Acc = {test_acc:.2f}%\")\n",
        "\n",
        "        if test_acc < 1.0:\n",
        "            print(\"  âš ï¸  ç²¾åº¦ä»ç„¶è¿‡ä½!\")\n",
        "        elif test_acc > 3.0:\n",
        "            print(\"  âœ“ ç²¾åº¦å¼€å§‹æå‡,åŸºç¡€æµç¨‹æ­£å¸¸\")\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    è¿è¡Œæ‰€æœ‰è¯Šæ–­\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"ğŸ”\"*35)\n",
        "    print(\"      è”é‚¦Task Arithmetic è¯Šæ–­å·¥å…·\")\n",
        "    print(\"ğŸ”\"*35)\n",
        "\n",
        "    # è¯Šæ–­1: æ©ç \n",
        "    mask_ok = diagnose_mask_problem(sparsity_ratio=0.1)\n",
        "\n",
        "    # è¯Šæ–­2: è®­ç»ƒæ­¥éª¤\n",
        "    training_ok = diagnose_training_step()\n",
        "\n",
        "    # è¯Šæ–­3: èšåˆ\n",
        "    aggregation_ok = diagnose_aggregation()\n",
        "\n",
        "    # è¯Šæ–­4: æ— TAçš„FedAvg\n",
        "    fedavg_ok = test_without_task_arithmetic()\n",
        "\n",
        "    # æ€»ç»“\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"è¯Šæ–­æ€»ç»“\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"1. æ©ç ç”Ÿæˆ: {'âœ“ æ­£å¸¸' if mask_ok else 'âŒ å¼‚å¸¸'}\")\n",
        "    print(f\"2. è®­ç»ƒæ­¥éª¤: {'âœ“ æ­£å¸¸' if training_ok else 'âŒ å¼‚å¸¸'}\")\n",
        "    print(f\"3. FedAvgèšåˆ: {'âœ“ æ­£å¸¸' if aggregation_ok else 'âŒ å¼‚å¸¸'}\")\n",
        "    print(f\"4. æ ‡å‡†FedAvg: {'âœ“ æ­£å¸¸' if fedavg_ok else 'âŒ å¼‚å¸¸'}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"å»ºè®®:\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    if not mask_ok:\n",
        "        print(\"1. æ£€æŸ¥calibrate_maskså‡½æ•°å®ç°\")\n",
        "        print(\"2. å°è¯•æ›´å¤§çš„sparsity_ratio (å¦‚0.5)\")\n",
        "        print(\"3. ç¡®è®¤keep_least_sensitiveé€»è¾‘æ­£ç¡®\")\n",
        "\n",
        "    if not training_ok:\n",
        "        print(\"1. æ£€æŸ¥æ¨¡å‹åˆå§‹åŒ–\")\n",
        "        print(\"2. ç¡®è®¤backboneæ­£ç¡®å†»ç»“\")\n",
        "        print(\"3. è°ƒæ•´å­¦ä¹ ç‡\")\n",
        "\n",
        "    if not fedavg_ok:\n",
        "        print(\"1. åŸºç¡€FedAvgå°±æœ‰é—®é¢˜,å…ˆä¿®å¤å®ƒ\")\n",
        "        print(\"2. æ£€æŸ¥æ•°æ®åŠ è½½\")\n",
        "        print(\"3. å¢åŠ æœ¬åœ°è®­ç»ƒæ­¥æ•°\")\n",
        "\n",
        "    if mask_ok and training_ok and aggregation_ok and not fedavg_ok:\n",
        "        print(\"1. é—®é¢˜å¯èƒ½åœ¨æ•°æ®å¤„ç†æˆ–æ¨¡å‹æ¶æ„\")\n",
        "        print(\"2. å°è¯•è¿è¡Œfed_avg_iid.pyçœ‹æ˜¯å¦æ­£å¸¸\")\n",
        "\n",
        "    print(\"\\nğŸ’¡ å¿«é€Ÿä¿®å¤å»ºè®®:\")\n",
        "    print(\"   - å…ˆç¡®ä¿æ ‡å‡†FedAvgèƒ½work (ç²¾åº¦>5%)\")\n",
        "    print(\"   - å†åŠ å…¥Task Arithmetic\")\n",
        "    print(\"   - ä½¿ç”¨è¾ƒå¤§çš„sparsity_ratioå¼€å§‹æµ‹è¯•\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24MgjhUNTAQh",
        "outputId": "8c59d3c7-d232-4177-8ec7-91376c025610"
      },
      "id": "24MgjhUNTAQh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”\n",
            "      è”é‚¦Task Arithmetic è¯Šæ–­å·¥å…·\n",
            "ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”\n",
            "\n",
            "======================================================================\n",
            "è¯Šæ–­ 1: æ£€æŸ¥æ©ç ç”Ÿæˆ\n",
            "======================================================================\n",
            "Creating IID partition for 10 clients...\n",
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "è®¡ç®—Fisheræ•æ„Ÿåº¦ (sparsity=0.1)...\n",
            "Calculating sensitivity over 5 batches...\n",
            "\n",
            "æ©ç ç»Ÿè®¡:\n",
            "----------------------------------------------------------------------\n",
            "backbone.cls_token             | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.pos_embed             | Total:    75648 | Active:      316 (  0.4%) | Frozen:    75332\n",
            "backbone.patch_embed.proj.weight | Total:   294912 | Active:        0 (  0.0%) | Frozen:   294912\n",
            "backbone.patch_embed.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.0.norm1.weight | Total:      384 | Active:      207 ( 53.9%) | Frozen:      177\n",
            "backbone.blocks.0.norm1.bias   | Total:      384 | Active:       44 ( 11.5%) | Frozen:      340\n",
            "backbone.blocks.0.attn.qkv.weight | Total:   442368 | Active:   351693 ( 79.5%) | Frozen:    90675\n",
            "backbone.blocks.0.attn.qkv.bias | Total:     1152 | Active:      685 ( 59.5%) | Frozen:      467\n",
            "backbone.blocks.0.attn.proj.weight | Total:   147456 | Active:    50960 ( 34.6%) | Frozen:    96496\n",
            "backbone.blocks.0.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.0.norm2.weight | Total:      384 | Active:      167 ( 43.5%) | Frozen:      217\n",
            "backbone.blocks.0.norm2.bias   | Total:      384 | Active:       81 ( 21.1%) | Frozen:      303\n",
            "backbone.blocks.0.mlp.fc1.weight | Total:   589824 | Active:   160498 ( 27.2%) | Frozen:   429326\n",
            "backbone.blocks.0.mlp.fc1.bias | Total:     1536 | Active:      416 ( 27.1%) | Frozen:     1120\n",
            "backbone.blocks.0.mlp.fc2.weight | Total:   589824 | Active:     3503 (  0.6%) | Frozen:   586321\n",
            "backbone.blocks.0.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.1.norm1.weight | Total:      384 | Active:      177 ( 46.1%) | Frozen:      207\n",
            "backbone.blocks.1.norm1.bias   | Total:      384 | Active:       19 (  4.9%) | Frozen:      365\n",
            "backbone.blocks.1.attn.qkv.weight | Total:   442368 | Active:   256093 ( 57.9%) | Frozen:   186275\n",
            "backbone.blocks.1.attn.qkv.bias | Total:     1152 | Active:      729 ( 63.3%) | Frozen:      423\n",
            "backbone.blocks.1.attn.proj.weight | Total:   147456 | Active:     6124 (  4.2%) | Frozen:   141332\n",
            "backbone.blocks.1.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.1.norm2.weight | Total:      384 | Active:      228 ( 59.4%) | Frozen:      156\n",
            "backbone.blocks.1.norm2.bias   | Total:      384 | Active:       81 ( 21.1%) | Frozen:      303\n",
            "backbone.blocks.1.mlp.fc1.weight | Total:   589824 | Active:    42255 (  7.2%) | Frozen:   547569\n",
            "backbone.blocks.1.mlp.fc1.bias | Total:     1536 | Active:      105 (  6.8%) | Frozen:     1431\n",
            "backbone.blocks.1.mlp.fc2.weight | Total:   589824 | Active:      446 (  0.1%) | Frozen:   589378\n",
            "backbone.blocks.1.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.2.norm1.weight | Total:      384 | Active:      125 ( 32.6%) | Frozen:      259\n",
            "backbone.blocks.2.norm1.bias   | Total:      384 | Active:        4 (  1.0%) | Frozen:      380\n",
            "backbone.blocks.2.attn.qkv.weight | Total:   442368 | Active:   194159 ( 43.9%) | Frozen:   248209\n",
            "backbone.blocks.2.attn.qkv.bias | Total:     1152 | Active:      679 ( 58.9%) | Frozen:      473\n",
            "backbone.blocks.2.attn.proj.weight | Total:   147456 | Active:      230 (  0.2%) | Frozen:   147226\n",
            "backbone.blocks.2.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.2.norm2.weight | Total:      384 | Active:      161 ( 41.9%) | Frozen:      223\n",
            "backbone.blocks.2.norm2.bias   | Total:      384 | Active:       15 (  3.9%) | Frozen:      369\n",
            "backbone.blocks.2.mlp.fc1.weight | Total:   589824 | Active:    13375 (  2.3%) | Frozen:   576449\n",
            "backbone.blocks.2.mlp.fc1.bias | Total:     1536 | Active:       26 (  1.7%) | Frozen:     1510\n",
            "backbone.blocks.2.mlp.fc2.weight | Total:   589824 | Active:      306 (  0.1%) | Frozen:   589518\n",
            "backbone.blocks.2.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.3.norm1.weight | Total:      384 | Active:      136 ( 35.4%) | Frozen:      248\n",
            "backbone.blocks.3.norm1.bias   | Total:      384 | Active:        4 (  1.0%) | Frozen:      380\n",
            "backbone.blocks.3.attn.qkv.weight | Total:   442368 | Active:   138281 ( 31.3%) | Frozen:   304087\n",
            "backbone.blocks.3.attn.qkv.bias | Total:     1152 | Active:      593 ( 51.5%) | Frozen:      559\n",
            "backbone.blocks.3.attn.proj.weight | Total:   147456 | Active:       76 (  0.1%) | Frozen:   147380\n",
            "backbone.blocks.3.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.3.norm2.weight | Total:      384 | Active:      121 ( 31.5%) | Frozen:      263\n",
            "backbone.blocks.3.norm2.bias   | Total:      384 | Active:        3 (  0.8%) | Frozen:      381\n",
            "backbone.blocks.3.mlp.fc1.weight | Total:   589824 | Active:    11443 (  1.9%) | Frozen:   578381\n",
            "backbone.blocks.3.mlp.fc1.bias | Total:     1536 | Active:       44 (  2.9%) | Frozen:     1492\n",
            "backbone.blocks.3.mlp.fc2.weight | Total:   589824 | Active:       24 (  0.0%) | Frozen:   589800\n",
            "backbone.blocks.3.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.4.norm1.weight | Total:      384 | Active:      100 ( 26.0%) | Frozen:      284\n",
            "backbone.blocks.4.norm1.bias   | Total:      384 | Active:        4 (  1.0%) | Frozen:      380\n",
            "backbone.blocks.4.attn.qkv.weight | Total:   442368 | Active:    94084 ( 21.3%) | Frozen:   348284\n",
            "backbone.blocks.4.attn.qkv.bias | Total:     1152 | Active:      498 ( 43.2%) | Frozen:      654\n",
            "backbone.blocks.4.attn.proj.weight | Total:   147456 | Active:        8 (  0.0%) | Frozen:   147448\n",
            "backbone.blocks.4.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.4.norm2.weight | Total:      384 | Active:      108 ( 28.1%) | Frozen:      276\n",
            "backbone.blocks.4.norm2.bias   | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.4.mlp.fc1.weight | Total:   589824 | Active:    14884 (  2.5%) | Frozen:   574940\n",
            "backbone.blocks.4.mlp.fc1.bias | Total:     1536 | Active:       77 (  5.0%) | Frozen:     1459\n",
            "backbone.blocks.4.mlp.fc2.weight | Total:   589824 | Active:      651 (  0.1%) | Frozen:   589173\n",
            "backbone.blocks.4.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.5.norm1.weight | Total:      384 | Active:      103 ( 26.8%) | Frozen:      281\n",
            "backbone.blocks.5.norm1.bias   | Total:      384 | Active:        2 (  0.5%) | Frozen:      382\n",
            "backbone.blocks.5.attn.qkv.weight | Total:   442368 | Active:    57751 ( 13.1%) | Frozen:   384617\n",
            "backbone.blocks.5.attn.qkv.bias | Total:     1152 | Active:      527 ( 45.7%) | Frozen:      625\n",
            "backbone.blocks.5.attn.proj.weight | Total:   147456 | Active:       10 (  0.0%) | Frozen:   147446\n",
            "backbone.blocks.5.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.5.norm2.weight | Total:      384 | Active:      136 ( 35.4%) | Frozen:      248\n",
            "backbone.blocks.5.norm2.bias   | Total:      384 | Active:        6 (  1.6%) | Frozen:      378\n",
            "backbone.blocks.5.mlp.fc1.weight | Total:   589824 | Active:    15229 (  2.6%) | Frozen:   574595\n",
            "backbone.blocks.5.mlp.fc1.bias | Total:     1536 | Active:      125 (  8.1%) | Frozen:     1411\n",
            "backbone.blocks.5.mlp.fc2.weight | Total:   589824 | Active:      976 (  0.2%) | Frozen:   588848\n",
            "backbone.blocks.5.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.6.norm1.weight | Total:      384 | Active:      107 ( 27.9%) | Frozen:      277\n",
            "backbone.blocks.6.norm1.bias   | Total:      384 | Active:        6 (  1.6%) | Frozen:      378\n",
            "backbone.blocks.6.attn.qkv.weight | Total:   442368 | Active:    52698 ( 11.9%) | Frozen:   389670\n",
            "backbone.blocks.6.attn.qkv.bias | Total:     1152 | Active:      466 ( 40.5%) | Frozen:      686\n",
            "backbone.blocks.6.attn.proj.weight | Total:   147456 | Active:        1 (  0.0%) | Frozen:   147455\n",
            "backbone.blocks.6.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.6.norm2.weight | Total:      384 | Active:      162 ( 42.2%) | Frozen:      222\n",
            "backbone.blocks.6.norm2.bias   | Total:      384 | Active:       18 (  4.7%) | Frozen:      366\n",
            "backbone.blocks.6.mlp.fc1.weight | Total:   589824 | Active:     8376 (  1.4%) | Frozen:   581448\n",
            "backbone.blocks.6.mlp.fc1.bias | Total:     1536 | Active:      153 ( 10.0%) | Frozen:     1383\n",
            "backbone.blocks.6.mlp.fc2.weight | Total:   589824 | Active:     1502 (  0.3%) | Frozen:   588322\n",
            "backbone.blocks.6.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.7.norm1.weight | Total:      384 | Active:      114 ( 29.7%) | Frozen:      270\n",
            "backbone.blocks.7.norm1.bias   | Total:      384 | Active:       13 (  3.4%) | Frozen:      371\n",
            "backbone.blocks.7.attn.qkv.weight | Total:   442368 | Active:    41040 (  9.3%) | Frozen:   401328\n",
            "backbone.blocks.7.attn.qkv.bias | Total:     1152 | Active:      521 ( 45.2%) | Frozen:      631\n",
            "backbone.blocks.7.attn.proj.weight | Total:   147456 | Active:        4 (  0.0%) | Frozen:   147452\n",
            "backbone.blocks.7.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.7.norm2.weight | Total:      384 | Active:      226 ( 58.9%) | Frozen:      158\n",
            "backbone.blocks.7.norm2.bias   | Total:      384 | Active:       70 ( 18.2%) | Frozen:      314\n",
            "backbone.blocks.7.mlp.fc1.weight | Total:   589824 | Active:     7998 (  1.4%) | Frozen:   581826\n",
            "backbone.blocks.7.mlp.fc1.bias | Total:     1536 | Active:      205 ( 13.3%) | Frozen:     1331\n",
            "backbone.blocks.7.mlp.fc2.weight | Total:   589824 | Active:     1180 (  0.2%) | Frozen:   588644\n",
            "backbone.blocks.7.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.8.norm1.weight | Total:      384 | Active:      151 ( 39.3%) | Frozen:      233\n",
            "backbone.blocks.8.norm1.bias   | Total:      384 | Active:       23 (  6.0%) | Frozen:      361\n",
            "backbone.blocks.8.attn.qkv.weight | Total:   442368 | Active:    23144 (  5.2%) | Frozen:   419224\n",
            "backbone.blocks.8.attn.qkv.bias | Total:     1152 | Active:      497 ( 43.1%) | Frozen:      655\n",
            "backbone.blocks.8.attn.proj.weight | Total:   147456 | Active:        0 (  0.0%) | Frozen:   147456\n",
            "backbone.blocks.8.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.8.norm2.weight | Total:      384 | Active:      315 ( 82.0%) | Frozen:       69\n",
            "backbone.blocks.8.norm2.bias   | Total:      384 | Active:      133 ( 34.6%) | Frozen:      251\n",
            "backbone.blocks.8.mlp.fc1.weight | Total:   589824 | Active:    10261 (  1.7%) | Frozen:   579563\n",
            "backbone.blocks.8.mlp.fc1.bias | Total:     1536 | Active:      280 ( 18.2%) | Frozen:     1256\n",
            "backbone.blocks.8.mlp.fc2.weight | Total:   589824 | Active:     2751 (  0.5%) | Frozen:   587073\n",
            "backbone.blocks.8.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.9.norm1.weight | Total:      384 | Active:      163 ( 42.4%) | Frozen:      221\n",
            "backbone.blocks.9.norm1.bias   | Total:      384 | Active:       22 (  5.7%) | Frozen:      362\n",
            "backbone.blocks.9.attn.qkv.weight | Total:   442368 | Active:    13536 (  3.1%) | Frozen:   428832\n",
            "backbone.blocks.9.attn.qkv.bias | Total:     1152 | Active:      556 ( 48.3%) | Frozen:      596\n",
            "backbone.blocks.9.attn.proj.weight | Total:   147456 | Active:        0 (  0.0%) | Frozen:   147456\n",
            "backbone.blocks.9.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.9.norm2.weight | Total:      384 | Active:      381 ( 99.2%) | Frozen:        3\n",
            "backbone.blocks.9.norm2.bias   | Total:      384 | Active:      384 (100.0%) | Frozen:        0\n",
            "backbone.blocks.9.mlp.fc1.weight | Total:   589824 | Active:    81918 ( 13.9%) | Frozen:   507906\n",
            "backbone.blocks.9.mlp.fc1.bias | Total:     1536 | Active:     1327 ( 86.4%) | Frozen:      209\n",
            "backbone.blocks.9.mlp.fc2.weight | Total:   589824 | Active:   198911 ( 33.7%) | Frozen:   390913\n",
            "backbone.blocks.9.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.10.norm1.weight | Total:      384 | Active:      138 ( 35.9%) | Frozen:      246\n",
            "backbone.blocks.10.norm1.bias  | Total:      384 | Active:        2 (  0.5%) | Frozen:      382\n",
            "backbone.blocks.10.attn.qkv.weight | Total:   442368 | Active:    11979 (  2.7%) | Frozen:   430389\n",
            "backbone.blocks.10.attn.qkv.bias | Total:     1152 | Active:      559 ( 48.5%) | Frozen:      593\n",
            "backbone.blocks.10.attn.proj.weight | Total:   147456 | Active:        3 (  0.0%) | Frozen:   147453\n",
            "backbone.blocks.10.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.10.norm2.weight | Total:      384 | Active:      315 ( 82.0%) | Frozen:       69\n",
            "backbone.blocks.10.norm2.bias  | Total:      384 | Active:      223 ( 58.1%) | Frozen:      161\n",
            "backbone.blocks.10.mlp.fc1.weight | Total:   589824 | Active:    31819 (  5.4%) | Frozen:   558005\n",
            "backbone.blocks.10.mlp.fc1.bias | Total:     1536 | Active:      539 ( 35.1%) | Frozen:      997\n",
            "backbone.blocks.10.mlp.fc2.weight | Total:   589824 | Active:    27230 (  4.6%) | Frozen:   562594\n",
            "backbone.blocks.10.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.11.norm1.weight | Total:      384 | Active:      109 ( 28.4%) | Frozen:      275\n",
            "backbone.blocks.11.norm1.bias  | Total:      384 | Active:        4 (  1.0%) | Frozen:      380\n",
            "backbone.blocks.11.attn.qkv.weight | Total:   442368 | Active:    13995 (  3.2%) | Frozen:   428373\n",
            "backbone.blocks.11.attn.qkv.bias | Total:     1152 | Active:      424 ( 36.8%) | Frozen:      728\n",
            "backbone.blocks.11.attn.proj.weight | Total:   147456 | Active:        4 (  0.0%) | Frozen:   147452\n",
            "backbone.blocks.11.attn.proj.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.blocks.11.norm2.weight | Total:      384 | Active:      335 ( 87.2%) | Frozen:       49\n",
            "backbone.blocks.11.norm2.bias  | Total:      384 | Active:      307 ( 79.9%) | Frozen:       77\n",
            "backbone.blocks.11.mlp.fc1.weight | Total:   589824 | Active:    99344 ( 16.8%) | Frozen:   490480\n",
            "backbone.blocks.11.mlp.fc1.bias | Total:     1536 | Active:      797 ( 51.9%) | Frozen:      739\n",
            "backbone.blocks.11.mlp.fc2.weight | Total:   589824 | Active:   109163 ( 18.5%) | Frozen:   480661\n",
            "backbone.blocks.11.mlp.fc2.bias | Total:      384 | Active:        0 (  0.0%) | Frozen:      384\n",
            "backbone.norm.weight           | Total:      384 | Active:        6 (  1.6%) | Frozen:      378\n",
            "backbone.norm.bias             | Total:      384 | Active:        2 (  0.5%) | Frozen:      382\n",
            "head.weight                    | Total:    38400 | Active:     3582 (  9.3%) | Frozen:    34818\n",
            "head.bias                      | Total:      100 | Active:       13 ( 13.0%) | Frozen:       87\n",
            "----------------------------------------------------------------------\n",
            "æ€»è®¡                             | Total: 21704164 | Active:  2170416 ( 10.0%) | Frozen: 19533748\n",
            "\n",
            "âœ“ æ©ç ç”Ÿæˆæ­£å¸¸\n",
            "\n",
            "======================================================================\n",
            "è¯Šæ–­ 2: æ£€æŸ¥è®­ç»ƒæ­¥éª¤\n",
            "======================================================================\n",
            "Creating IID partition for 10 clients...\n",
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "æ£€æŸ¥backboneå†»ç»“çŠ¶æ€:\n",
            "Backboneå¯è®­ç»ƒå‚æ•°æ•°: 150\n",
            "âŒ é”™è¯¯: Backboneåº”è¯¥è¢«å®Œå…¨å†»ç»“!\n",
            "\n",
            "======================================================================\n",
            "è¯Šæ–­ 3: æ£€æŸ¥FedAvgèšåˆ\n",
            "======================================================================\n",
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "æ‰§è¡Œèšåˆ...\n",
            "å…¨å±€æ¨¡å‹æƒé‡æœ€å¤§å˜åŒ–: 0.325009\n",
            "âœ“ èšåˆæ­£å¸¸\n",
            "\n",
            "======================================================================\n",
            "è¯Šæ–­ 4: æµ‹è¯•æ ‡å‡†FedAvg (æ— Task Arithmetic)\n",
            "======================================================================\n",
            "Creating IID partition for 10 clients...\n",
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "è¿è¡Œ3è½®æ ‡å‡†FedAvg...\n",
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading/Loading DINO ViT-S/16...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_dino_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1: Test Acc = 6.55%\n",
            "  âœ“ ç²¾åº¦å¼€å§‹æå‡,åŸºç¡€æµç¨‹æ­£å¸¸\n",
            "\n",
            "======================================================================\n",
            "è¯Šæ–­æ€»ç»“\n",
            "======================================================================\n",
            "1. æ©ç ç”Ÿæˆ: âœ“ æ­£å¸¸\n",
            "2. è®­ç»ƒæ­¥éª¤: âŒ å¼‚å¸¸\n",
            "3. FedAvgèšåˆ: âœ“ æ­£å¸¸\n",
            "4. æ ‡å‡†FedAvg: âœ“ æ­£å¸¸\n",
            "\n",
            "======================================================================\n",
            "å»ºè®®:\n",
            "======================================================================\n",
            "1. æ£€æŸ¥æ¨¡å‹åˆå§‹åŒ–\n",
            "2. ç¡®è®¤backboneæ­£ç¡®å†»ç»“\n",
            "3. è°ƒæ•´å­¦ä¹ ç‡\n",
            "\n",
            "ğŸ’¡ å¿«é€Ÿä¿®å¤å»ºè®®:\n",
            "   - å…ˆç¡®ä¿æ ‡å‡†FedAvgèƒ½work (ç²¾åº¦>5%)\n",
            "   - å†åŠ å…¥Task Arithmetic\n",
            "   - ä½¿ç”¨è¾ƒå¤§çš„sparsity_ratioå¼€å§‹æµ‹è¯•\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}