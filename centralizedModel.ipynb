{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ILoveCoder999/FederatedLearning/blob/master/centralizedModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "825e3347",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "825e3347",
        "outputId": "d073dec3-e716-4dab-9ee9-6bbddbbeee49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# import module\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive')\n",
        "from preprocessing import FederatedDataBuilder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f172bdc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0f172bdc",
        "outputId": "aca415be-5c09-4428-cc9e-0171c34fefc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing centralized_model.py\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# ============================================================\n",
        "# 1. Model Definition (with Dropout)\n",
        "# ============================================================\n",
        "class DINOCIFAR100(nn.Module):\n",
        "    def __init__(self, num_classes=100, dropout_rate=0.1):\n",
        "        \"\"\"\n",
        "        DINO ViT-S/16 model for CIFAR-100 classification.\n",
        "\n",
        "        Args:\n",
        "            num_classes: Number of output classes (100 for CIFAR-100)\n",
        "            dropout_rate: Dropout probability for regularization\n",
        "        \"\"\"\n",
        "        super(DINOCIFAR100, self).__init__()\n",
        "        print(\"Downloading/Loading DINO ViT-S/16...\")\n",
        "        self.backbone = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
        "        self.embed_dim = 384\n",
        "\n",
        "        # Add Dropout layer for regularization\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.head = nn.Linear(self.embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass through the network\"\"\"\n",
        "        features = self.backbone(x)\n",
        "        features = self.dropout(features)\n",
        "        return self.head(features)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2. Training & Evaluation Functions\n",
        "# ============================================================\n",
        "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch.\n",
        "\n",
        "    Args:\n",
        "        model: Neural network model\n",
        "        loader: Training data loader\n",
        "        criterion: Loss function\n",
        "        optimizer: Optimizer\n",
        "        device: Device (cuda/cpu)\n",
        "\n",
        "    Returns:\n",
        "        avg_loss: Average loss for this epoch\n",
        "        accuracy: Training accuracy (%)\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, targets in tqdm(loader, desc=\"Training\", leave=False):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / len(loader)\n",
        "    accuracy = 100. * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Evaluate the model on validation/test set.\n",
        "\n",
        "    Args:\n",
        "        model: Neural network model\n",
        "        loader: Validation/test data loader\n",
        "        criterion: Loss function\n",
        "        device: Device (cuda/cpu)\n",
        "\n",
        "    Returns:\n",
        "        avg_loss: Average loss\n",
        "        accuracy: Accuracy (%)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in tqdm(loader, desc=\"Evaluating\", leave=False):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / len(loader)\n",
        "    accuracy = 100. * correct / total\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3. Warmup + Cosine Decay Learning Rate Scheduler\n",
        "# ============================================================\n",
        "def get_lr_schedule(optimizer, warmup_epochs=5, total_epochs=50):\n",
        "    \"\"\"\n",
        "    Create a learning rate scheduler with Warmup + Cosine Decay.\n",
        "\n",
        "    - First warmup_epochs: Linear warmup from 0 to initial LR\n",
        "    - Remaining epochs: Cosine annealing decay\n",
        "\n",
        "    Args:\n",
        "        optimizer: Optimizer\n",
        "        warmup_epochs: Number of warmup epochs\n",
        "        total_epochs: Total number of training epochs\n",
        "\n",
        "    Returns:\n",
        "        LambdaLR scheduler\n",
        "    \"\"\"\n",
        "    def lr_lambda(epoch):\n",
        "        if epoch < warmup_epochs:\n",
        "            # Warmup phase: Linear growth from 0 to 1\n",
        "            return epoch / warmup_epochs\n",
        "        else:\n",
        "            # Cosine Decay phase: Smooth decay\n",
        "            progress = (epoch - warmup_epochs) / (total_epochs - warmup_epochs)\n",
        "            return 0.5 * (1 + np.cos(np.pi * progress))\n",
        "\n",
        "    return optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. Checkpointing Functions\n",
        "# ============================================================\n",
        "def save_checkpoint(epoch, model, optimizer, scheduler, best_acc, history,\n",
        "                   checkpoint_dir='checkpoints', filename='checkpoint.pth'):\n",
        "    \"\"\"\n",
        "    Save training checkpoint.\n",
        "\n",
        "    Args:\n",
        "        epoch: Current epoch number\n",
        "        model: Model state\n",
        "        optimizer: Optimizer state\n",
        "        scheduler: Scheduler state\n",
        "        best_acc: Best validation accuracy so far\n",
        "        history: Training history dictionary\n",
        "        checkpoint_dir: Directory to save checkpoints\n",
        "        filename: Checkpoint filename\n",
        "    \"\"\"\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, filename)\n",
        "\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(),\n",
        "        'best_acc': best_acc,\n",
        "        'history': history\n",
        "    }, checkpoint_path)\n",
        "\n",
        "    print(f\"Checkpoint saved to {checkpoint_path}\")\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_path, model, optimizer=None, scheduler=None):\n",
        "    \"\"\"\n",
        "    Load training checkpoint.\n",
        "\n",
        "    Args:\n",
        "        checkpoint_path: Path to checkpoint file\n",
        "        model: Model to load state into\n",
        "        optimizer: Optional optimizer to load state into\n",
        "        scheduler: Optional scheduler to load state into\n",
        "\n",
        "    Returns:\n",
        "        start_epoch: Epoch to resume from\n",
        "        best_acc: Best accuracy from checkpoint\n",
        "        history: Training history\n",
        "    \"\"\"\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        print(f\"No checkpoint found at {checkpoint_path}\")\n",
        "        return 0, 0.0, {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "    print(f\"Loading checkpoint from {checkpoint_path}\")\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    if optimizer is not None:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    if scheduler is not None:\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "    return checkpoint['epoch'] + 1, checkpoint['best_acc'], checkpoint['history']\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. Experiment Logging\n",
        "# ============================================================\n",
        "class ExperimentLogger:\n",
        "    \"\"\"Simple logger for tracking experiments\"\"\"\n",
        "\n",
        "    def __init__(self, log_dir='logs', experiment_name=None):\n",
        "        \"\"\"\n",
        "        Initialize experiment logger.\n",
        "\n",
        "        Args:\n",
        "            log_dir: Directory to save logs\n",
        "            experiment_name: Name of experiment (auto-generated if None)\n",
        "        \"\"\"\n",
        "        os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "        if experiment_name is None:\n",
        "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            experiment_name = f'centralized_{timestamp}'\n",
        "\n",
        "        self.log_file = os.path.join(log_dir, f'{experiment_name}.json')\n",
        "        self.metrics = {\n",
        "            'experiment_name': experiment_name,\n",
        "            'start_time': datetime.now().isoformat(),\n",
        "            'hyperparameters': {},\n",
        "            'epochs': []\n",
        "        }\n",
        "\n",
        "    def log_hyperparameters(self, hparams):\n",
        "        \"\"\"Log hyperparameters\"\"\"\n",
        "        self.metrics['hyperparameters'] = hparams\n",
        "\n",
        "    def log_epoch(self, epoch, train_loss, train_acc, val_loss, val_acc, lr):\n",
        "        \"\"\"Log metrics for one epoch\"\"\"\n",
        "        self.metrics['epochs'].append({\n",
        "            'epoch': epoch,\n",
        "            'train_loss': train_loss,\n",
        "            'train_acc': train_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'val_acc': val_acc,\n",
        "            'learning_rate': lr\n",
        "        })\n",
        "\n",
        "    def log_final_results(self, test_loss, test_acc, total_epochs):\n",
        "        \"\"\"Log final test results\"\"\"\n",
        "        self.metrics['end_time'] = datetime.now().isoformat()\n",
        "        self.metrics['total_epochs'] = total_epochs\n",
        "        self.metrics['test_loss'] = test_loss\n",
        "        self.metrics['test_acc'] = test_acc\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\"Save logs to file\"\"\"\n",
        "        with open(self.log_file, 'w') as f:\n",
        "            json.dump(self.metrics, f, indent=2)\n",
        "        print(f\"Experiment log saved to {self.log_file}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 6. Main Training Function (Enhanced)\n",
        "# ============================================================\n",
        "def run_centralized_baseline(config=None, seed=42, resume_from=None):\n",
        "    \"\"\"\n",
        "    Main training function with all optimizations and best practices.\n",
        "\n",
        "    Args:\n",
        "        config: Dictionary with hyperparameters (if None, uses defaults)\n",
        "        seed: Random seed for reproducibility\n",
        "        resume_from: Path to checkpoint to resume from\n",
        "\n",
        "    Returns:\n",
        "        test_acc: Final test accuracy\n",
        "        history: Training history\n",
        "    \"\"\"\n",
        "    # Set random seeds for reproducibility\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "\n",
        "    # ========== Hyperparameters ==========\n",
        "    if config is None:\n",
        "        config = {\n",
        "            'batch_size': 128,\n",
        "            'epochs': 50,\n",
        "            'lr': 0.0001,\n",
        "            'momentum': 0.9,\n",
        "            'weight_decay': 5e-4,\n",
        "            'dropout_rate': 0.1,\n",
        "            'warmup_epochs': 5,\n",
        "            'patience': 10\n",
        "        }\n",
        "\n",
        "    BATCH_SIZE = config['batch_size']\n",
        "    EPOCHS = config['epochs']\n",
        "    LR = config['lr']\n",
        "    MOMENTUM = config['momentum']\n",
        "    WEIGHT_DECAY = config['weight_decay']\n",
        "    DROPOUT_RATE = config['dropout_rate']\n",
        "    WARMUP_EPOCHS = config['warmup_epochs']\n",
        "    PATIENCE = config['patience']\n",
        "\n",
        "    # Device setup\n",
        "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {DEVICE}\")\n",
        "    print(f\"Random seed: {seed}\")\n",
        "\n",
        "    # ========== Initialize Logger ==========\n",
        "    logger = ExperimentLogger(experiment_name=f'centralized_seed{seed}')\n",
        "    logger.log_hyperparameters(config)\n",
        "\n",
        "    # ========== Data Preparation ==========\n",
        "    import torchvision.transforms as transforms\n",
        "\n",
        "    # Training set: Apply data augmentation\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
        "                           (0.2675, 0.2565, 0.2761))\n",
        "    ])\n",
        "\n",
        "    # Validation/Test set: No augmentation\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5071, 0.4867, 0.4408),\n",
        "                           (0.2675, 0.2565, 0.2761))\n",
        "    ])\n",
        "\n",
        "    # Load datasets\n",
        "    from preprocessing import FederatedDataBuilder\n",
        "    data_builder = FederatedDataBuilder(val_split_ratio=0.1)\n",
        "\n",
        "    # Apply augmentation to training set\n",
        "    data_builder.train_dataset.dataset.transform = transform_train\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        data_builder.train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "        num_workers=2, pin_memory=True\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        data_builder.val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "        num_workers=2, pin_memory=True\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        data_builder.test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "        num_workers=2, pin_memory=True\n",
        "    )\n",
        "\n",
        "    print(f\"\\nDataset sizes:\")\n",
        "    print(f\"  Training: {len(data_builder.train_dataset)}\")\n",
        "    print(f\"  Validation: {len(data_builder.val_dataset)}\")\n",
        "    print(f\"  Test: {len(data_builder.test_dataset)}\")\n",
        "\n",
        "    # ========== Model, Optimizer, Loss Function ==========\n",
        "    model = DINOCIFAR100(num_classes=100, dropout_rate=DROPOUT_RATE).to(DEVICE)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM,\n",
        "                         weight_decay=WEIGHT_DECAY)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scheduler = get_lr_schedule(optimizer, warmup_epochs=WARMUP_EPOCHS,\n",
        "                               total_epochs=EPOCHS)\n",
        "\n",
        "    # ========== Resume from checkpoint if specified ==========\n",
        "    start_epoch = 0\n",
        "    best_val_acc = 0.0\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "    if resume_from is not None:\n",
        "        start_epoch, best_val_acc, history = load_checkpoint(\n",
        "            resume_from, model, optimizer, scheduler\n",
        "        )\n",
        "        print(f\"Resumed from epoch {start_epoch} with best acc {best_val_acc:.2f}%\")\n",
        "\n",
        "    # ========== Early Stopping Setup ==========\n",
        "    no_improve_count = 0\n",
        "    checkpoint_dir = 'checkpoints'\n",
        "    best_model_path = os.path.join(checkpoint_dir, f'best_model_seed{seed}.pth')\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # ========== Training Loop ==========\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Starting centralized training for {EPOCHS} epochs...\")\n",
        "    print(f\"Hyperparameters: LR={LR}, Batch={BATCH_SIZE}, WD={WEIGHT_DECAY}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    for epoch in range(start_epoch, EPOCHS):\n",
        "        # Train for one epoch\n",
        "        t_loss, t_acc = train_one_epoch(model, train_loader, criterion,\n",
        "                                       optimizer, DEVICE)\n",
        "\n",
        "        # Validate\n",
        "        v_loss, v_acc = evaluate(model, val_loader, criterion, DEVICE)\n",
        "\n",
        "        # Get current learning rate\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        # Record history\n",
        "        history['train_loss'].append(t_loss)\n",
        "        history['train_acc'].append(t_acc)\n",
        "        history['val_loss'].append(v_loss)\n",
        "        history['val_acc'].append(v_acc)\n",
        "\n",
        "        # Log to experiment logger\n",
        "        logger.log_epoch(epoch + 1, t_loss, t_acc, v_loss, v_acc, current_lr)\n",
        "\n",
        "        # Early Stopping check\n",
        "        if v_acc > best_val_acc:\n",
        "            best_val_acc = v_acc\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            no_improve_count = 0\n",
        "            print(f\"✓ Epoch {epoch+1}/{EPOCHS} | LR: {current_lr:.6f} | \"\n",
        "                  f\"Train Loss: {t_loss:.4f} Acc: {t_acc:.2f}% | \"\n",
        "                  f\"Val Loss: {v_loss:.4f} Acc: {v_acc:.2f}% | \"\n",
        "                  f\"NEW BEST! ⭐\")\n",
        "        else:\n",
        "            no_improve_count += 1\n",
        "            print(f\"  Epoch {epoch+1}/{EPOCHS} | LR: {current_lr:.6f} | \"\n",
        "                  f\"Train Loss: {t_loss:.4f} Acc: {t_acc:.2f}% | \"\n",
        "                  f\"Val Loss: {v_loss:.4f} Acc: {v_acc:.2f}% | \"\n",
        "                  f\"No improvement: {no_improve_count}/{PATIENCE}\")\n",
        "\n",
        "        # Save periodic checkpoint (every 10 epochs)\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            save_checkpoint(epoch, model, optimizer, scheduler, best_val_acc,\n",
        "                          history, checkpoint_dir,\n",
        "                          f'checkpoint_epoch{epoch+1}_seed{seed}.pth')\n",
        "\n",
        "        # Stop training if no improvement for PATIENCE epochs\n",
        "        if no_improve_count >= PATIENCE:\n",
        "            print(f\"\\n⚠ Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    # ========== Load Best Model for Final Test ==========\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"Training completed! Loading best model for testing...\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    model.load_state_dict(torch.load(best_model_path))\n",
        "    test_loss, test_acc = evaluate(model, test_loader, criterion, DEVICE)\n",
        "\n",
        "    print(f\" Final Results:\")\n",
        "    print(f\"   Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "    print(f\"   Test Accuracy: {test_acc:.2f}%\")\n",
        "    print(f\"   Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "    # Log final results\n",
        "    logger.log_final_results(test_loss, test_acc, epoch + 1)\n",
        "    logger.save()\n",
        "\n",
        "    # ========== Plot Training Curves ==========\n",
        "    plot_results(history, save_path=f'figures/training_curves_seed{seed}.png')\n",
        "\n",
        "    return test_acc, history\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 7. Multiple Runs for Statistical Significance\n",
        "# ============================================================\n",
        "def run_multiple_experiments(num_runs=3, config=None):\n",
        "    \"\"\"\n",
        "    Run multiple experiments with different random seeds.\n",
        "\n",
        "    Args:\n",
        "        num_runs: Number of independent runs\n",
        "        config: Hyperparameter configuration\n",
        "\n",
        "    Returns:\n",
        "        results: List of test accuracies from each run\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Running {num_runs} independent experiments\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for run in range(num_runs):\n",
        "        seed = 42 + run\n",
        "        print(f\"\\n{'#'*60}\")\n",
        "        print(f\"# RUN {run+1}/{num_runs} (seed={seed})\")\n",
        "        print(f\"{'#'*60}\\n\")\n",
        "\n",
        "        test_acc, _ = run_centralized_baseline(config=config, seed=seed)\n",
        "        results.append(test_acc)\n",
        "\n",
        "    # Calculate statistics\n",
        "    mean_acc = np.mean(results)\n",
        "    std_acc = np.std(results)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"FINAL RESULTS (across {num_runs} runs)\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Test Accuracy: {mean_acc:.2f}% ± {std_acc:.2f}%\")\n",
        "    print(f\"Individual runs: {[f'{acc:.2f}%' for acc in results]}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Save aggregated results\n",
        "    os.makedirs('logs', exist_ok=True)\n",
        "    with open('logs/multiple_runs_summary.json', 'w') as f:\n",
        "        json.dump({\n",
        "            'num_runs': num_runs,\n",
        "            'results': results,\n",
        "            'mean': mean_acc,\n",
        "            'std': std_acc,\n",
        "            'config': config\n",
        "        }, f, indent=2)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 8. Hyperparameter Search\n",
        "# ============================================================\n",
        "def hyperparameter_search():\n",
        "    \"\"\"\n",
        "    Perform hyperparameter search over common parameters.\n",
        "    This is a simple grid search - you can expand it as needed.\n",
        "\n",
        "    Returns:\n",
        "        best_config: Best hyperparameter configuration\n",
        "        all_results: Results from all configurations\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"HYPERPARAMETER SEARCH\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Define search space (simplified for demonstration)\n",
        "    search_space = {\n",
        "        'lr': [0.0001, 0.0005, 0.001],\n",
        "        'batch_size': [64, 128],\n",
        "        'weight_decay': [1e-4, 5e-4]\n",
        "    }\n",
        "\n",
        "    # Base configuration\n",
        "    base_config = {\n",
        "        'epochs': 30,  # Reduced for search\n",
        "        'momentum': 0.9,\n",
        "        'dropout_rate': 0.1,\n",
        "        'warmup_epochs': 5,\n",
        "        'patience': 10\n",
        "    }\n",
        "\n",
        "    all_results = []\n",
        "    best_acc = 0\n",
        "    best_config = None\n",
        "\n",
        "    # Grid search\n",
        "    for lr in search_space['lr']:\n",
        "        for batch_size in search_space['batch_size']:\n",
        "            for weight_decay in search_space['weight_decay']:\n",
        "                config = base_config.copy()\n",
        "                config.update({\n",
        "                    'lr': lr,\n",
        "                    'batch_size': batch_size,\n",
        "                    'weight_decay': weight_decay\n",
        "                })\n",
        "\n",
        "                print(f\"\\nTesting config: LR={lr}, BS={batch_size}, WD={weight_decay}\")\n",
        "                test_acc, _ = run_centralized_baseline(config=config, seed=42)\n",
        "\n",
        "                all_results.append({\n",
        "                    'config': config,\n",
        "                    'test_acc': test_acc\n",
        "                })\n",
        "\n",
        "                if test_acc > best_acc:\n",
        "                    best_acc = test_acc\n",
        "                    best_config = config\n",
        "                    print(f\"✓ New best config! Acc={test_acc:.2f}%\")\n",
        "\n",
        "    # Save search results\n",
        "    with open('logs/hyperparameter_search.json', 'w') as f:\n",
        "        json.dump({\n",
        "            'best_config': best_config,\n",
        "            'best_acc': best_acc,\n",
        "            'all_results': all_results\n",
        "        }, f, indent=2)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"HYPERPARAMETER SEARCH COMPLETE\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Best configuration:\")\n",
        "    for key, value in best_config.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "    print(f\"Best test accuracy: {best_acc:.2f}%\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return best_config, all_results\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 9. Plotting Function (Enhanced)\n",
        "# ============================================================\n",
        "def plot_results(history, save_path=None):\n",
        "    \"\"\"\n",
        "    Plot training and validation loss/accuracy curves.\n",
        "\n",
        "    Args:\n",
        "        history: Dictionary containing training history\n",
        "        save_path: Optional path to save figure\n",
        "    \"\"\"\n",
        "    os.makedirs('figures', exist_ok=True)\n",
        "\n",
        "    epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Loss curve\n",
        "    axes[0].plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
        "    axes[0].plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
        "    axes[0].set_title('Loss over Epochs', fontsize=14, fontweight='bold')\n",
        "    axes[0].set_xlabel('Epochs', fontsize=12)\n",
        "    axes[0].set_ylabel('Loss', fontsize=12)\n",
        "    axes[0].legend(fontsize=11)\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Accuracy curve\n",
        "    axes[1].plot(epochs, history['train_acc'], 'b-', label='Training Accuracy', linewidth=2)\n",
        "    axes[1].plot(epochs, history['val_acc'], 'r-', label='Validation Accuracy', linewidth=2)\n",
        "    axes[1].set_title('Accuracy over Epochs', fontsize=14, fontweight='bold')\n",
        "    axes[1].set_xlabel('Epochs', fontsize=12)\n",
        "    axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
        "    axes[1].legend(fontsize=11)\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Add best validation accuracy marker\n",
        "    best_val_idx = np.argmax(history['val_acc'])\n",
        "    best_val_acc = history['val_acc'][best_val_idx]\n",
        "    axes[1].axvline(x=best_val_idx+1, color='green', linestyle='--',\n",
        "                   alpha=0.5, label=f'Best: {best_val_acc:.2f}%')\n",
        "    axes[1].legend(fontsize=11)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path is None:\n",
        "        save_path = 'figures/training_curves.png'\n",
        "\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"Training curves saved to {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create necessary directories\n",
        "    os.makedirs('checkpoints', exist_ok=True)\n",
        "    os.makedirs('logs', exist_ok=True)\n",
        "    os.makedirs('figures', exist_ok=True)\n",
        "\n",
        "    # Option 1: Single run with default config\n",
        "    print(\"Option 1: Single run with default configuration\")\n",
        "    test_acc, history = run_centralized_baseline()\n",
        "\n",
        "    # Option 2: Multiple runs for statistical significance\n",
        "    # print(\"Option 2: Multiple runs for statistical significance\")\n",
        "    results = run_multiple_experiments(num_runs=3)\n",
        "\n",
        "    # Option 3: Hyperparameter search (commented out - takes time)\n",
        "    # print(\"Option 3: Hyperparameter search\")\n",
        "    best_config, all_results = hyperparameter_search()\n",
        "    # print(f\"Best config: {best_config}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "AdvancedMachingLearning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
